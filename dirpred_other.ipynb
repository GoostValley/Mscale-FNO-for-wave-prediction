{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6b93d1",
   "metadata": {},
   "source": [
    "## Direct Prediction by other spatial temporal methods\n",
    "\n",
    "The part is mainly implemented with the library OpenSTL(). To run this notebook, you need to install OpenSTL first. My experience of the installation is that set the version of **timm==0.9**, this can avoid plenty errors. \n",
    "\n",
    "The models tried here are ConvLSTM and SimVp. Using the template config for mmnist. To keep accordance with the FNO experiments, the optimizer is set to Adam, and the epochs is set to 500.  \n",
    "* ConvLSTM\n",
    "* SimVp-gsta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb321dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengyaokun/anaconda3/envs/OpenSTL/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from utilities3 import *\n",
    "from openstl.api import BaseExperiment\n",
    "from openstl.utils import create_parser, default_parser\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c90bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and split the data\n",
    "def read_data(file_paths, inlen=16, outlen=16):\n",
    "    eta = []\n",
    "    scatter = []\n",
    "    len = inlen + outlen\n",
    "    for f in file_paths:\n",
    "        reader = MatReader(f, to_torch=False)\n",
    "        eta_tmp = reader.read_field('eta')\n",
    "        scatter_tmp = reader.read_field('scatter')\n",
    "        #eta_tmp = eta_tmp[:,:,:,117:501]\n",
    "        #scatter_tmp = scatter_tmp[:,:,:,117:501]\n",
    "        eta_tmp = eta_tmp[:,:,:,117:437]\n",
    "        scatter_tmp = scatter_tmp[:,:,:,117:437]\n",
    "        #print(eta_tmp.shape,scatter_tmp.shape)\n",
    "        slice_eta = []\n",
    "        slice_scatter = []\n",
    "        for i in range(10):\n",
    "            slice_eta.append(eta_tmp[:,:,:,32*i:32*(i+1)])\n",
    "            slice_scatter.append(scatter_tmp[:,:,:,32*i:32*(i+1)])\n",
    "        eta_tmp = np.concatenate(slice_eta,axis=0)\n",
    "        scatter_tmp = np.concatenate(slice_scatter,axis=0)\n",
    "        #print(eta_tmp.shape,scatter_tmp.shape)\n",
    "        #eta.append(eta_tmp)\n",
    "        #scatter.append(scatter_tmp)\n",
    "        x = reader.read_field('x').flatten()\n",
    "        y = reader.read_field('y').flatten()\n",
    "        t = reader.read_field('t').flatten()\n",
    "        t = t[0:32] \n",
    "        if eta == []:\n",
    "            eta = eta_tmp\n",
    "            scatter = scatter_tmp\n",
    "        else:\n",
    "            eta = np.concatenate([eta,eta_tmp])\n",
    "            scatter = np.concatenate([scatter,scatter_tmp])\n",
    "    return eta, scatter, x, y, t\n",
    "\n",
    "def split_data(eta, scatter, train_test_split=[0.6,0.2,0.2], inlen=16, outlen=16, sub=2, to_torch=False):\n",
    "    train_size = int(eta.shape[0]*train_test_split[0])\n",
    "    test_size = int(eta.shape[0]*train_test_split[2])\n",
    "    train_a = scatter[:train_size,::sub,::sub,:inlen]\n",
    "    train_e = eta[:train_size,::sub,::sub,:inlen]\n",
    "    train_u = eta[:train_size,::sub,::sub,inlen:inlen+outlen]\n",
    "    val_a = scatter[train_size:train_size+test_size,::sub,::sub,:inlen]\n",
    "    val_e = eta[train_size:train_size+test_size,::sub,::sub,:inlen]\n",
    "    val_u = eta[train_size:train_size+test_size,::sub,::sub,inlen:inlen+outlen]\n",
    "    test_a = scatter[train_size+test_size:,::sub,::sub,:inlen]\n",
    "    test_e = eta[train_size+test_size:,::sub,::sub,:inlen]\n",
    "    test_u = eta[train_size+test_size:,::sub,::sub,inlen:inlen+outlen]\n",
    "    if to_torch:\n",
    "        train_a = torch.from_numpy(train_a)\n",
    "        train_e = torch.from_numpy(train_e)\n",
    "        train_u = torch.from_numpy(train_u)\n",
    "        val_a = torch.from_numpy(val_a)\n",
    "        val_e = torch.from_numpy(val_e)\n",
    "        val_u = torch.from_numpy(val_u)\n",
    "        test_a = torch.from_numpy(test_a)\n",
    "        test_e = torch.from_numpy(test_e)\n",
    "        test_u = torch.from_numpy(test_u)\n",
    "    return train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u\n",
    "\n",
    "# read and split data, for each datafile, spilit it in to train,val and test then concatenate them, add hs and spread tag in the filename, length the same as the test array\n",
    "def read_and_split(file_paths, train_test_split=[0.6,0.2,0.2], inlen=16, outlen=16, sub=2, to_torch=False):\n",
    "    eta, scatter, x, y, t = read_data([file_paths[0]], inlen=inlen, outlen=outlen)\n",
    "    train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u = split_data(eta, scatter, train_test_split=train_test_split, inlen=inlen, outlen=outlen, sub=sub, to_torch=to_torch)\n",
    "    hs = float(file_paths[0].split('angle')[1].split('h')[1].split('.mat')[0]) * np.ones(test_a.shape[0])   \n",
    "    spread = float(file_paths[0].split('angle')[1].split('h')[0]) * np.ones(test_a.shape[0]) \n",
    "\n",
    "    for i,f in enumerate(file_paths):\n",
    "        if i>0:\n",
    "            eta, scatter, x, y, t = read_data([f], inlen=inlen, outlen=outlen)\n",
    "            train_a_tmp, train_e_tmp, train_u_tmp, val_a_tmp, val_e_tmp, val_u_tmp, test_a_tmp, test_e_tmp, test_u_tmp = split_data(eta, scatter, train_test_split=train_test_split, inlen=inlen, outlen=outlen, sub=sub, to_torch=to_torch)\n",
    "            train_a = np.concatenate([train_a,train_a_tmp])\n",
    "            train_e = np.concatenate([train_e,train_e_tmp])\n",
    "            train_u = np.concatenate([train_u,train_u_tmp])\n",
    "            val_a = np.concatenate([val_a,val_a_tmp])\n",
    "            val_e = np.concatenate([val_e,val_e_tmp])\n",
    "            val_u = np.concatenate([val_u,val_u_tmp])\n",
    "            test_a = np.concatenate([test_a,test_a_tmp])\n",
    "            test_e = np.concatenate([test_e,test_e_tmp])\n",
    "            test_u = np.concatenate([test_u,test_u_tmp])\n",
    "            hs = np.concatenate([hs,float(f.split('angle')[1].split('h')[1].split('.mat')[0]) * np.ones(test_a_tmp.shape[0])])\n",
    "            spread = np.concatenate([spread,float(f.split('angle')[1].split('h')[0]) * np.ones(test_a_tmp.shape[0])])\n",
    "    if to_torch:\n",
    "        train_a = torch.from_numpy(train_a)\n",
    "        train_e = torch.from_numpy(train_e)\n",
    "        train_u = torch.from_numpy(train_u)\n",
    "        val_a = torch.from_numpy(val_a)\n",
    "        val_e = torch.from_numpy(val_e)\n",
    "        val_u = torch.from_numpy(val_u)\n",
    "        test_a = torch.from_numpy(test_a)\n",
    "        test_e = torch.from_numpy(test_e)\n",
    "        test_u = torch.from_numpy(test_u)\n",
    "        hs = torch.from_numpy(hs)\n",
    "        spread = torch.from_numpy(spread)\n",
    "\n",
    "    return train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u, x, y, t, hs, spread\n",
    "\n",
    "\n",
    "dirs = os.listdir(\"../mixed_data\")\n",
    "dirs = [os.path.join(\"../mixed_data\",d) for d in dirs]\n",
    "# add another dir\n",
    "dirs2 = os.listdir(\"../mixed_data2\")\n",
    "dirs2 = [os.path.join(\"../mixed_data2\",d) for d in dirs2]\n",
    "dirs = dirs + dirs2\n",
    "train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u,x_domain,y_domain,t_domain,hs, spread = read_and_split(dirs,inlen=16,outlen=16,sub=2,to_torch=False)\n",
    "hs = hs.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16662bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset and build the dataloader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y, normalize=False):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.data_name = \"custom\"\n",
    "\n",
    "        if normalize:\n",
    "            # get the mean/std values along the channel dimension\n",
    "            mean = data.mean(axis=(0, 1, 2, 3)).reshape(1, 1, -1, 1, 1)\n",
    "            std = data.std(axis=(0, 1, 2, 3)).reshape(1, 1, -1, 1, 1)\n",
    "            data = (data - mean) / std\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.tensor(self.X[index]).float()\n",
    "        labels = torch.tensor(self.Y[index]).float()\n",
    "        return data, labels\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_a = np.transpose(np.expand_dims(train_a,axis=1),axes=(0,4,1,2,3))\n",
    "train_u = np.transpose(np.expand_dims(train_u,axis=1),axes=(0,4,1,2,3))\n",
    "val_a = np.transpose(np.expand_dims(val_a,axis=1),axes=(0,4,1,2,3))\n",
    "val_u = np.transpose(np.expand_dims(val_u,axis=1),axes=(0,4,1,2,3))\n",
    "test_a = np.transpose(np.expand_dims(test_a,axis=1),axes=(0,4,1,2,3))\n",
    "test_u = np.transpose(np.expand_dims(test_u,axis=1),axes=(0,4,1,2,3))\n",
    "\n",
    "train_set = CustomDataset(X=train_a, Y=train_u)\n",
    "val_set = CustomDataset(X=val_a, Y=val_u)\n",
    "test_set = CustomDataset(X=test_a, Y=test_u)\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for SimVP-gSTA, setting copy from './OpenSTL/configs/mmnist/simvp/SimVP_gSTA.py'\n",
    "pre_seq_length = 16\n",
    "aft_seq_length = 16\n",
    "custom_training_config = {\n",
    "    'pre_seq_length': pre_seq_length,\n",
    "    'aft_seq_length': aft_seq_length,\n",
    "    'total_length': pre_seq_length + aft_seq_length,\n",
    "    'batch_size': batch_size,\n",
    "    'val_batch_size': batch_size,\n",
    "    'epoch': 500,\n",
    "    'lr': 0.001,   \n",
    "    'metrics': ['mse', 'mae'],\n",
    "    'dataname': 'custom',\n",
    "    'ex_name': 'simvp',\n",
    "    'in_shape': [16, 1, 64, 64],\n",
    "    'optimizer': 'adam',\n",
    "}\n",
    "\n",
    "custom_model_config = {\n",
    "    # For MetaVP models, the most important hyperparameters are: \n",
    "    # N_S, N_T, hid_S, hid_T, model_type\n",
    "    #'method': 'SimVP',\n",
    "    # Users can either using a config file or directly set these hyperparameters \n",
    "    #'config_file': './OpenSTL/configs/mmnist/simvp/SimVP_gSTA-L.py',\n",
    "    # Here, we directly set these parameters\n",
    "    'method': 'SimVP',\n",
    "    # model\n",
    "    'spatio_kernel_enc': 3,\n",
    "    'spatio_kernel_dec': 3,\n",
    "    'model_type': 'gSTA',\n",
    "    'hid_S': 64,\n",
    "    'hid_T': 512,\n",
    "    'N_T': 8,\n",
    "    'N_S': 4,\n",
    "    # training\n",
    "    'lr': 1e-3,\n",
    "    #'batch_size': 16,\n",
    "    'drop_path': 0,\n",
    "    'sched': 'onecycle',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1551ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for ConvLSTM, seting copy from  './OpenSTL/configs/mmnist/ConvLSTM.py'\n",
    "pre_seq_length = 16\n",
    "aft_seq_length = 16\n",
    "custom_training_config = {\n",
    "    'pre_seq_length': pre_seq_length,\n",
    "    'aft_seq_length': aft_seq_length,\n",
    "    'total_length': pre_seq_length + aft_seq_length,\n",
    "    'batch_size': batch_size,\n",
    "    'val_batch_size': batch_size,\n",
    "    'epoch': 500,\n",
    "    'lr': 0.001,   \n",
    "    'metrics': ['mse', 'mae'],\n",
    "    'dataname': 'custom',\n",
    "    'ex_name': 'convlstm',\n",
    "    'in_shape': [16, 1, 64, 64],\n",
    "    'optimizer': 'adam',\n",
    "}\n",
    "\n",
    "custom_model_config = {\n",
    "    # For MetaVP models, the most important hyperparameters are: \n",
    "    # N_S, N_T, hid_S, hid_T, model_type\n",
    "    #'method': 'SimVP',\n",
    "    # Users can either using a config file or directly set these hyperparameters \n",
    "    #'config_file': './OpenSTL/configs/mmnist/ConvLSTM-L.py',\n",
    "    # Here, we directly set these parameters\n",
    "    'method': 'ConvLSTM',\n",
    "# reverse scheduled sampling\n",
    "    'reverse_scheduled_sampling': 0,\n",
    "    'r_sampling_step_1': 25000,\n",
    "    'r_sampling_step_2': 50000,\n",
    "    'r_exp_alpha': 5000,\n",
    "    # scheduled sampling\n",
    "    'scheduled_sampling': 1,\n",
    "    'sampling_stop_iter': 50000,\n",
    "    'sampling_start_value': 1.0,\n",
    "    'sampling_changing_rate': 0.00002,\n",
    "    # model\n",
    "    'num_hidden': '128,128,128,128',\n",
    "    'filter_size': 5,\n",
    "    'stride': 1,\n",
    "    'patch_size': 4,\n",
    "    'layer_norm': 0,\n",
    "    # training\n",
    "    'lr': 5e-4,\n",
    "    #'batch_size': 16,\n",
    "    'sched': 'onecycle',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ab8af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# set up the experiment\n",
    "args = create_parser().parse_args([])\n",
    "config = args.__dict__\n",
    "\n",
    "# update the training config\n",
    "config.update(custom_training_config)\n",
    "# update the model config\n",
    "config.update(custom_model_config)\n",
    "# fulfill with default values\n",
    "default_values = default_parser()\n",
    "for attribute in default_values.keys():\n",
    "    if config[attribute] is None:\n",
    "        config[attribute] = default_values[attribute]\n",
    "\n",
    "exp = BaseExperiment(args, dataloaders=(dataloader_train, dataloader_val, dataloader_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abe4212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'cuda', 'dist': False, 'res_dir': 'work_dirs', 'ex_name': 'convlstm', 'fp16': False, 'torchscript': False, 'seed': 42, 'fps': False, 'test': False, 'deterministic': False, 'batch_size': 20, 'val_batch_size': 20, 'num_workers': 4, 'data_root': './data', 'dataname': 'custom', 'pre_seq_length': 16, 'aft_seq_length': 16, 'total_length': 32, 'use_augment': False, 'use_prefetcher': False, 'drop_last': False, 'method': 'convlstm', 'config_file': None, 'model_type': 'gSTA', 'drop': 0.0, 'drop_path': 0.0, 'overwrite': False, 'epoch': 500, 'log_step': 1, 'opt': 'adam', 'opt_eps': None, 'opt_betas': None, 'momentum': 0.9, 'weight_decay': 0.0, 'clip_grad': None, 'clip_mode': 'norm', 'no_display_method_info': False, 'sched': 'onecycle', 'lr': 0.0005, 'lr_k_decay': 1.0, 'warmup_lr': 1e-05, 'min_lr': 1e-06, 'final_div_factor': 10000.0, 'warmup_epoch': 0, 'decay_epoch': 100, 'decay_rate': 0.1, 'filter_bias_and_bn': False, 'gpus': [0], 'metric_for_bestckpt': 'val_loss', 'ckpt_path': None, 'metrics': ['mse', 'mae'], 'in_shape': [16, 1, 64, 64], 'optimizer': 'adam', 'reverse_scheduled_sampling': 0, 'r_sampling_step_1': 25000, 'r_sampling_step_2': 50000, 'r_exp_alpha': 5000, 'scheduled_sampling': 1, 'sampling_stop_iter': 50000, 'sampling_start_value': 1.0, 'sampling_changing_rate': 2e-05, 'num_hidden': '128,128,128,128', 'filter_size': 5, 'stride': 1, 'patch_size': 4, 'layer_norm': 0}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dadc35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | model     | ConvLSTM_Model | 15.1 M\n",
      "1 | criterion | MSELoss        | 0     \n",
      "---------------------------------------------\n",
      "15.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.1 M    Total params\n",
      "60.334    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> training <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]\n",
      "CUDA available: True\n",
      "CUDA_HOME: /usr/local/cuda-11.2\n",
      "NVCC: Build cuda_11.2.r11.2/compiler.29373293_0\n",
      "GPU 0: NVIDIA A100 80GB PCIe\n",
      "GCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "PyTorch: 2.1.0+cu121\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.16.0+cu121\n",
      "OpenCV: 4.8.1\n",
      "openstl: 1.0.0\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "device: \tcuda\t\n",
      "dist: \tFalse\t\n",
      "res_dir: \twork_dirs\t\n",
      "ex_name: \tconvlstm\t\n",
      "fp16: \tFalse\t\n",
      "torchscript: \tFalse\t\n",
      "seed: \t42\t\n",
      "fps: \tFalse\t\n",
      "test: \tFalse\t\n",
      "deterministic: \tFalse\t\n",
      "batch_size: \t20\t\n",
      "val_batch_size: \t20\t\n",
      "num_workers: \t4\t\n",
      "data_root: \t./data\t\n",
      "dataname: \tcustom\t\n",
      "pre_seq_length: \t16\t\n",
      "aft_seq_length: \t16\t\n",
      "total_length: \t32\t\n",
      "use_augment: \tFalse\t\n",
      "use_prefetcher: \tFalse\t\n",
      "drop_last: \tFalse\t\n",
      "method: \tconvlstm\t\n",
      "config_file: \tNone\t\n",
      "model_type: \tgSTA\t\n",
      "drop: \t0.0\t\n",
      "drop_path: \t0.0\t\n",
      "overwrite: \tFalse\t\n",
      "epoch: \t500\t\n",
      "log_step: \t1\t\n",
      "opt: \tadam\t\n",
      "opt_eps: \tNone\t\n",
      "opt_betas: \tNone\t\n",
      "momentum: \t0.9\t\n",
      "weight_decay: \t0.0\t\n",
      "clip_grad: \tNone\t\n",
      "clip_mode: \tnorm\t\n",
      "no_display_method_info: \tFalse\t\n",
      "sched: \tonecycle\t\n",
      "lr: \t0.0005\t\n",
      "lr_k_decay: \t1.0\t\n",
      "warmup_lr: \t1e-05\t\n",
      "min_lr: \t1e-06\t\n",
      "final_div_factor: \t10000.0\t\n",
      "warmup_epoch: \t0\t\n",
      "decay_epoch: \t100\t\n",
      "decay_rate: \t0.1\t\n",
      "filter_bias_and_bn: \tFalse\t\n",
      "gpus: \t[0]\t\n",
      "metric_for_bestckpt: \tval_loss\t\n",
      "ckpt_path: \tNone\t\n",
      "metrics: \t['mse', 'mae']\t\n",
      "in_shape: \t[16, 1, 64, 64]\t\n",
      "optimizer: \tadam\t\n",
      "reverse_scheduled_sampling: \t0\t\n",
      "r_sampling_step_1: \t25000\t\n",
      "r_sampling_step_2: \t50000\t\n",
      "r_exp_alpha: \t5000\t\n",
      "scheduled_sampling: \t1\t\n",
      "sampling_stop_iter: \t50000\t\n",
      "sampling_start_value: \t1.0\t\n",
      "sampling_changing_rate: \t2e-05\t\n",
      "num_hidden: \t128,128,128,128\t\n",
      "filter_size: \t5\t\n",
      "stride: \t1\t\n",
      "patch_size: \t4\t\n",
      "layer_norm: \t0\t\n",
      "Model info:\n",
      "ConvLSTM_Model(\n",
      "  (MSE_criterion): MSELoss()\n",
      "  (cell_list): ModuleList(\n",
      "    (0): ConvLSTMCell(\n",
      "      (conv_x): Sequential(\n",
      "        (0): Conv2d(16, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      )\n",
      "      (conv_h): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      )\n",
      "      (conv_o): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      )\n",
      "      (conv_last): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1-3): 3 x ConvLSTMCell(\n",
      "      (conv_x): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      )\n",
      "      (conv_h): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      )\n",
      "      (conv_o): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      )\n",
      "      (conv_last): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (conv_last): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n",
      "| module                   | #parameters or shape   | #flops     |\n",
      "|:-------------------------|:-----------------------|:-----------|\n",
      "| model                    | 15.084M                | 92.658G    |\n",
      "|  cell_list               |  15.081M               |  92.642G   |\n",
      "|   cell_list.0            |   2.695M               |   14.628G  |\n",
      "|    cell_list.0.conv_x.0  |    0.205M              |    1.625G  |\n",
      "|    cell_list.0.conv_h.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.0.conv_o.0  |    0.819M              |            |\n",
      "|    cell_list.0.conv_last |    32.768K             |            |\n",
      "|   cell_list.1            |   4.129M               |   26.005G  |\n",
      "|    cell_list.1.conv_x.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.1.conv_h.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.1.conv_o.0  |    0.819M              |            |\n",
      "|    cell_list.1.conv_last |    32.768K             |            |\n",
      "|   cell_list.2            |   4.129M               |   26.005G  |\n",
      "|    cell_list.2.conv_x.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.2.conv_h.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.2.conv_o.0  |    0.819M              |            |\n",
      "|    cell_list.2.conv_last |    32.768K             |            |\n",
      "|   cell_list.3            |   4.129M               |   26.005G  |\n",
      "|    cell_list.3.conv_x.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.3.conv_h.0  |    1.638M              |    13.002G |\n",
      "|    cell_list.3.conv_o.0  |    0.819M              |            |\n",
      "|    cell_list.3.conv_last |    32.768K             |            |\n",
      "|  conv_last               |  2.048K                |  16.253M   |\n",
      "|   conv_last.weight       |   (16, 128, 1, 1)      |            |\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 36/36 [00:09<00:00,  3.83it/s, v_num=9, train_loss_step=1.24e+3, train_loss_epoch=1.1e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 36: 'val_loss' reached 1.95434 (best 1.95434), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=00-val_loss=1.954.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=986.0, train_loss_epoch=1.1e+3]  Epoch 1: Lr: 0.0000202 | Train Loss: 1100.7482910 | Vali Loss: 2.7089663\n",
      "Epoch 1: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=986.0, train_loss_epoch=1.07e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 72: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=983.0, train_loss_epoch=1.07e+3]  Epoch 2: Lr: 0.0000205 | Train Loss: 1074.8193359 | Vali Loss: 3.0473144\n",
      "Epoch 2: 100%|██████████| 36/36 [00:08<00:00,  4.07it/s, v_num=9, train_loss_step=983.0, train_loss_epoch=1.07e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 108: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=1.02e+3, train_loss_epoch=1.07e+3]Epoch 3: Lr: 0.0000208 | Train Loss: 1068.0043945 | Vali Loss: 3.3928673\n",
      "Epoch 3: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=1.02e+3, train_loss_epoch=1.06e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 144: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=1.01e+3, train_loss_epoch=1.06e+3]Epoch 4: Lr: 0.0000213 | Train Loss: 1064.1126709 | Vali Loss: 3.7529948\n",
      "Epoch 4: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=1.01e+3, train_loss_epoch=1.06e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 180: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=1.13e+3, train_loss_epoch=1.06e+3]Epoch 5: Lr: 0.0000219 | Train Loss: 1060.6896973 | Vali Loss: 4.1358461\n",
      "Epoch 5: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=1.13e+3, train_loss_epoch=1.06e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 216: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=1.23e+3, train_loss_epoch=1.06e+3]Epoch 6: Lr: 0.0000226 | Train Loss: 1057.4229736 | Vali Loss: 4.5408416\n",
      "Epoch 6: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=1.23e+3, train_loss_epoch=1.05e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 252: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=965.0, train_loss_epoch=1.05e+3]  Epoch 7: Lr: 0.0000234 | Train Loss: 1054.1693115 | Vali Loss: 4.9777169\n",
      "Epoch 7: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=965.0, train_loss_epoch=1.05e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 288: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=856.0, train_loss_epoch=1.05e+3]  Epoch 8: Lr: 0.0000243 | Train Loss: 1050.9387207 | Vali Loss: 5.4573269\n",
      "Epoch 8: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=856.0, train_loss_epoch=1.05e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 324: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=1.08e+3, train_loss_epoch=1.05e+3]Epoch 9: Lr: 0.0000252 | Train Loss: 1047.7125244 | Vali Loss: 5.9680305\n",
      "Epoch 9: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=1.08e+3, train_loss_epoch=1.04e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 360: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=882.0, train_loss_epoch=1.04e+3]  Epoch 10: Lr: 0.0000263 | Train Loss: 1044.3721924 | Vali Loss: 6.5272722\n",
      "Epoch 10: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=882.0, train_loss_epoch=1.04e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 396: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3]Epoch 11: Lr: 0.0000275 | Train Loss: 1041.0163574 | Vali Loss: 7.1343508\n",
      "Epoch 11: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 432: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=1.41e+3, train_loss_epoch=1.04e+3]Epoch 12: Lr: 0.0000288 | Train Loss: 1037.5566406 | Vali Loss: 7.7956500\n",
      "Epoch 12: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=1.41e+3, train_loss_epoch=1.03e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 468: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=939.0, train_loss_epoch=1.03e+3]  Epoch 13: Lr: 0.0000302 | Train Loss: 1034.0100098 | Vali Loss: 8.5196724\n",
      "Epoch 13: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=939.0, train_loss_epoch=1.03e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 504: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=993.0, train_loss_epoch=1.03e+3]  Epoch 14: Lr: 0.0000318 | Train Loss: 1030.3697510 | Vali Loss: 9.3098116\n",
      "Epoch 14: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=993.0, train_loss_epoch=1.03e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 540: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=929.0, train_loss_epoch=1.03e+3]  Epoch 15: Lr: 0.0000334 | Train Loss: 1026.6107178 | Vali Loss: 10.1825733\n",
      "Epoch 15: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=929.0, train_loss_epoch=1.02e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 576: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=1.31e+3, train_loss_epoch=1.02e+3]Epoch 16: Lr: 0.0000351 | Train Loss: 1022.7678223 | Vali Loss: 11.1256866\n",
      "Epoch 16: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=1.31e+3, train_loss_epoch=1.02e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 612: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=1.13e+3, train_loss_epoch=1.02e+3]Epoch 17: Lr: 0.0000369 | Train Loss: 1018.7582397 | Vali Loss: 12.1708717\n",
      "Epoch 17: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=1.13e+3, train_loss_epoch=1.01e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 648: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=1.26e+3, train_loss_epoch=1.01e+3]Epoch 18: Lr: 0.0000388 | Train Loss: 1014.6823120 | Vali Loss: 13.2961979\n",
      "Epoch 18: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=1.26e+3, train_loss_epoch=1.01e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 684: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=996.0, train_loss_epoch=1.01e+3]  Epoch 19: Lr: 0.0000408 | Train Loss: 1010.4190063 | Vali Loss: 14.5555229\n",
      "Epoch 19: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=996.0, train_loss_epoch=1.01e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 720: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=1.03e+3, train_loss_epoch=1.01e+3]Epoch 20: Lr: 0.0000428 | Train Loss: 1006.1231079 | Vali Loss: 15.8954401\n",
      "Epoch 20: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=1.03e+3, train_loss_epoch=1e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=1.22e+3, train_loss_epoch=1e+3]Epoch 21: Lr: 0.0000450 | Train Loss: 1001.5033569 | Vali Loss: 17.3624172\n",
      "Epoch 21: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=1.22e+3, train_loss_epoch=994.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 792: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=851.0, train_loss_epoch=994.0]  Epoch 22: Lr: 0.0000473 | Train Loss: 994.4369507 | Vali Loss: 15.3444433\n",
      "Epoch 22: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=851.0, train_loss_epoch=984.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 828: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=916.0, train_loss_epoch=984.0]  Epoch 23: Lr: 0.0000497 | Train Loss: 984.1008911 | Vali Loss: 16.6454506\n",
      "Epoch 23: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=916.0, train_loss_epoch=977.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 864: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=1.02e+3, train_loss_epoch=977.0]Epoch 24: Lr: 0.0000522 | Train Loss: 977.3227539 | Vali Loss: 6.0188522\n",
      "Epoch 24: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=1.02e+3, train_loss_epoch=971.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 900: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=1.03e+3, train_loss_epoch=971.0]Epoch 25: Lr: 0.0000547 | Train Loss: 970.5221558 | Vali Loss: 2.6578894\n",
      "Epoch 25: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=1.03e+3, train_loss_epoch=964.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 936: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=1.2e+3, train_loss_epoch=964.0] Epoch 26: Lr: 0.0000574 | Train Loss: 963.6397705 | Vali Loss: 2.5294235\n",
      "Epoch 26: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=1.2e+3, train_loss_epoch=956.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 972: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 36/36 [00:07<00:00,  4.51it/s, v_num=9, train_loss_step=1.13e+3, train_loss_epoch=956.0]Epoch 27: Lr: 0.0000601 | Train Loss: 956.4967041 | Vali Loss: 2.7305911\n",
      "Epoch 27: 100%|██████████| 36/36 [00:08<00:00,  4.01it/s, v_num=9, train_loss_step=1.13e+3, train_loss_epoch=949.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 1008: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=873.0, train_loss_epoch=949.0]  Epoch 28: Lr: 0.0000629 | Train Loss: 949.2537231 | Vali Loss: 2.8932467\n",
      "Epoch 28: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=873.0, train_loss_epoch=942.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 1044: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=863.0, train_loss_epoch=942.0]  Epoch 29: Lr: 0.0000659 | Train Loss: 941.7354126 | Vali Loss: 3.0349913\n",
      "Epoch 29: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=863.0, train_loss_epoch=934.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 1080: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=922.0, train_loss_epoch=934.0]  Epoch 30: Lr: 0.0000689 | Train Loss: 934.0508423 | Vali Loss: 3.2814367\n",
      "Epoch 30: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=922.0, train_loss_epoch=926.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 1116: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=629.0, train_loss_epoch=926.0]  Epoch 31: Lr: 0.0000719 | Train Loss: 926.1609497 | Vali Loss: 3.5104723\n",
      "Epoch 31: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=629.0, train_loss_epoch=918.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 1152: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=1.02e+3, train_loss_epoch=918.0]Epoch 32: Lr: 0.0000751 | Train Loss: 918.1291504 | Vali Loss: 3.7857733\n",
      "Epoch 32: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=1.02e+3, train_loss_epoch=910.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 1188: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=947.0, train_loss_epoch=910.0]  Epoch 33: Lr: 0.0000783 | Train Loss: 909.8446045 | Vali Loss: 4.0869493\n",
      "Epoch 33: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=947.0, train_loss_epoch=901.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 1224: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 36/36 [00:07<00:00,  4.54it/s, v_num=9, train_loss_step=1.01e+3, train_loss_epoch=901.0]Epoch 34: Lr: 0.0000817 | Train Loss: 901.4303589 | Vali Loss: 4.4056721\n",
      "Epoch 34: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=1.01e+3, train_loss_epoch=893.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 1260: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=776.0, train_loss_epoch=893.0]  Epoch 35: Lr: 0.0000851 | Train Loss: 892.8657227 | Vali Loss: 4.8092089\n",
      "Epoch 35: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=776.0, train_loss_epoch=884.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 1296: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=996.0, train_loss_epoch=884.0]  Epoch 36: Lr: 0.0000886 | Train Loss: 884.1430664 | Vali Loss: 5.5583563\n",
      "Epoch 36: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=996.0, train_loss_epoch=875.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 1332: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=850.0, train_loss_epoch=875.0]  Epoch 37: Lr: 0.0000921 | Train Loss: 875.2293701 | Vali Loss: 5.5861664\n",
      "Epoch 37: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=850.0, train_loss_epoch=866.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 1368: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=780.0, train_loss_epoch=866.0]  Epoch 38: Lr: 0.0000957 | Train Loss: 866.2691040 | Vali Loss: 5.9531264\n",
      "Epoch 38: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=780.0, train_loss_epoch=857.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 1404: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=766.0, train_loss_epoch=857.0]  Epoch 39: Lr: 0.0000994 | Train Loss: 857.1082764 | Vali Loss: 6.4250636\n",
      "Epoch 39: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=766.0, train_loss_epoch=848.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 1440: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=649.0, train_loss_epoch=848.0]  Epoch 40: Lr: 0.0001032 | Train Loss: 847.9047852 | Vali Loss: 7.1081767\n",
      "Epoch 40: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=649.0, train_loss_epoch=839.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 1476: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=829.0, train_loss_epoch=839.0]  Epoch 41: Lr: 0.0001070 | Train Loss: 838.5856934 | Vali Loss: 7.6210070\n",
      "Epoch 41: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=829.0, train_loss_epoch=829.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 1512: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 36/36 [00:07<00:00,  4.74it/s, v_num=9, train_loss_step=928.0, train_loss_epoch=829.0]  Epoch 42: Lr: 0.0001110 | Train Loss: 829.1657104 | Vali Loss: 7.9802051\n",
      "Epoch 42: 100%|██████████| 36/36 [00:08<00:00,  4.19it/s, v_num=9, train_loss_step=928.0, train_loss_epoch=819.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 1548: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=783.0, train_loss_epoch=819.0]  Epoch 43: Lr: 0.0001149 | Train Loss: 819.4505005 | Vali Loss: 8.4952936\n",
      "Epoch 43: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=783.0, train_loss_epoch=810.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 1584: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=876.0, train_loss_epoch=810.0]Epoch 44: Lr: 0.0001190 | Train Loss: 809.6580811 | Vali Loss: 9.0088215\n",
      "Epoch 44: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=876.0, train_loss_epoch=800.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 1620: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=666.0, train_loss_epoch=800.0]  Epoch 45: Lr: 0.0001231 | Train Loss: 799.8455811 | Vali Loss: 10.0858879\n",
      "Epoch 45: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=666.0, train_loss_epoch=789.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 1656: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 36/36 [00:07<00:00,  4.74it/s, v_num=9, train_loss_step=886.0, train_loss_epoch=789.0]Epoch 46: Lr: 0.0001272 | Train Loss: 789.4159546 | Vali Loss: 11.7125349\n",
      "Epoch 46: 100%|██████████| 36/36 [00:08<00:00,  4.19it/s, v_num=9, train_loss_step=886.0, train_loss_epoch=776.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 1692: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=671.0, train_loss_epoch=776.0]Epoch 47: Lr: 0.0001314 | Train Loss: 775.8887939 | Vali Loss: 11.8277340\n",
      "Epoch 47: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=671.0, train_loss_epoch=763.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 1728: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 36/36 [00:07<00:00,  4.57it/s, v_num=9, train_loss_step=681.0, train_loss_epoch=763.0]Epoch 48: Lr: 0.0001357 | Train Loss: 763.3356934 | Vali Loss: 10.0399904\n",
      "Epoch 48: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=681.0, train_loss_epoch=751.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 1764: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=724.0, train_loss_epoch=751.0]Epoch 49: Lr: 0.0001400 | Train Loss: 751.4911499 | Vali Loss: 10.7701511\n",
      "Epoch 49: 100%|██████████| 36/36 [00:08<00:00,  4.07it/s, v_num=9, train_loss_step=724.0, train_loss_epoch=740.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1800: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=851.0, train_loss_epoch=740.0]Epoch 50: Lr: 0.0001444 | Train Loss: 739.7508545 | Vali Loss: 10.4967403\n",
      "Epoch 50: 100%|██████████| 36/36 [00:08<00:00,  4.19it/s, v_num=9, train_loss_step=851.0, train_loss_epoch=728.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50, global step 1836: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=788.0, train_loss_epoch=728.0]Epoch 51: Lr: 0.0001489 | Train Loss: 728.3150024 | Vali Loss: 12.5757856\n",
      "Epoch 51: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=788.0, train_loss_epoch=716.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51, global step 1872: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=797.0, train_loss_epoch=716.0]Epoch 52: Lr: 0.0001533 | Train Loss: 716.4505005 | Vali Loss: 13.6559906\n",
      "Epoch 52: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=797.0, train_loss_epoch=705.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52, global step 1908: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=667.0, train_loss_epoch=705.0]Epoch 53: Lr: 0.0001579 | Train Loss: 705.3809204 | Vali Loss: 260.7846069\n",
      "Epoch 53: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=667.0, train_loss_epoch=694.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53, global step 1944: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=685.0, train_loss_epoch=694.0]Epoch 54: Lr: 0.0001624 | Train Loss: 694.4698486 | Vali Loss: 54.2053261\n",
      "Epoch 54: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=685.0, train_loss_epoch=683.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54, global step 1980: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=661.0, train_loss_epoch=683.0]Epoch 55: Lr: 0.0001670 | Train Loss: 682.9151001 | Vali Loss: 87.4393997\n",
      "Epoch 55: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=661.0, train_loss_epoch=672.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55, global step 2016: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=703.0, train_loss_epoch=672.0]Epoch 56: Lr: 0.0001717 | Train Loss: 671.5612183 | Vali Loss: 24.1926003\n",
      "Epoch 56: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=703.0, train_loss_epoch=660.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56, global step 2052: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=590.0, train_loss_epoch=660.0]Epoch 57: Lr: 0.0001764 | Train Loss: 659.7675781 | Vali Loss: 54.6643562\n",
      "Epoch 57: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=590.0, train_loss_epoch=648.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57, global step 2088: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=592.0, train_loss_epoch=648.0]Epoch 58: Lr: 0.0001811 | Train Loss: 648.1588745 | Vali Loss: 147.4389038\n",
      "Epoch 58: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=592.0, train_loss_epoch=639.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58, global step 2124: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=689.0, train_loss_epoch=639.0]Epoch 59: Lr: 0.0001859 | Train Loss: 639.2895508 | Vali Loss: 42.1408653\n",
      "Epoch 59: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=689.0, train_loss_epoch=626.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 2160: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=626.0, train_loss_epoch=626.0]Epoch 60: Lr: 0.0001907 | Train Loss: 626.4310913 | Vali Loss: 102.1576462\n",
      "Epoch 60: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=626.0, train_loss_epoch=615.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60, global step 2196: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=525.0, train_loss_epoch=615.0]Epoch 61: Lr: 0.0001955 | Train Loss: 615.4029541 | Vali Loss: 15.5453682\n",
      "Epoch 61: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=525.0, train_loss_epoch=605.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61, global step 2232: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=598.0, train_loss_epoch=605.0]Epoch 62: Lr: 0.0002004 | Train Loss: 605.4760742 | Vali Loss: 7.7642369\n",
      "Epoch 62: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=598.0, train_loss_epoch=593.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62, global step 2268: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=595.0, train_loss_epoch=593.0]Epoch 63: Lr: 0.0002053 | Train Loss: 592.6060791 | Vali Loss: 121.7140121\n",
      "Epoch 63: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=595.0, train_loss_epoch=583.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63, global step 2304: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=526.0, train_loss_epoch=583.0]Epoch 64: Lr: 0.0002102 | Train Loss: 583.3865356 | Vali Loss: 16.0939369\n",
      "Epoch 64: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=526.0, train_loss_epoch=569.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64, global step 2340: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 36/36 [00:07<00:00,  4.51it/s, v_num=9, train_loss_step=511.0, train_loss_epoch=569.0]Epoch 65: Lr: 0.0002151 | Train Loss: 569.0951538 | Vali Loss: 103.9566574\n",
      "Epoch 65: 100%|██████████| 36/36 [00:08<00:00,  4.01it/s, v_num=9, train_loss_step=511.0, train_loss_epoch=562.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65, global step 2376: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=457.0, train_loss_epoch=562.0]Epoch 66: Lr: 0.0002200 | Train Loss: 562.0814819 | Vali Loss: 14.8740940\n",
      "Epoch 66: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=457.0, train_loss_epoch=550.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66, global step 2412: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=638.0, train_loss_epoch=550.0]Epoch 67: Lr: 0.0002250 | Train Loss: 549.7002563 | Vali Loss: 2.0495598\n",
      "Epoch 67: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=638.0, train_loss_epoch=534.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67, global step 2448: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=572.0, train_loss_epoch=534.0]Epoch 68: Lr: 0.0002300 | Train Loss: 534.3876953 | Vali Loss: 1.4142108\n",
      "Epoch 68: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=572.0, train_loss_epoch=523.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68, global step 2484: 'val_loss' reached 1.41421 (best 1.41421), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=68-val_loss=1.414.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=477.0, train_loss_epoch=523.0]Epoch 69: Lr: 0.0002350 | Train Loss: 522.9447021 | Vali Loss: 1.3067764\n",
      "Epoch 69: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=477.0, train_loss_epoch=513.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 2520: 'val_loss' reached 1.30678 (best 1.30678), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=69-val_loss=1.307.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=458.0, train_loss_epoch=513.0]Epoch 70: Lr: 0.0002400 | Train Loss: 513.0812988 | Vali Loss: 1.5539019\n",
      "Epoch 70: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=458.0, train_loss_epoch=502.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70, global step 2556: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=469.0, train_loss_epoch=502.0]Epoch 71: Lr: 0.0002450 | Train Loss: 502.2067261 | Vali Loss: 0.7439674\n",
      "Epoch 71: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=469.0, train_loss_epoch=492.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71, global step 2592: 'val_loss' reached 0.74397 (best 0.74397), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=71-val_loss=0.744.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=516.0, train_loss_epoch=492.0]Epoch 72: Lr: 0.0002500 | Train Loss: 491.7658081 | Vali Loss: 0.6404898\n",
      "Epoch 72: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=516.0, train_loss_epoch=482.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72, global step 2628: 'val_loss' reached 0.64049 (best 0.64049), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=72-val_loss=0.640.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=551.0, train_loss_epoch=482.0]Epoch 73: Lr: 0.0002550 | Train Loss: 481.8315125 | Vali Loss: 0.6645428\n",
      "Epoch 73: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=551.0, train_loss_epoch=472.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73, global step 2664: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=521.0, train_loss_epoch=472.0]Epoch 74: Lr: 0.0002601 | Train Loss: 472.2712708 | Vali Loss: 0.6979699\n",
      "Epoch 74: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=521.0, train_loss_epoch=463.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74, global step 2700: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=485.0, train_loss_epoch=463.0]Epoch 75: Lr: 0.0002651 | Train Loss: 463.1072998 | Vali Loss: 0.6717415\n",
      "Epoch 75: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=485.0, train_loss_epoch=454.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75, global step 2736: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=394.0, train_loss_epoch=454.0]Epoch 76: Lr: 0.0002701 | Train Loss: 454.0910034 | Vali Loss: 0.7173256\n",
      "Epoch 76: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=394.0, train_loss_epoch=445.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76, global step 2772: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 36/36 [00:08<00:00,  4.38it/s, v_num=9, train_loss_step=371.0, train_loss_epoch=445.0]Epoch 77: Lr: 0.0002751 | Train Loss: 445.3498840 | Vali Loss: 0.6909177\n",
      "Epoch 77: 100%|██████████| 36/36 [00:09<00:00,  3.91it/s, v_num=9, train_loss_step=371.0, train_loss_epoch=437.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77, global step 2808: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=528.0, train_loss_epoch=437.0]Epoch 78: Lr: 0.0002802 | Train Loss: 436.8667603 | Vali Loss: 0.7082605\n",
      "Epoch 78: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=528.0, train_loss_epoch=429.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78, global step 2844: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=354.0, train_loss_epoch=429.0]Epoch 79: Lr: 0.0002852 | Train Loss: 428.5397644 | Vali Loss: 0.6731927\n",
      "Epoch 79: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=354.0, train_loss_epoch=421.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 2880: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=347.0, train_loss_epoch=421.0]Epoch 80: Lr: 0.0002902 | Train Loss: 420.6253052 | Vali Loss: 0.6515905\n",
      "Epoch 80: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=347.0, train_loss_epoch=413.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80, global step 2916: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=356.0, train_loss_epoch=413.0]Epoch 81: Lr: 0.0002951 | Train Loss: 412.6735535 | Vali Loss: 0.6331356\n",
      "Epoch 81: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=356.0, train_loss_epoch=405.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81, global step 2952: 'val_loss' reached 0.63314 (best 0.63314), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=81-val_loss=0.633.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=372.0, train_loss_epoch=405.0]Epoch 82: Lr: 0.0003001 | Train Loss: 405.0680237 | Vali Loss: 0.6304583\n",
      "Epoch 82: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=372.0, train_loss_epoch=398.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82, global step 2988: 'val_loss' reached 0.63046 (best 0.63046), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=82-val_loss=0.630.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=305.0, train_loss_epoch=398.0]Epoch 83: Lr: 0.0003050 | Train Loss: 397.7455750 | Vali Loss: 0.6275688\n",
      "Epoch 83: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=305.0, train_loss_epoch=391.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83, global step 3024: 'val_loss' reached 0.62757 (best 0.62757), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=83-val_loss=0.628.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=415.0, train_loss_epoch=391.0]Epoch 84: Lr: 0.0003100 | Train Loss: 390.6621094 | Vali Loss: 56.7255249\n",
      "Epoch 84: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=415.0, train_loss_epoch=399.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84, global step 3060: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=357.0, train_loss_epoch=399.0]Epoch 85: Lr: 0.0003149 | Train Loss: 399.2059937 | Vali Loss: 0.6406831\n",
      "Epoch 85: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=357.0, train_loss_epoch=383.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85, global step 3096: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=373.0, train_loss_epoch=383.0]Epoch 86: Lr: 0.0003198 | Train Loss: 382.9729614 | Vali Loss: 0.5644261\n",
      "Epoch 86: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=373.0, train_loss_epoch=373.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86, global step 3132: 'val_loss' reached 0.56443 (best 0.56443), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=86-val_loss=0.564.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=349.0, train_loss_epoch=373.0]Epoch 87: Lr: 0.0003246 | Train Loss: 372.7109375 | Vali Loss: 0.5677854\n",
      "Epoch 87: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=349.0, train_loss_epoch=367.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87, global step 3168: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=371.0, train_loss_epoch=367.0]Epoch 88: Lr: 0.0003294 | Train Loss: 366.5860291 | Vali Loss: 0.5571511\n",
      "Epoch 88: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=371.0, train_loss_epoch=361.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88, global step 3204: 'val_loss' reached 0.55715 (best 0.55715), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=88-val_loss=0.557.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=355.0, train_loss_epoch=361.0]Epoch 89: Lr: 0.0003342 | Train Loss: 360.7468872 | Vali Loss: 0.5372069\n",
      "Epoch 89: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=355.0, train_loss_epoch=354.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 3240: 'val_loss' reached 0.53721 (best 0.53721), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=89-val_loss=0.537.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=311.0, train_loss_epoch=354.0]Epoch 90: Lr: 0.0003390 | Train Loss: 354.2897034 | Vali Loss: 0.5413479\n",
      "Epoch 90: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=311.0, train_loss_epoch=348.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90, global step 3276: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=311.0, train_loss_epoch=348.0]Epoch 91: Lr: 0.0003437 | Train Loss: 348.2599487 | Vali Loss: 0.5119030\n",
      "Epoch 91: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=311.0, train_loss_epoch=343.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91, global step 3312: 'val_loss' reached 0.51190 (best 0.51190), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=91-val_loss=0.512.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=344.0, train_loss_epoch=343.0]Epoch 92: Lr: 0.0003484 | Train Loss: 342.6967163 | Vali Loss: 0.5248146\n",
      "Epoch 92: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=344.0, train_loss_epoch=337.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92, global step 3348: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=298.0, train_loss_epoch=337.0]Epoch 93: Lr: 0.0003531 | Train Loss: 337.3311768 | Vali Loss: 0.5149075\n",
      "Epoch 93: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=298.0, train_loss_epoch=332.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93, global step 3384: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 36/36 [00:07<00:00,  4.57it/s, v_num=9, train_loss_step=310.0, train_loss_epoch=332.0]Epoch 94: Lr: 0.0003577 | Train Loss: 332.3306274 | Vali Loss: 0.5233652\n",
      "Epoch 94: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=310.0, train_loss_epoch=327.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94, global step 3420: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=334.0, train_loss_epoch=327.0]Epoch 95: Lr: 0.0003623 | Train Loss: 327.2456055 | Vali Loss: 0.5402958\n",
      "Epoch 95: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=334.0, train_loss_epoch=322.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95, global step 3456: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=319.0, train_loss_epoch=322.0]Epoch 96: Lr: 0.0003668 | Train Loss: 322.4185181 | Vali Loss: 0.5168498\n",
      "Epoch 96: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=319.0, train_loss_epoch=318.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96, global step 3492: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=266.0, train_loss_epoch=318.0]Epoch 97: Lr: 0.0003713 | Train Loss: 317.8392029 | Vali Loss: 0.4903596\n",
      "Epoch 97: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=266.0, train_loss_epoch=313.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97, global step 3528: 'val_loss' reached 0.49036 (best 0.49036), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=97-val_loss=0.490.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=294.0, train_loss_epoch=313.0]Epoch 98: Lr: 0.0003757 | Train Loss: 313.2059631 | Vali Loss: 0.5856721\n",
      "Epoch 98: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=294.0, train_loss_epoch=309.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98, global step 3564: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=295.0, train_loss_epoch=309.0]Epoch 99: Lr: 0.0003801 | Train Loss: 308.7407837 | Vali Loss: 0.4403824\n",
      "Epoch 99: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=295.0, train_loss_epoch=304.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 3600: 'val_loss' reached 0.44038 (best 0.44038), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=99-val_loss=0.440.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=314.0, train_loss_epoch=304.0]Epoch 100: Lr: 0.0003844 | Train Loss: 304.4004211 | Vali Loss: 0.4797941\n",
      "Epoch 100: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=314.0, train_loss_epoch=300.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100, global step 3636: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=270.0, train_loss_epoch=300.0]Epoch 101: Lr: 0.0003887 | Train Loss: 300.1551514 | Vali Loss: 0.4630109\n",
      "Epoch 101: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=270.0, train_loss_epoch=296.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101, global step 3672: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=281.0, train_loss_epoch=296.0]Epoch 102: Lr: 0.0003929 | Train Loss: 296.4859009 | Vali Loss: 0.4704312\n",
      "Epoch 102: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=281.0, train_loss_epoch=292.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102, global step 3708: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=281.0, train_loss_epoch=292.0]Epoch 103: Lr: 0.0003971 | Train Loss: 292.3195801 | Vali Loss: 0.4460809\n",
      "Epoch 103: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=281.0, train_loss_epoch=288.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103, global step 3744: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=293.0, train_loss_epoch=288.0]Epoch 104: Lr: 0.0004011 | Train Loss: 288.4659729 | Vali Loss: 0.4382509\n",
      "Epoch 104: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=293.0, train_loss_epoch=285.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104, global step 3780: 'val_loss' reached 0.43825 (best 0.43825), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=104-val_loss=0.438.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=271.0, train_loss_epoch=285.0]Epoch 105: Lr: 0.0004052 | Train Loss: 284.7089233 | Vali Loss: 0.4238253\n",
      "Epoch 105: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=271.0, train_loss_epoch=281.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105, global step 3816: 'val_loss' reached 0.42383 (best 0.42383), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=105-val_loss=0.424.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=271.0, train_loss_epoch=281.0]Epoch 106: Lr: 0.0004092 | Train Loss: 281.3332825 | Vali Loss: 0.4504611\n",
      "Epoch 106: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=271.0, train_loss_epoch=278.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106, global step 3852: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=265.0, train_loss_epoch=278.0]Epoch 107: Lr: 0.0004131 | Train Loss: 278.1677856 | Vali Loss: 0.4160686\n",
      "Epoch 107: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=265.0, train_loss_epoch=274.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107, global step 3888: 'val_loss' reached 0.41607 (best 0.41607), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=107-val_loss=0.416.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=317.0, train_loss_epoch=274.0]Epoch 108: Lr: 0.0004169 | Train Loss: 274.1730347 | Vali Loss: 1038.9373779\n",
      "Epoch 108: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=317.0, train_loss_epoch=282.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108, global step 3924: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=324.0, train_loss_epoch=282.0]Epoch 109: Lr: 0.0004207 | Train Loss: 282.1254883 | Vali Loss: 106.5318069\n",
      "Epoch 109: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=324.0, train_loss_epoch=303.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 3960: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=258.0, train_loss_epoch=303.0]Epoch 110: Lr: 0.0004244 | Train Loss: 303.0041199 | Vali Loss: 0.6210595\n",
      "Epoch 110: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=258.0, train_loss_epoch=276.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110, global step 3996: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=242.0, train_loss_epoch=276.0]Epoch 111: Lr: 0.0004280 | Train Loss: 276.0495300 | Vali Loss: 0.4975435\n",
      "Epoch 111: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=242.0, train_loss_epoch=266.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111, global step 4032: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=276.0, train_loss_epoch=266.0]Epoch 112: Lr: 0.0004315 | Train Loss: 265.9662781 | Vali Loss: 0.6357919\n",
      "Epoch 112: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=276.0, train_loss_epoch=262.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112, global step 4068: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=253.0, train_loss_epoch=262.0]Epoch 113: Lr: 0.0004350 | Train Loss: 262.0184631 | Vali Loss: 0.5260567\n",
      "Epoch 113: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=253.0, train_loss_epoch=259.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113, global step 4104: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=242.0, train_loss_epoch=259.0]Epoch 114: Lr: 0.0004384 | Train Loss: 258.6508484 | Vali Loss: 0.5200179\n",
      "Epoch 114: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=242.0, train_loss_epoch=256.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114, global step 4140: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=250.0, train_loss_epoch=256.0]Epoch 115: Lr: 0.0004417 | Train Loss: 255.5097809 | Vali Loss: 0.5585519\n",
      "Epoch 115: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=250.0, train_loss_epoch=252.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115, global step 4176: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=262.0, train_loss_epoch=252.0]Epoch 116: Lr: 0.0004450 | Train Loss: 252.2245636 | Vali Loss: 0.5329728\n",
      "Epoch 116: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=262.0, train_loss_epoch=249.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116, global step 4212: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=261.0, train_loss_epoch=249.0]Epoch 117: Lr: 0.0004482 | Train Loss: 249.0240479 | Vali Loss: 0.5376127\n",
      "Epoch 117: 100%|██████████| 36/36 [00:08<00:00,  4.07it/s, v_num=9, train_loss_step=261.0, train_loss_epoch=246.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117, global step 4248: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=240.0, train_loss_epoch=246.0]Epoch 118: Lr: 0.0004512 | Train Loss: 246.2115936 | Vali Loss: 0.5311713\n",
      "Epoch 118: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=240.0, train_loss_epoch=244.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118, global step 4284: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=242.0, train_loss_epoch=244.0]Epoch 119: Lr: 0.0004542 | Train Loss: 243.6979218 | Vali Loss: 0.5001305\n",
      "Epoch 119: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=242.0, train_loss_epoch=241.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 4320: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=219.0, train_loss_epoch=241.0]Epoch 120: Lr: 0.0004571 | Train Loss: 240.5479431 | Vali Loss: 0.5709220\n",
      "Epoch 120: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=219.0, train_loss_epoch=238.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120, global step 4356: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=229.0, train_loss_epoch=238.0]Epoch 121: Lr: 0.0004600 | Train Loss: 238.0089417 | Vali Loss: 0.4655822\n",
      "Epoch 121: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=229.0, train_loss_epoch=235.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121, global step 4392: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=226.0, train_loss_epoch=235.0]Epoch 122: Lr: 0.0004627 | Train Loss: 234.8843384 | Vali Loss: 0.3628599\n",
      "Epoch 122: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=226.0, train_loss_epoch=233.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122, global step 4428: 'val_loss' reached 0.36286 (best 0.36286), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=122-val_loss=0.363.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=223.0, train_loss_epoch=233.0]Epoch 123: Lr: 0.0004653 | Train Loss: 232.9562531 | Vali Loss: 0.3792112\n",
      "Epoch 123: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=223.0, train_loss_epoch=232.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123, global step 4464: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=213.0, train_loss_epoch=232.0]Epoch 124: Lr: 0.0004679 | Train Loss: 231.7134094 | Vali Loss: 0.3671491\n",
      "Epoch 124: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=213.0, train_loss_epoch=229.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124, global step 4500: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=234.0, train_loss_epoch=229.0]Epoch 125: Lr: 0.0004704 | Train Loss: 229.0208740 | Vali Loss: 0.5017527\n",
      "Epoch 125: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=234.0, train_loss_epoch=226.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125, global step 4536: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=227.0, train_loss_epoch=226.0]Epoch 126: Lr: 0.0004727 | Train Loss: 226.4492035 | Vali Loss: 0.3539775\n",
      "Epoch 126: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=227.0, train_loss_epoch=227.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126, global step 4572: 'val_loss' reached 0.35398 (best 0.35398), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=126-val_loss=0.354.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=207.0, train_loss_epoch=227.0]Epoch 127: Lr: 0.0004750 | Train Loss: 226.5273590 | Vali Loss: 0.3389767\n",
      "Epoch 127: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=207.0, train_loss_epoch=220.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127, global step 4608: 'val_loss' reached 0.33898 (best 0.33898), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=127-val_loss=0.339.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=216.0, train_loss_epoch=220.0]Epoch 128: Lr: 0.0004772 | Train Loss: 220.0791626 | Vali Loss: 0.3361773\n",
      "Epoch 128: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=216.0, train_loss_epoch=217.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128, global step 4644: 'val_loss' reached 0.33618 (best 0.33618), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=128-val_loss=0.336.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=204.0, train_loss_epoch=217.0]Epoch 129: Lr: 0.0004793 | Train Loss: 217.3419342 | Vali Loss: 0.3711783\n",
      "Epoch 129: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=204.0, train_loss_epoch=215.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 4680: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=203.0, train_loss_epoch=215.0]Epoch 130: Lr: 0.0004813 | Train Loss: 214.6546478 | Vali Loss: 0.3464747\n",
      "Epoch 130: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=203.0, train_loss_epoch=213.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130, global step 4716: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=203.0, train_loss_epoch=213.0]Epoch 131: Lr: 0.0004832 | Train Loss: 212.5784760 | Vali Loss: 0.3299116\n",
      "Epoch 131: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=203.0, train_loss_epoch=210.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131, global step 4752: 'val_loss' reached 0.32991 (best 0.32991), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=131-val_loss=0.330.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=191.0, train_loss_epoch=210.0]Epoch 132: Lr: 0.0004850 | Train Loss: 209.9294434 | Vali Loss: 0.3245839\n",
      "Epoch 132: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=191.0, train_loss_epoch=207.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132, global step 4788: 'val_loss' reached 0.32458 (best 0.32458), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=132-val_loss=0.325.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=198.0, train_loss_epoch=207.0]Epoch 133: Lr: 0.0004867 | Train Loss: 207.2811432 | Vali Loss: 0.3055064\n",
      "Epoch 133: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=198.0, train_loss_epoch=205.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133, global step 4824: 'val_loss' reached 0.30551 (best 0.30551), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=133-val_loss=0.306.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=214.0, train_loss_epoch=205.0]Epoch 134: Lr: 0.0004883 | Train Loss: 205.0433655 | Vali Loss: 0.3265589\n",
      "Epoch 134: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=214.0, train_loss_epoch=203.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134, global step 4860: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=203.0, train_loss_epoch=203.0]Epoch 135: Lr: 0.0004898 | Train Loss: 202.8415222 | Vali Loss: 0.3019145\n",
      "Epoch 135: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=203.0, train_loss_epoch=201.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135, global step 4896: 'val_loss' reached 0.30191 (best 0.30191), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=135-val_loss=0.302.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=189.0, train_loss_epoch=201.0]Epoch 136: Lr: 0.0004912 | Train Loss: 200.5176239 | Vali Loss: 0.2821144\n",
      "Epoch 136: 100%|██████████| 36/36 [00:08<00:00,  4.07it/s, v_num=9, train_loss_step=189.0, train_loss_epoch=198.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136, global step 4932: 'val_loss' reached 0.28211 (best 0.28211), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=136-val_loss=0.282.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137: 100%|██████████| 36/36 [00:08<00:00,  4.49it/s, v_num=9, train_loss_step=182.0, train_loss_epoch=198.0]Epoch 137: Lr: 0.0004925 | Train Loss: 198.1934052 | Vali Loss: 0.2885353\n",
      "Epoch 137: 100%|██████████| 36/36 [00:09<00:00,  3.98it/s, v_num=9, train_loss_step=182.0, train_loss_epoch=197.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137, global step 4968: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=206.0, train_loss_epoch=197.0]Epoch 138: Lr: 0.0004937 | Train Loss: 196.5762177 | Vali Loss: 0.2669765\n",
      "Epoch 138: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=206.0, train_loss_epoch=194.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138, global step 5004: 'val_loss' reached 0.26698 (best 0.26698), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=138-val_loss=0.267.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=174.0, train_loss_epoch=194.0]Epoch 139: Lr: 0.0004948 | Train Loss: 194.1396332 | Vali Loss: 0.2720631\n",
      "Epoch 139: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=174.0, train_loss_epoch=192.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 5040: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=208.0, train_loss_epoch=192.0]Epoch 140: Lr: 0.0004958 | Train Loss: 191.8422699 | Vali Loss: 0.2726557\n",
      "Epoch 140: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=208.0, train_loss_epoch=190.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140, global step 5076: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=179.0, train_loss_epoch=190.0]Epoch 141: Lr: 0.0004967 | Train Loss: 190.0587463 | Vali Loss: 0.2691056\n",
      "Epoch 141: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=179.0, train_loss_epoch=188.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141, global step 5112: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=187.0, train_loss_epoch=188.0]Epoch 142: Lr: 0.0004974 | Train Loss: 187.7778168 | Vali Loss: 0.2635335\n",
      "Epoch 142: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=187.0, train_loss_epoch=186.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142, global step 5148: 'val_loss' reached 0.26353 (best 0.26353), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=142-val_loss=0.264.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=174.0, train_loss_epoch=186.0]Epoch 143: Lr: 0.0004981 | Train Loss: 185.8775635 | Vali Loss: 0.2701572\n",
      "Epoch 143: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=174.0, train_loss_epoch=184.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143, global step 5184: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=349.0, train_loss_epoch=184.0]Epoch 144: Lr: 0.0004987 | Train Loss: 183.7612152 | Vali Loss: 973.2905884\n",
      "Epoch 144: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=349.0, train_loss_epoch=197.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144, global step 5220: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=268.0, train_loss_epoch=197.0]Epoch 145: Lr: 0.0004992 | Train Loss: 196.6705475 | Vali Loss: 740.3150024\n",
      "Epoch 145: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=268.0, train_loss_epoch=240.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145, global step 5256: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=194.0, train_loss_epoch=240.0]Epoch 146: Lr: 0.0004995 | Train Loss: 239.9124298 | Vali Loss: 0.6896570\n",
      "Epoch 146: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=194.0, train_loss_epoch=206.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146, global step 5292: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=171.0, train_loss_epoch=206.0]Epoch 147: Lr: 0.0004998 | Train Loss: 205.6413574 | Vali Loss: 0.5154313\n",
      "Epoch 147: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=171.0, train_loss_epoch=185.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147, global step 5328: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=163.0, train_loss_epoch=185.0]Epoch 148: Lr: 0.0005000 | Train Loss: 184.8099823 | Vali Loss: 0.4016939\n",
      "Epoch 148: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=163.0, train_loss_epoch=181.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148, global step 5364: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=171.0, train_loss_epoch=181.0]Epoch 149: Lr: 0.0005000 | Train Loss: 180.7881470 | Vali Loss: 0.4605759\n",
      "Epoch 149: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=171.0, train_loss_epoch=178.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 5400: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=192.0, train_loss_epoch=178.0]Epoch 150: Lr: 0.0005000 | Train Loss: 178.2797546 | Vali Loss: 0.3597318\n",
      "Epoch 150: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=192.0, train_loss_epoch=176.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150, global step 5436: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=167.0, train_loss_epoch=176.0]Epoch 151: Lr: 0.0005000 | Train Loss: 175.9211731 | Vali Loss: 0.4124933\n",
      "Epoch 151: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=167.0, train_loss_epoch=174.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151, global step 5472: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=177.0, train_loss_epoch=174.0]Epoch 152: Lr: 0.0004999 | Train Loss: 174.0194244 | Vali Loss: 0.3328737\n",
      "Epoch 152: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=177.0, train_loss_epoch=172.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152, global step 5508: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=169.0, train_loss_epoch=172.0]Epoch 153: Lr: 0.0004998 | Train Loss: 172.0044861 | Vali Loss: 0.4276572\n",
      "Epoch 153: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=169.0, train_loss_epoch=170.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153, global step 5544: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=160.0, train_loss_epoch=170.0]Epoch 154: Lr: 0.0004997 | Train Loss: 170.1414337 | Vali Loss: 0.3526090\n",
      "Epoch 154: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=160.0, train_loss_epoch=169.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154, global step 5580: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=166.0, train_loss_epoch=169.0]Epoch 155: Lr: 0.0004996 | Train Loss: 168.5630341 | Vali Loss: 0.3041318\n",
      "Epoch 155: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=166.0, train_loss_epoch=170.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155, global step 5616: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=158.0, train_loss_epoch=170.0]Epoch 156: Lr: 0.0004995 | Train Loss: 169.8537903 | Vali Loss: 0.3571028\n",
      "Epoch 156: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=158.0, train_loss_epoch=166.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156, global step 5652: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=166.0, train_loss_epoch=166.0]Epoch 157: Lr: 0.0004994 | Train Loss: 166.3917999 | Vali Loss: 0.2795721\n",
      "Epoch 157: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=166.0, train_loss_epoch=165.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157, global step 5688: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=171.0, train_loss_epoch=165.0]Epoch 158: Lr: 0.0004992 | Train Loss: 164.8508301 | Vali Loss: 2.2769308\n",
      "Epoch 158: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=171.0, train_loss_epoch=171.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158, global step 5724: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=176.0, train_loss_epoch=171.0]Epoch 159: Lr: 0.0004990 | Train Loss: 171.1515961 | Vali Loss: 0.6914014\n",
      "Epoch 159: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=176.0, train_loss_epoch=175.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 5760: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=168.0, train_loss_epoch=175.0]Epoch 160: Lr: 0.0004988 | Train Loss: 175.3863068 | Vali Loss: 0.3916764\n",
      "Epoch 160: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=168.0, train_loss_epoch=163.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160, global step 5796: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=154.0, train_loss_epoch=163.0]Epoch 161: Lr: 0.0004985 | Train Loss: 163.0551910 | Vali Loss: 0.3237715\n",
      "Epoch 161: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=154.0, train_loss_epoch=160.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161, global step 5832: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=167.0, train_loss_epoch=160.0]Epoch 162: Lr: 0.0004983 | Train Loss: 159.6845551 | Vali Loss: 0.3619849\n",
      "Epoch 162: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=167.0, train_loss_epoch=158.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162, global step 5868: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=143.0, train_loss_epoch=158.0]Epoch 163: Lr: 0.0004980 | Train Loss: 157.9153595 | Vali Loss: 0.3115142\n",
      "Epoch 163: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=143.0, train_loss_epoch=156.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163, global step 5904: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=152.0, train_loss_epoch=156.0]Epoch 164: Lr: 0.0004977 | Train Loss: 155.9254913 | Vali Loss: 0.3283550\n",
      "Epoch 164: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=152.0, train_loss_epoch=154.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164, global step 5940: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=153.0, train_loss_epoch=154.0]Epoch 165: Lr: 0.0004974 | Train Loss: 154.4889832 | Vali Loss: 0.3086665\n",
      "Epoch 165: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=153.0, train_loss_epoch=153.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165, global step 5976: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=159.0, train_loss_epoch=153.0]Epoch 166: Lr: 0.0004971 | Train Loss: 152.8786011 | Vali Loss: 0.2932526\n",
      "Epoch 166: 100%|██████████| 36/36 [00:08<00:00,  4.07it/s, v_num=9, train_loss_step=159.0, train_loss_epoch=151.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166, global step 6012: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=147.0, train_loss_epoch=151.0]Epoch 167: Lr: 0.0004967 | Train Loss: 151.4613647 | Vali Loss: 0.2760855\n",
      "Epoch 167: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=147.0, train_loss_epoch=150.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167, global step 6048: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=147.0, train_loss_epoch=150.0]Epoch 168: Lr: 0.0004964 | Train Loss: 149.7336426 | Vali Loss: 0.2879204\n",
      "Epoch 168: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=147.0, train_loss_epoch=148.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168, global step 6084: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=158.0, train_loss_epoch=148.0]Epoch 169: Lr: 0.0004960 | Train Loss: 148.3903046 | Vali Loss: 0.2746331\n",
      "Epoch 169: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=158.0, train_loss_epoch=147.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 6120: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=145.0, train_loss_epoch=147.0]Epoch 170: Lr: 0.0004956 | Train Loss: 146.8226318 | Vali Loss: 0.2858436\n",
      "Epoch 170: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=145.0, train_loss_epoch=146.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170, global step 6156: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=163.0, train_loss_epoch=146.0]Epoch 171: Lr: 0.0004951 | Train Loss: 145.6192017 | Vali Loss: 0.2579617\n",
      "Epoch 171: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=163.0, train_loss_epoch=145.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 171, global step 6192: 'val_loss' reached 0.25796 (best 0.25796), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=171-val_loss=0.258.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172: 100%|██████████| 36/36 [00:07<00:00,  4.53it/s, v_num=9, train_loss_step=128.0, train_loss_epoch=145.0]Epoch 172: Lr: 0.0004947 | Train Loss: 145.1800385 | Vali Loss: 0.2731974\n",
      "Epoch 172: 100%|██████████| 36/36 [00:08<00:00,  4.02it/s, v_num=9, train_loss_step=128.0, train_loss_epoch=143.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 172, global step 6228: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=140.0, train_loss_epoch=143.0]Epoch 173: Lr: 0.0004942 | Train Loss: 142.9047241 | Vali Loss: 0.2654136\n",
      "Epoch 173: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=140.0, train_loss_epoch=142.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 173, global step 6264: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=130.0, train_loss_epoch=142.0]Epoch 174: Lr: 0.0004937 | Train Loss: 141.5480194 | Vali Loss: 0.2714550\n",
      "Epoch 174: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=130.0, train_loss_epoch=141.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 174, global step 6300: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=140.0, train_loss_epoch=141.0]Epoch 175: Lr: 0.0004932 | Train Loss: 140.5863647 | Vali Loss: 0.2808799\n",
      "Epoch 175: 100%|██████████| 36/36 [00:08<00:00,  4.05it/s, v_num=9, train_loss_step=140.0, train_loss_epoch=139.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 175, global step 6336: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=133.0, train_loss_epoch=139.0]Epoch 176: Lr: 0.0004927 | Train Loss: 139.4954071 | Vali Loss: 0.2835166\n",
      "Epoch 176: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=133.0, train_loss_epoch=138.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 176, global step 6372: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=125.0, train_loss_epoch=138.0]Epoch 177: Lr: 0.0004921 | Train Loss: 137.9098053 | Vali Loss: 0.2738514\n",
      "Epoch 177: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=125.0, train_loss_epoch=136.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177, global step 6408: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=136.0, train_loss_epoch=136.0]Epoch 178: Lr: 0.0004916 | Train Loss: 135.8978577 | Vali Loss: 0.2554083\n",
      "Epoch 178: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=136.0, train_loss_epoch=135.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 178, global step 6444: 'val_loss' reached 0.25541 (best 0.25541), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=178-val_loss=0.255.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=147.0, train_loss_epoch=135.0]Epoch 179: Lr: 0.0004910 | Train Loss: 134.6660614 | Vali Loss: 0.2605095\n",
      "Epoch 179: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=147.0, train_loss_epoch=133.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 6480: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=130.0, train_loss_epoch=133.0]Epoch 180: Lr: 0.0004904 | Train Loss: 133.4376373 | Vali Loss: 0.2765371\n",
      "Epoch 180: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=130.0, train_loss_epoch=132.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 180, global step 6516: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=123.0, train_loss_epoch=132.0]Epoch 181: Lr: 0.0004897 | Train Loss: 132.4255371 | Vali Loss: 0.2702715\n",
      "Epoch 181: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=123.0, train_loss_epoch=131.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 181, global step 6552: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=136.0, train_loss_epoch=131.0]Epoch 182: Lr: 0.0004891 | Train Loss: 131.2805481 | Vali Loss: 0.2543581\n",
      "Epoch 182: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=136.0, train_loss_epoch=130.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 182, global step 6588: 'val_loss' reached 0.25436 (best 0.25436), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=182-val_loss=0.254.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=122.0, train_loss_epoch=130.0]Epoch 183: Lr: 0.0004884 | Train Loss: 129.5516663 | Vali Loss: 0.2396627\n",
      "Epoch 183: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=122.0, train_loss_epoch=128.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 183, global step 6624: 'val_loss' reached 0.23966 (best 0.23966), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=183-val_loss=0.240.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=112.0, train_loss_epoch=128.0]Epoch 184: Lr: 0.0004877 | Train Loss: 128.4941559 | Vali Loss: 0.2443471\n",
      "Epoch 184: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=112.0, train_loss_epoch=128.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 184, global step 6660: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=126.0, train_loss_epoch=128.0]Epoch 185: Lr: 0.0004870 | Train Loss: 127.8119354 | Vali Loss: 0.2448570\n",
      "Epoch 185: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=126.0, train_loss_epoch=126.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185, global step 6696: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=122.0, train_loss_epoch=126.0]Epoch 186: Lr: 0.0004863 | Train Loss: 126.2389755 | Vali Loss: 0.2465854\n",
      "Epoch 186: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=122.0, train_loss_epoch=126.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 186, global step 6732: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=126.0, train_loss_epoch=126.0]Epoch 187: Lr: 0.0004856 | Train Loss: 125.7950516 | Vali Loss: 0.2333824\n",
      "Epoch 187: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=126.0, train_loss_epoch=124.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 187, global step 6768: 'val_loss' reached 0.23338 (best 0.23338), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=187-val_loss=0.233.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=126.0, train_loss_epoch=124.0]Epoch 188: Lr: 0.0004848 | Train Loss: 124.0943146 | Vali Loss: 0.2553555\n",
      "Epoch 188: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=126.0, train_loss_epoch=122.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 188, global step 6804: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=122.0]Epoch 189: Lr: 0.0004840 | Train Loss: 122.4916687 | Vali Loss: 0.2438476\n",
      "Epoch 189: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=121.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 6840: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=124.0, train_loss_epoch=121.0]Epoch 190: Lr: 0.0004832 | Train Loss: 121.2786865 | Vali Loss: 0.2585530\n",
      "Epoch 190: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=124.0, train_loss_epoch=121.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 190, global step 6876: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=111.0, train_loss_epoch=121.0]Epoch 191: Lr: 0.0004824 | Train Loss: 121.1966705 | Vali Loss: 0.2595113\n",
      "Epoch 191: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=111.0, train_loss_epoch=119.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 191, global step 6912: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=114.0, train_loss_epoch=119.0]Epoch 192: Lr: 0.0004816 | Train Loss: 119.3107758 | Vali Loss: 0.2299694\n",
      "Epoch 192: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=114.0, train_loss_epoch=118.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 192, global step 6948: 'val_loss' reached 0.22997 (best 0.22997), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=192-val_loss=0.230.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=118.0]Epoch 193: Lr: 0.0004807 | Train Loss: 118.2248993 | Vali Loss: 0.2352777\n",
      "Epoch 193: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=117.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193, global step 6984: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=116.0, train_loss_epoch=117.0]Epoch 194: Lr: 0.0004799 | Train Loss: 117.1457596 | Vali Loss: 0.2544602\n",
      "Epoch 194: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=116.0, train_loss_epoch=116.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 194, global step 7020: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=111.0, train_loss_epoch=116.0]Epoch 195: Lr: 0.0004790 | Train Loss: 115.9852295 | Vali Loss: 0.2614696\n",
      "Epoch 195: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=111.0, train_loss_epoch=115.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 195, global step 7056: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=121.0, train_loss_epoch=115.0]Epoch 196: Lr: 0.0004781 | Train Loss: 114.8192368 | Vali Loss: 0.2707410\n",
      "Epoch 196: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=121.0, train_loss_epoch=114.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 196, global step 7092: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=106.0, train_loss_epoch=114.0]Epoch 197: Lr: 0.0004771 | Train Loss: 114.3936768 | Vali Loss: 0.2490469\n",
      "Epoch 197: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=106.0, train_loss_epoch=113.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 197, global step 7128: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=106.0, train_loss_epoch=113.0]Epoch 198: Lr: 0.0004762 | Train Loss: 112.9295807 | Vali Loss: 0.2399546\n",
      "Epoch 198: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=106.0, train_loss_epoch=112.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 198, global step 7164: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=112.0]Epoch 199: Lr: 0.0004752 | Train Loss: 111.8224640 | Vali Loss: 0.2379640\n",
      "Epoch 199: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=111.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 7200: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=113.0, train_loss_epoch=111.0]Epoch 200: Lr: 0.0004742 | Train Loss: 111.3498611 | Vali Loss: 0.2510787\n",
      "Epoch 200: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=113.0, train_loss_epoch=110.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200, global step 7236: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=95.80, train_loss_epoch=110.0]Epoch 201: Lr: 0.0004732 | Train Loss: 110.1452332 | Vali Loss: 0.2304401\n",
      "Epoch 201: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=95.80, train_loss_epoch=110.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201, global step 7272: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=110.0]Epoch 202: Lr: 0.0004722 | Train Loss: 109.7616730 | Vali Loss: 0.2243497\n",
      "Epoch 202: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=108.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 202, global step 7308: 'val_loss' reached 0.22435 (best 0.22435), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=202-val_loss=0.224.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=105.0, train_loss_epoch=108.0]Epoch 203: Lr: 0.0004712 | Train Loss: 108.4126053 | Vali Loss: 0.2260863\n",
      "Epoch 203: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=105.0, train_loss_epoch=108.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 203, global step 7344: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=103.0, train_loss_epoch=108.0]Epoch 204: Lr: 0.0004701 | Train Loss: 107.6242523 | Vali Loss: 0.2466377\n",
      "Epoch 204: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=103.0, train_loss_epoch=107.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 204, global step 7380: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=107.0]Epoch 205: Lr: 0.0004690 | Train Loss: 106.6779404 | Vali Loss: 0.2740367\n",
      "Epoch 205: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=106.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 205, global step 7416: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=106.0]Epoch 206: Lr: 0.0004680 | Train Loss: 106.4364777 | Vali Loss: 0.2430301\n",
      "Epoch 206: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=105.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 206, global step 7452: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=106.0, train_loss_epoch=105.0]Epoch 207: Lr: 0.0004668 | Train Loss: 104.9861984 | Vali Loss: 0.2390470\n",
      "Epoch 207: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=106.0, train_loss_epoch=104.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 207, global step 7488: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=116.0, train_loss_epoch=104.0]Epoch 208: Lr: 0.0004657 | Train Loss: 104.3131714 | Vali Loss: 0.2466561\n",
      "Epoch 208: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=116.0, train_loss_epoch=104.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 208, global step 7524: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=110.0, train_loss_epoch=104.0]Epoch 209: Lr: 0.0004646 | Train Loss: 103.9197845 | Vali Loss: 0.2414915\n",
      "Epoch 209: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=110.0, train_loss_epoch=104.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 7560: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=104.0]Epoch 210: Lr: 0.0004634 | Train Loss: 103.9847107 | Vali Loss: 0.2106871\n",
      "Epoch 210: 100%|██████████| 36/36 [00:08<00:00,  4.07it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=102.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 210, global step 7596: 'val_loss' reached 0.21069 (best 0.21069), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=210-val_loss=0.211.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=95.60, train_loss_epoch=102.0]Epoch 211: Lr: 0.0004622 | Train Loss: 102.0937424 | Vali Loss: 0.2123536\n",
      "Epoch 211: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=95.60, train_loss_epoch=101.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 211, global step 7632: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=101.0]Epoch 212: Lr: 0.0004610 | Train Loss: 101.1554260 | Vali Loss: 0.2314325\n",
      "Epoch 212: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=109.0, train_loss_epoch=101.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 212, global step 7668: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=113.0, train_loss_epoch=101.0]Epoch 213: Lr: 0.0004598 | Train Loss: 100.8600159 | Vali Loss: 0.2239056\n",
      "Epoch 213: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=113.0, train_loss_epoch=99.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 213, global step 7704: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=101.0, train_loss_epoch=99.90]Epoch 214: Lr: 0.0004586 | Train Loss: 99.9140320 | Vali Loss: 0.2212464\n",
      "Epoch 214: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=101.0, train_loss_epoch=99.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 214, global step 7740: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215: 100%|██████████| 36/36 [00:08<00:00,  4.42it/s, v_num=9, train_loss_step=103.0, train_loss_epoch=99.30]Epoch 215: Lr: 0.0004574 | Train Loss: 99.2990417 | Vali Loss: 0.2203635\n",
      "Epoch 215: 100%|██████████| 36/36 [00:09<00:00,  3.91it/s, v_num=9, train_loss_step=103.0, train_loss_epoch=99.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 215, global step 7776: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=100.0, train_loss_epoch=99.30]Epoch 216: Lr: 0.0004561 | Train Loss: 99.3048248 | Vali Loss: 0.2197496\n",
      "Epoch 216: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=100.0, train_loss_epoch=98.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 216, global step 7812: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=98.10]Epoch 217: Lr: 0.0004548 | Train Loss: 98.1439667 | Vali Loss: 0.2169725\n",
      "Epoch 217: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=108.0, train_loss_epoch=97.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 217, global step 7848: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=98.10, train_loss_epoch=97.10]Epoch 218: Lr: 0.0004535 | Train Loss: 97.1221161 | Vali Loss: 0.2743071\n",
      "Epoch 218: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=98.10, train_loss_epoch=96.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 218, global step 7884: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=90.20, train_loss_epoch=96.30]Epoch 219: Lr: 0.0004522 | Train Loss: 96.3464813 | Vali Loss: 0.2276764\n",
      "Epoch 219: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=90.20, train_loss_epoch=96.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 7920: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=102.0, train_loss_epoch=96.10]Epoch 220: Lr: 0.0004509 | Train Loss: 96.0708008 | Vali Loss: 0.2049340\n",
      "Epoch 220: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=102.0, train_loss_epoch=95.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220, global step 7956: 'val_loss' reached 0.20493 (best 0.20493), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=220-val_loss=0.205.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=102.0, train_loss_epoch=95.60]Epoch 221: Lr: 0.0004495 | Train Loss: 95.5641632 | Vali Loss: 0.2368719\n",
      "Epoch 221: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=102.0, train_loss_epoch=94.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 221, global step 7992: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=95.40, train_loss_epoch=94.90]Epoch 222: Lr: 0.0004482 | Train Loss: 94.8786469 | Vali Loss: 0.2167327\n",
      "Epoch 222: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=95.40, train_loss_epoch=93.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 222, global step 8028: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=104.0, train_loss_epoch=93.90]Epoch 223: Lr: 0.0004468 | Train Loss: 93.8605118 | Vali Loss: 0.2291297\n",
      "Epoch 223: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=104.0, train_loss_epoch=93.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 223, global step 8064: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=95.20, train_loss_epoch=93.10]Epoch 224: Lr: 0.0004454 | Train Loss: 93.0804367 | Vali Loss: 0.2267409\n",
      "Epoch 224: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=95.20, train_loss_epoch=92.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 224, global step 8100: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=100.0, train_loss_epoch=92.70]Epoch 225: Lr: 0.0004440 | Train Loss: 92.7469101 | Vali Loss: 0.2182741\n",
      "Epoch 225: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=100.0, train_loss_epoch=92.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 225, global step 8136: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=84.70, train_loss_epoch=92.20]Epoch 226: Lr: 0.0004426 | Train Loss: 92.2231674 | Vali Loss: 0.2085699\n",
      "Epoch 226: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=84.70, train_loss_epoch=91.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 226, global step 8172: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=85.70, train_loss_epoch=91.60]Epoch 227: Lr: 0.0004412 | Train Loss: 91.6298141 | Vali Loss: 0.2146765\n",
      "Epoch 227: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=85.70, train_loss_epoch=90.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 227, global step 8208: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=96.80, train_loss_epoch=90.90]Epoch 228: Lr: 0.0004397 | Train Loss: 90.8657303 | Vali Loss: 0.2305034\n",
      "Epoch 228: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=96.80, train_loss_epoch=91.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 228, global step 8244: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=92.40, train_loss_epoch=91.60]Epoch 229: Lr: 0.0004382 | Train Loss: 91.5628357 | Vali Loss: 0.2364476\n",
      "Epoch 229: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=92.40, train_loss_epoch=90.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 8280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=76.50, train_loss_epoch=90.10]Epoch 230: Lr: 0.0004367 | Train Loss: 90.1262589 | Vali Loss: 0.2191392\n",
      "Epoch 230: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=76.50, train_loss_epoch=89.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 230, global step 8316: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=84.20, train_loss_epoch=89.10]Epoch 231: Lr: 0.0004352 | Train Loss: 89.0887070 | Vali Loss: 0.2120066\n",
      "Epoch 231: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=84.20, train_loss_epoch=88.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 231, global step 8352: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=85.80, train_loss_epoch=88.90]Epoch 232: Lr: 0.0004337 | Train Loss: 88.8939667 | Vali Loss: 0.2226135\n",
      "Epoch 232: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=85.80, train_loss_epoch=89.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 232, global step 8388: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=87.10, train_loss_epoch=89.20]Epoch 233: Lr: 0.0004322 | Train Loss: 89.2314301 | Vali Loss: 0.2121825\n",
      "Epoch 233: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=87.10, train_loss_epoch=87.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 233, global step 8424: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=74.50, train_loss_epoch=87.90]Epoch 234: Lr: 0.0004307 | Train Loss: 87.9013367 | Vali Loss: 0.2094280\n",
      "Epoch 234: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=74.50, train_loss_epoch=87.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 234, global step 8460: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=83.90, train_loss_epoch=87.70]Epoch 235: Lr: 0.0004291 | Train Loss: 87.6829224 | Vali Loss: 0.2015494\n",
      "Epoch 235: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=83.90, train_loss_epoch=86.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 235, global step 8496: 'val_loss' reached 0.20155 (best 0.20155), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=235-val_loss=0.202.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=87.80, train_loss_epoch=86.60]Epoch 236: Lr: 0.0004275 | Train Loss: 86.6299286 | Vali Loss: 0.2024904\n",
      "Epoch 236: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=87.80, train_loss_epoch=86.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 236, global step 8532: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=85.00, train_loss_epoch=86.20]Epoch 237: Lr: 0.0004259 | Train Loss: 86.2402725 | Vali Loss: 0.1955716\n",
      "Epoch 237: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=85.00, train_loss_epoch=85.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 237, global step 8568: 'val_loss' reached 0.19557 (best 0.19557), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=237-val_loss=0.196.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=91.60, train_loss_epoch=85.60]Epoch 238: Lr: 0.0004243 | Train Loss: 85.5747070 | Vali Loss: 0.2034719\n",
      "Epoch 238: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=91.60, train_loss_epoch=84.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 238, global step 8604: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=88.80, train_loss_epoch=84.90]Epoch 239: Lr: 0.0004227 | Train Loss: 84.9043503 | Vali Loss: 0.2174316\n",
      "Epoch 239: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=88.80, train_loss_epoch=84.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 8640: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=80.60, train_loss_epoch=84.70]Epoch 240: Lr: 0.0004211 | Train Loss: 84.6548309 | Vali Loss: 0.2204346\n",
      "Epoch 240: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=80.60, train_loss_epoch=84.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 240, global step 8676: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=99.10, train_loss_epoch=84.70]Epoch 241: Lr: 0.0004194 | Train Loss: 84.6697464 | Vali Loss: 0.2136253\n",
      "Epoch 241: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=99.10, train_loss_epoch=83.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241, global step 8712: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=79.60, train_loss_epoch=83.80]Epoch 242: Lr: 0.0004178 | Train Loss: 83.7963028 | Vali Loss: 0.2035721\n",
      "Epoch 242: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=79.60, train_loss_epoch=82.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 242, global step 8748: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=87.90, train_loss_epoch=82.80]Epoch 243: Lr: 0.0004161 | Train Loss: 82.8426514 | Vali Loss: 0.1940222\n",
      "Epoch 243: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=87.90, train_loss_epoch=82.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 243, global step 8784: 'val_loss' reached 0.19402 (best 0.19402), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=243-val_loss=0.194.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=85.80, train_loss_epoch=82.40]Epoch 244: Lr: 0.0004144 | Train Loss: 82.3708267 | Vali Loss: 0.2038057\n",
      "Epoch 244: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=85.80, train_loss_epoch=81.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 244, global step 8820: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=90.90, train_loss_epoch=81.90]Epoch 245: Lr: 0.0004127 | Train Loss: 81.9328079 | Vali Loss: 0.2084576\n",
      "Epoch 245: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=90.90, train_loss_epoch=83.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 245, global step 8856: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=80.00, train_loss_epoch=83.70]Epoch 246: Lr: 0.0004110 | Train Loss: 83.6571198 | Vali Loss: 0.1977784\n",
      "Epoch 246: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=80.00, train_loss_epoch=81.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 246, global step 8892: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=70.50, train_loss_epoch=81.60]Epoch 247: Lr: 0.0004093 | Train Loss: 81.5914688 | Vali Loss: 0.1959763\n",
      "Epoch 247: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=70.50, train_loss_epoch=80.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 247, global step 8928: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=84.50, train_loss_epoch=80.60]Epoch 248: Lr: 0.0004076 | Train Loss: 80.5904999 | Vali Loss: 0.1990386\n",
      "Epoch 248: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=84.50, train_loss_epoch=80.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 248, global step 8964: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=86.10, train_loss_epoch=80.10]Epoch 249: Lr: 0.0004058 | Train Loss: 80.1191711 | Vali Loss: 0.1894808\n",
      "Epoch 249: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=86.10, train_loss_epoch=79.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 9000: 'val_loss' reached 0.18948 (best 0.18948), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=249-val_loss=0.189.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=71.60, train_loss_epoch=79.60]Epoch 250: Lr: 0.0004041 | Train Loss: 79.5889282 | Vali Loss: 0.1939422\n",
      "Epoch 250: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=71.60, train_loss_epoch=79.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250, global step 9036: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=75.10, train_loss_epoch=79.00]Epoch 251: Lr: 0.0004023 | Train Loss: 79.0445175 | Vali Loss: 0.2109677\n",
      "Epoch 251: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=75.10, train_loss_epoch=78.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 251, global step 9072: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=87.00, train_loss_epoch=78.70]Epoch 252: Lr: 0.0004005 | Train Loss: 78.7106323 | Vali Loss: 0.2084182\n",
      "Epoch 252: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=87.00, train_loss_epoch=78.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 252, global step 9108: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=75.50, train_loss_epoch=78.60]Epoch 253: Lr: 0.0003987 | Train Loss: 78.5904160 | Vali Loss: 0.1890391\n",
      "Epoch 253: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=75.50, train_loss_epoch=78.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 253, global step 9144: 'val_loss' reached 0.18904 (best 0.18904), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=253-val_loss=0.189.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=86.30, train_loss_epoch=78.00]Epoch 254: Lr: 0.0003969 | Train Loss: 78.0299683 | Vali Loss: 0.2125678\n",
      "Epoch 254: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=86.30, train_loss_epoch=77.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 254, global step 9180: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=87.30, train_loss_epoch=77.40]Epoch 255: Lr: 0.0003951 | Train Loss: 77.3780136 | Vali Loss: 0.2049152\n",
      "Epoch 255: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=87.30, train_loss_epoch=76.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 255, global step 9216: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=69.70, train_loss_epoch=76.80]Epoch 256: Lr: 0.0003932 | Train Loss: 76.8001251 | Vali Loss: 0.2141338\n",
      "Epoch 256: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=69.70, train_loss_epoch=77.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 256, global step 9252: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=81.40, train_loss_epoch=77.20]Epoch 257: Lr: 0.0003914 | Train Loss: 77.1905365 | Vali Loss: 0.1792450\n",
      "Epoch 257: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=81.40, train_loss_epoch=76.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 257, global step 9288: 'val_loss' reached 0.17924 (best 0.17924), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=257-val_loss=0.179.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=69.10, train_loss_epoch=76.20]Epoch 258: Lr: 0.0003895 | Train Loss: 76.1840668 | Vali Loss: 0.1952971\n",
      "Epoch 258: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=69.10, train_loss_epoch=75.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 258, global step 9324: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=71.30, train_loss_epoch=75.60]Epoch 259: Lr: 0.0003877 | Train Loss: 75.6065445 | Vali Loss: 0.1786350\n",
      "Epoch 259: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=71.30, train_loss_epoch=75.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 9360: 'val_loss' reached 0.17863 (best 0.17863), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=259-val_loss=0.179.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=74.70, train_loss_epoch=75.40]Epoch 260: Lr: 0.0003858 | Train Loss: 75.3747253 | Vali Loss: 0.2095736\n",
      "Epoch 260: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=74.70, train_loss_epoch=75.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 260, global step 9396: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=73.00, train_loss_epoch=75.50]Epoch 261: Lr: 0.0003839 | Train Loss: 75.4517975 | Vali Loss: 0.1995965\n",
      "Epoch 261: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=73.00, train_loss_epoch=74.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 261, global step 9432: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=68.50, train_loss_epoch=74.60]Epoch 262: Lr: 0.0003820 | Train Loss: 74.6056061 | Vali Loss: 0.1892961\n",
      "Epoch 262: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=68.50, train_loss_epoch=73.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 262, global step 9468: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=69.90, train_loss_epoch=73.80]Epoch 263: Lr: 0.0003801 | Train Loss: 73.8177338 | Vali Loss: 0.1792715\n",
      "Epoch 263: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=69.90, train_loss_epoch=73.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 263, global step 9504: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=70.90, train_loss_epoch=73.40]Epoch 264: Lr: 0.0003782 | Train Loss: 73.3615723 | Vali Loss: 0.1946443\n",
      "Epoch 264: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=70.90, train_loss_epoch=73.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 264, global step 9540: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=73.30, train_loss_epoch=73.20]Epoch 265: Lr: 0.0003762 | Train Loss: 73.1538696 | Vali Loss: 0.1872336\n",
      "Epoch 265: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=73.30, train_loss_epoch=72.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265, global step 9576: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=77.20, train_loss_epoch=72.90]Epoch 266: Lr: 0.0003743 | Train Loss: 72.8627777 | Vali Loss: 0.1936586\n",
      "Epoch 266: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=77.20, train_loss_epoch=72.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 266, global step 9612: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=80.50, train_loss_epoch=72.80]Epoch 267: Lr: 0.0003723 | Train Loss: 72.7631912 | Vali Loss: 0.1772797\n",
      "Epoch 267: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=80.50, train_loss_epoch=72.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 267, global step 9648: 'val_loss' reached 0.17728 (best 0.17728), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=267-val_loss=0.177.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=65.30, train_loss_epoch=72.00]Epoch 268: Lr: 0.0003704 | Train Loss: 72.0035858 | Vali Loss: 0.2059598\n",
      "Epoch 268: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=65.30, train_loss_epoch=71.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 268, global step 9684: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=67.40, train_loss_epoch=71.50]Epoch 269: Lr: 0.0003684 | Train Loss: 71.4700165 | Vali Loss: 0.1735956\n",
      "Epoch 269: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=67.40, train_loss_epoch=71.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 9720: 'val_loss' reached 0.17360 (best 0.17360), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=269-val_loss=0.174.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=78.90, train_loss_epoch=71.00]Epoch 270: Lr: 0.0003664 | Train Loss: 71.0453033 | Vali Loss: 0.1888083\n",
      "Epoch 270: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=78.90, train_loss_epoch=70.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 270, global step 9756: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=86.00, train_loss_epoch=70.90]Epoch 271: Lr: 0.0003644 | Train Loss: 70.9349976 | Vali Loss: 0.1847713\n",
      "Epoch 271: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=86.00, train_loss_epoch=70.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 271, global step 9792: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=58.30, train_loss_epoch=70.50]Epoch 272: Lr: 0.0003624 | Train Loss: 70.4596405 | Vali Loss: 0.2276791\n",
      "Epoch 272: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=58.30, train_loss_epoch=70.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 272, global step 9828: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=60.40, train_loss_epoch=70.00]Epoch 273: Lr: 0.0003604 | Train Loss: 69.9545822 | Vali Loss: 0.2045758\n",
      "Epoch 273: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=60.40, train_loss_epoch=70.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 273, global step 9864: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=61.60, train_loss_epoch=70.10]Epoch 274: Lr: 0.0003584 | Train Loss: 70.0773239 | Vali Loss: 0.1801292\n",
      "Epoch 274: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=61.60, train_loss_epoch=69.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 274, global step 9900: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=67.70, train_loss_epoch=69.70]Epoch 275: Lr: 0.0003564 | Train Loss: 69.6926880 | Vali Loss: 0.2117310\n",
      "Epoch 275: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=67.70, train_loss_epoch=69.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 275, global step 9936: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276: 100%|██████████| 36/36 [00:07<00:00,  4.57it/s, v_num=9, train_loss_step=64.40, train_loss_epoch=69.20]Epoch 276: Lr: 0.0003544 | Train Loss: 69.2366028 | Vali Loss: 0.1827827\n",
      "Epoch 276: 100%|██████████| 36/36 [00:08<00:00,  4.05it/s, v_num=9, train_loss_step=64.40, train_loss_epoch=68.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 276, global step 9972: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=71.80, train_loss_epoch=68.60]Epoch 277: Lr: 0.0003523 | Train Loss: 68.6092453 | Vali Loss: 0.1715480\n",
      "Epoch 277: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=71.80, train_loss_epoch=68.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 277, global step 10008: 'val_loss' reached 0.17155 (best 0.17155), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=277-val_loss=0.172.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=74.30, train_loss_epoch=68.20]Epoch 278: Lr: 0.0003503 | Train Loss: 68.1779022 | Vali Loss: 0.2083457\n",
      "Epoch 278: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=74.30, train_loss_epoch=67.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 278, global step 10044: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=73.10, train_loss_epoch=67.90]Epoch 279: Lr: 0.0003482 | Train Loss: 67.9170151 | Vali Loss: 0.1762615\n",
      "Epoch 279: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=73.10, train_loss_epoch=67.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 10080: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=59.50, train_loss_epoch=67.50]Epoch 280: Lr: 0.0003461 | Train Loss: 67.5484619 | Vali Loss: 0.1780295\n",
      "Epoch 280: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=59.50, train_loss_epoch=67.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 280, global step 10116: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=71.60, train_loss_epoch=67.10]Epoch 281: Lr: 0.0003441 | Train Loss: 67.0673294 | Vali Loss: 0.1760733\n",
      "Epoch 281: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=71.60, train_loss_epoch=66.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 281, global step 10152: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=63.80, train_loss_epoch=66.80]Epoch 282: Lr: 0.0003420 | Train Loss: 66.8043060 | Vali Loss: 0.1791547\n",
      "Epoch 282: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=63.80, train_loss_epoch=66.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 282, global step 10188: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=53.80, train_loss_epoch=66.60]Epoch 283: Lr: 0.0003399 | Train Loss: 66.6083221 | Vali Loss: 0.1699716\n",
      "Epoch 283: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=53.80, train_loss_epoch=66.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 283, global step 10224: 'val_loss' reached 0.16997 (best 0.16997), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=283-val_loss=0.170.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=68.90, train_loss_epoch=66.20]Epoch 284: Lr: 0.0003378 | Train Loss: 66.1605835 | Vali Loss: 0.1859935\n",
      "Epoch 284: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=68.90, train_loss_epoch=65.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 284, global step 10260: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=60.50, train_loss_epoch=65.90]Epoch 285: Lr: 0.0003357 | Train Loss: 65.8885345 | Vali Loss: 0.1884839\n",
      "Epoch 285: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=60.50, train_loss_epoch=65.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 285, global step 10296: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=74.90, train_loss_epoch=65.50]Epoch 286: Lr: 0.0003336 | Train Loss: 65.4946899 | Vali Loss: 0.1754525\n",
      "Epoch 286: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=74.90, train_loss_epoch=65.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 286, global step 10332: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=73.50, train_loss_epoch=65.60]Epoch 287: Lr: 0.0003315 | Train Loss: 65.5652008 | Vali Loss: 0.1804123\n",
      "Epoch 287: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=73.50, train_loss_epoch=66.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 287, global step 10368: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=67.00, train_loss_epoch=66.00]Epoch 288: Lr: 0.0003293 | Train Loss: 66.0400314 | Vali Loss: 0.1667611\n",
      "Epoch 288: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=67.00, train_loss_epoch=65.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 288, global step 10404: 'val_loss' reached 0.16676 (best 0.16676), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=288-val_loss=0.167.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=70.00, train_loss_epoch=65.50]Epoch 289: Lr: 0.0003272 | Train Loss: 65.4973984 | Vali Loss: 0.1785541\n",
      "Epoch 289: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=70.00, train_loss_epoch=64.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 10440: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=59.00, train_loss_epoch=64.70]Epoch 290: Lr: 0.0003251 | Train Loss: 64.7204208 | Vali Loss: 0.2309228\n",
      "Epoch 290: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=59.00, train_loss_epoch=64.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 290, global step 10476: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=61.30, train_loss_epoch=64.40]Epoch 291: Lr: 0.0003229 | Train Loss: 64.4436874 | Vali Loss: 0.1957716\n",
      "Epoch 291: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=61.30, train_loss_epoch=64.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 291, global step 10512: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=58.60, train_loss_epoch=64.30]Epoch 292: Lr: 0.0003208 | Train Loss: 64.2574539 | Vali Loss: 0.1819923\n",
      "Epoch 292: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=58.60, train_loss_epoch=63.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 292, global step 10548: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=68.20, train_loss_epoch=63.50]Epoch 293: Lr: 0.0003186 | Train Loss: 63.4547043 | Vali Loss: 0.1714097\n",
      "Epoch 293: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=68.20, train_loss_epoch=63.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 293, global step 10584: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=62.00, train_loss_epoch=63.10]Epoch 294: Lr: 0.0003164 | Train Loss: 63.0552025 | Vali Loss: 0.1727055\n",
      "Epoch 294: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=62.00, train_loss_epoch=62.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 294, global step 10620: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=65.70, train_loss_epoch=62.80]Epoch 295: Lr: 0.0003143 | Train Loss: 62.7779999 | Vali Loss: 0.1625607\n",
      "Epoch 295: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=65.70, train_loss_epoch=62.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 295, global step 10656: 'val_loss' reached 0.16256 (best 0.16256), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=295-val_loss=0.163.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=54.30, train_loss_epoch=62.50]Epoch 296: Lr: 0.0003121 | Train Loss: 62.4879723 | Vali Loss: 0.1726294\n",
      "Epoch 296: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=54.30, train_loss_epoch=62.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 296, global step 10692: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=63.40, train_loss_epoch=62.20]Epoch 297: Lr: 0.0003099 | Train Loss: 62.2121964 | Vali Loss: 0.1621324\n",
      "Epoch 297: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=63.40, train_loss_epoch=61.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 297, global step 10728: 'val_loss' reached 0.16213 (best 0.16213), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=297-val_loss=0.162.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=58.60, train_loss_epoch=61.90]Epoch 298: Lr: 0.0003078 | Train Loss: 61.9221992 | Vali Loss: 0.1675241\n",
      "Epoch 298: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=58.60, train_loss_epoch=61.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 298, global step 10764: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=64.80, train_loss_epoch=61.70]Epoch 299: Lr: 0.0003056 | Train Loss: 61.6769676 | Vali Loss: 0.1630225\n",
      "Epoch 299: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=64.80, train_loss_epoch=61.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 10800: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=60.20, train_loss_epoch=61.50]Epoch 300: Lr: 0.0003034 | Train Loss: 61.4913292 | Vali Loss: 0.1809123\n",
      "Epoch 300: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=60.20, train_loss_epoch=61.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300, global step 10836: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=65.10, train_loss_epoch=61.30]Epoch 301: Lr: 0.0003012 | Train Loss: 61.3014717 | Vali Loss: 0.1849531\n",
      "Epoch 301: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=65.10, train_loss_epoch=60.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 301, global step 10872: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=57.70, train_loss_epoch=60.90]Epoch 302: Lr: 0.0002990 | Train Loss: 60.8711166 | Vali Loss: 0.1684522\n",
      "Epoch 302: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=57.70, train_loss_epoch=60.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 302, global step 10908: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=57.50, train_loss_epoch=60.60]Epoch 303: Lr: 0.0002968 | Train Loss: 60.5710297 | Vali Loss: 0.1614235\n",
      "Epoch 303: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=57.50, train_loss_epoch=60.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 303, global step 10944: 'val_loss' reached 0.16142 (best 0.16142), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=303-val_loss=0.161.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=58.30, train_loss_epoch=60.40]Epoch 304: Lr: 0.0002946 | Train Loss: 60.3881226 | Vali Loss: 0.1612608\n",
      "Epoch 304: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=58.30, train_loss_epoch=60.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 304, global step 10980: 'val_loss' reached 0.16126 (best 0.16126), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=304-val_loss=0.161.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=54.70, train_loss_epoch=60.10]Epoch 305: Lr: 0.0002924 | Train Loss: 60.0894547 | Vali Loss: 0.1778762\n",
      "Epoch 305: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=54.70, train_loss_epoch=59.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 305, global step 11016: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=70.60, train_loss_epoch=59.80]Epoch 306: Lr: 0.0002902 | Train Loss: 59.8386917 | Vali Loss: 0.1791894\n",
      "Epoch 306: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=70.60, train_loss_epoch=59.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 306, global step 11052: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=51.00, train_loss_epoch=59.70]Epoch 307: Lr: 0.0002879 | Train Loss: 59.7196236 | Vali Loss: 0.1621141\n",
      "Epoch 307: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=51.00, train_loss_epoch=60.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 307, global step 11088: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=55.20, train_loss_epoch=60.00]Epoch 308: Lr: 0.0002857 | Train Loss: 59.9741325 | Vali Loss: 0.1562065\n",
      "Epoch 308: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=55.20, train_loss_epoch=59.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 308, global step 11124: 'val_loss' reached 0.15621 (best 0.15621), saving model to '/home/zhengyaokun/radar_data_generation/radarWave/fno_hosdata/othermethod/work_dirs/convlstm/checkpoints/best-epoch=308-val_loss=0.156.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=53.70, train_loss_epoch=59.40]Epoch 309: Lr: 0.0002835 | Train Loss: 59.4307899 | Vali Loss: 0.1690325\n",
      "Epoch 309: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=53.70, train_loss_epoch=58.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 11160: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=55.00, train_loss_epoch=58.90]Epoch 310: Lr: 0.0002813 | Train Loss: 58.9176445 | Vali Loss: 0.1767249\n",
      "Epoch 310: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=55.00, train_loss_epoch=58.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 310, global step 11196: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=42.10, train_loss_epoch=58.70]Epoch 311: Lr: 0.0002790 | Train Loss: 58.6645622 | Vali Loss: 0.1727930\n",
      "Epoch 311: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=42.10, train_loss_epoch=58.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 311, global step 11232: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=57.50, train_loss_epoch=58.30]Epoch 312: Lr: 0.0002768 | Train Loss: 58.3084908 | Vali Loss: 0.1717708\n",
      "Epoch 312: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=57.50, train_loss_epoch=58.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 312, global step 11268: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=62.70, train_loss_epoch=58.10]Epoch 313: Lr: 0.0002746 | Train Loss: 58.1038742 | Vali Loss: 0.1629290\n",
      "Epoch 313: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=62.70, train_loss_epoch=58.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 313, global step 11304: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=53.20, train_loss_epoch=58.00]Epoch 314: Lr: 0.0002723 | Train Loss: 58.0445595 | Vali Loss: 0.1713224\n",
      "Epoch 314: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=53.20, train_loss_epoch=57.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 314, global step 11340: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=55.30, train_loss_epoch=57.80]Epoch 315: Lr: 0.0002701 | Train Loss: 57.7508202 | Vali Loss: 0.1621935\n",
      "Epoch 315: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=55.30, train_loss_epoch=57.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 315, global step 11376: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=58.80, train_loss_epoch=57.50]Epoch 316: Lr: 0.0002679 | Train Loss: 57.4675636 | Vali Loss: 0.1710877\n",
      "Epoch 316: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=58.80, train_loss_epoch=57.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 316, global step 11412: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317: 100%|██████████| 36/36 [00:07<00:00,  4.54it/s, v_num=9, train_loss_step=51.50, train_loss_epoch=57.30]Epoch 317: Lr: 0.0002656 | Train Loss: 57.2722321 | Vali Loss: 0.1732122\n",
      "Epoch 317: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=51.50, train_loss_epoch=57.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 317, global step 11448: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=54.70, train_loss_epoch=57.10]Epoch 318: Lr: 0.0002634 | Train Loss: 57.1239815 | Vali Loss: 0.1598076\n",
      "Epoch 318: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=54.70, train_loss_epoch=57.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 318, global step 11484: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=64.50, train_loss_epoch=57.20]Epoch 319: Lr: 0.0002612 | Train Loss: 57.2279205 | Vali Loss: 0.1667229\n",
      "Epoch 319: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=64.50, train_loss_epoch=56.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 11520: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=59.60, train_loss_epoch=56.60]Epoch 320: Lr: 0.0002589 | Train Loss: 56.6210556 | Vali Loss: 0.1726892\n",
      "Epoch 320: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=59.60, train_loss_epoch=56.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 320, global step 11556: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=49.30, train_loss_epoch=56.50]Epoch 321: Lr: 0.0002567 | Train Loss: 56.4506874 | Vali Loss: 0.1662843\n",
      "Epoch 321: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=49.30, train_loss_epoch=56.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 321, global step 11592: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=59.10, train_loss_epoch=56.30]Epoch 322: Lr: 0.0002544 | Train Loss: 56.2881470 | Vali Loss: 0.1759885\n",
      "Epoch 322: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=59.10, train_loss_epoch=56.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 322, global step 11628: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323: 100%|██████████| 36/36 [00:07<00:00,  4.51it/s, v_num=9, train_loss_step=58.50, train_loss_epoch=56.20]Epoch 323: Lr: 0.0002522 | Train Loss: 56.2400284 | Vali Loss: 0.1777295\n",
      "Epoch 323: 100%|██████████| 36/36 [00:08<00:00,  4.01it/s, v_num=9, train_loss_step=58.50, train_loss_epoch=56.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 323, global step 11664: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=47.40, train_loss_epoch=56.00]Epoch 324: Lr: 0.0002499 | Train Loss: 55.9831581 | Vali Loss: 0.1877449\n",
      "Epoch 324: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=47.40, train_loss_epoch=55.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 324, global step 11700: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=54.50, train_loss_epoch=55.60]Epoch 325: Lr: 0.0002477 | Train Loss: 55.5924950 | Vali Loss: 0.1704015\n",
      "Epoch 325: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=54.50, train_loss_epoch=55.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 325, global step 11736: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=46.30, train_loss_epoch=55.50]Epoch 326: Lr: 0.0002455 | Train Loss: 55.4571877 | Vali Loss: 0.1660631\n",
      "Epoch 326: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=46.30, train_loss_epoch=55.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 326, global step 11772: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=58.70, train_loss_epoch=55.10]Epoch 327: Lr: 0.0002432 | Train Loss: 55.1076508 | Vali Loss: 0.1670825\n",
      "Epoch 327: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=58.70, train_loss_epoch=55.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 327, global step 11808: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=55.60, train_loss_epoch=55.00]Epoch 328: Lr: 0.0002410 | Train Loss: 54.9891129 | Vali Loss: 0.1790934\n",
      "Epoch 328: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=55.60, train_loss_epoch=54.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 328, global step 11844: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=42.20, train_loss_epoch=54.90]Epoch 329: Lr: 0.0002387 | Train Loss: 54.8627586 | Vali Loss: 0.1737242\n",
      "Epoch 329: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=42.20, train_loss_epoch=54.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 11880: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=60.40, train_loss_epoch=54.70]Epoch 330: Lr: 0.0002365 | Train Loss: 54.7172165 | Vali Loss: 0.1714532\n",
      "Epoch 330: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=60.40, train_loss_epoch=54.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 330, global step 11916: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=50.10, train_loss_epoch=54.40]Epoch 331: Lr: 0.0002342 | Train Loss: 54.4009666 | Vali Loss: 0.1724676\n",
      "Epoch 331: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=50.10, train_loss_epoch=54.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 331, global step 11952: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=53.20, train_loss_epoch=54.40]Epoch 332: Lr: 0.0002320 | Train Loss: 54.3537979 | Vali Loss: 0.1883036\n",
      "Epoch 332: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=53.20, train_loss_epoch=54.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 332, global step 11988: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=51.60, train_loss_epoch=54.10]Epoch 333: Lr: 0.0002298 | Train Loss: 54.0933380 | Vali Loss: 0.1794832\n",
      "Epoch 333: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=51.60, train_loss_epoch=53.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 333, global step 12024: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=50.10, train_loss_epoch=53.90]Epoch 334: Lr: 0.0002275 | Train Loss: 53.8664284 | Vali Loss: 0.1782424\n",
      "Epoch 334: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=50.10, train_loss_epoch=53.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 334, global step 12060: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335: 100%|██████████| 36/36 [00:07<00:00,  4.55it/s, v_num=9, train_loss_step=60.40, train_loss_epoch=53.70]Epoch 335: Lr: 0.0002253 | Train Loss: 53.6997414 | Vali Loss: 0.1679886\n",
      "Epoch 335: 100%|██████████| 36/36 [00:08<00:00,  4.01it/s, v_num=9, train_loss_step=60.40, train_loss_epoch=53.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 335, global step 12096: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=52.50, train_loss_epoch=53.70]Epoch 336: Lr: 0.0002231 | Train Loss: 53.6653328 | Vali Loss: 0.1748536\n",
      "Epoch 336: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=52.50, train_loss_epoch=53.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 336, global step 12132: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=48.30, train_loss_epoch=53.60]Epoch 337: Lr: 0.0002208 | Train Loss: 53.6138573 | Vali Loss: 0.1749166\n",
      "Epoch 337: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=48.30, train_loss_epoch=53.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 337, global step 12168: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=51.20, train_loss_epoch=53.20]Epoch 338: Lr: 0.0002186 | Train Loss: 53.2012787 | Vali Loss: 0.1900182\n",
      "Epoch 338: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=51.20, train_loss_epoch=53.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 338, global step 12204: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=54.10, train_loss_epoch=53.10]Epoch 339: Lr: 0.0002164 | Train Loss: 53.1180611 | Vali Loss: 0.1873653\n",
      "Epoch 339: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=54.10, train_loss_epoch=52.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 12240: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=56.20, train_loss_epoch=52.90]Epoch 340: Lr: 0.0002142 | Train Loss: 52.8769150 | Vali Loss: 0.1772929\n",
      "Epoch 340: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=56.20, train_loss_epoch=52.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 340, global step 12276: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341: 100%|██████████| 36/36 [00:07<00:00,  4.52it/s, v_num=9, train_loss_step=54.20, train_loss_epoch=52.80]Epoch 341: Lr: 0.0002119 | Train Loss: 52.7576370 | Vali Loss: 0.1783961\n",
      "Epoch 341: 100%|██████████| 36/36 [00:08<00:00,  4.01it/s, v_num=9, train_loss_step=54.20, train_loss_epoch=52.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 341, global step 12312: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=53.60, train_loss_epoch=52.90]Epoch 342: Lr: 0.0002097 | Train Loss: 52.8887978 | Vali Loss: 0.1774441\n",
      "Epoch 342: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=53.60, train_loss_epoch=52.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 342, global step 12348: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=55.00, train_loss_epoch=52.40]Epoch 343: Lr: 0.0002075 | Train Loss: 52.3873749 | Vali Loss: 0.1684766\n",
      "Epoch 343: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=55.00, train_loss_epoch=52.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 343, global step 12384: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=47.90, train_loss_epoch=52.20]Epoch 344: Lr: 0.0002053 | Train Loss: 52.1721077 | Vali Loss: 0.1789978\n",
      "Epoch 344: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=47.90, train_loss_epoch=52.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 344, global step 12420: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=52.20, train_loss_epoch=52.00]Epoch 345: Lr: 0.0002031 | Train Loss: 52.0203285 | Vali Loss: 0.1746671\n",
      "Epoch 345: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=52.20, train_loss_epoch=51.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 345, global step 12456: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=51.90, train_loss_epoch=51.90]Epoch 346: Lr: 0.0002009 | Train Loss: 51.8665543 | Vali Loss: 0.1872401\n",
      "Epoch 346: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=51.90, train_loss_epoch=51.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 346, global step 12492: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347: 100%|██████████| 36/36 [00:07<00:00,  4.51it/s, v_num=9, train_loss_step=58.70, train_loss_epoch=51.80]Epoch 347: Lr: 0.0001987 | Train Loss: 51.7829170 | Vali Loss: 0.1826069\n",
      "Epoch 347: 100%|██████████| 36/36 [00:09<00:00,  3.99it/s, v_num=9, train_loss_step=58.70, train_loss_epoch=51.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 347, global step 12528: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=53.90, train_loss_epoch=51.60]Epoch 348: Lr: 0.0001965 | Train Loss: 51.5587006 | Vali Loss: 0.1780347\n",
      "Epoch 348: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=53.90, train_loss_epoch=51.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 348, global step 12564: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 36/36 [00:07<00:00,  4.53it/s, v_num=9, train_loss_step=47.40, train_loss_epoch=51.50]Epoch 349: Lr: 0.0001943 | Train Loss: 51.4507637 | Vali Loss: 0.1711180\n",
      "Epoch 349: 100%|██████████| 36/36 [00:09<00:00,  3.99it/s, v_num=9, train_loss_step=47.40, train_loss_epoch=51.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 12600: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=53.90, train_loss_epoch=51.30]Epoch 350: Lr: 0.0001921 | Train Loss: 51.3436050 | Vali Loss: 0.1784828\n",
      "Epoch 350: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=53.90, train_loss_epoch=51.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 350, global step 12636: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=48.90, train_loss_epoch=51.20]Epoch 351: Lr: 0.0001899 | Train Loss: 51.1957245 | Vali Loss: 0.1824232\n",
      "Epoch 351: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=48.90, train_loss_epoch=51.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 351, global step 12672: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=55.30, train_loss_epoch=51.00]Epoch 352: Lr: 0.0001878 | Train Loss: 51.0491867 | Vali Loss: 0.1862281\n",
      "Epoch 352: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=55.30, train_loss_epoch=50.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 352, global step 12708: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=53.70, train_loss_epoch=50.90]Epoch 353: Lr: 0.0001856 | Train Loss: 50.9477158 | Vali Loss: 0.1821329\n",
      "Epoch 353: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=53.70, train_loss_epoch=50.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 353, global step 12744: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=58.00, train_loss_epoch=50.80]Epoch 354: Lr: 0.0001834 | Train Loss: 50.7613335 | Vali Loss: 0.1826401\n",
      "Epoch 354: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=58.00, train_loss_epoch=50.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 354, global step 12780: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355: 100%|██████████| 36/36 [00:08<00:00,  4.49it/s, v_num=9, train_loss_step=56.10, train_loss_epoch=50.60]Epoch 355: Lr: 0.0001813 | Train Loss: 50.5700035 | Vali Loss: 0.1784296\n",
      "Epoch 355: 100%|██████████| 36/36 [00:09<00:00,  3.99it/s, v_num=9, train_loss_step=56.10, train_loss_epoch=50.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 355, global step 12816: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=50.50]Epoch 356: Lr: 0.0001791 | Train Loss: 50.4851227 | Vali Loss: 0.1805184\n",
      "Epoch 356: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=50.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 356, global step 12852: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=55.40, train_loss_epoch=50.30]Epoch 357: Lr: 0.0001770 | Train Loss: 50.3073692 | Vali Loss: 0.1777267\n",
      "Epoch 357: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=55.40, train_loss_epoch=50.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 357, global step 12888: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=50.20]Epoch 358: Lr: 0.0001748 | Train Loss: 50.2059021 | Vali Loss: 0.1826350\n",
      "Epoch 358: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=50.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 358, global step 12924: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 36/36 [00:07<00:00,  4.55it/s, v_num=9, train_loss_step=40.90, train_loss_epoch=50.10]Epoch 359: Lr: 0.0001727 | Train Loss: 50.0808258 | Vali Loss: 0.1859704\n",
      "Epoch 359: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=40.90, train_loss_epoch=50.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 12960: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=54.10, train_loss_epoch=50.10]Epoch 360: Lr: 0.0001706 | Train Loss: 50.0677299 | Vali Loss: 0.1804017\n",
      "Epoch 360: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=54.10, train_loss_epoch=49.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 360, global step 12996: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=41.50, train_loss_epoch=49.90]Epoch 361: Lr: 0.0001684 | Train Loss: 49.8911629 | Vali Loss: 0.1842110\n",
      "Epoch 361: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=41.50, train_loss_epoch=49.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 361, global step 13032: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=54.00, train_loss_epoch=49.70]Epoch 362: Lr: 0.0001663 | Train Loss: 49.7223434 | Vali Loss: 0.1772489\n",
      "Epoch 362: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=54.00, train_loss_epoch=49.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 362, global step 13068: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=44.80, train_loss_epoch=49.50]Epoch 363: Lr: 0.0001642 | Train Loss: 49.5471458 | Vali Loss: 0.1810707\n",
      "Epoch 363: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=44.80, train_loss_epoch=49.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 363, global step 13104: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=40.10, train_loss_epoch=49.40]Epoch 364: Lr: 0.0001621 | Train Loss: 49.4286461 | Vali Loss: 0.1825542\n",
      "Epoch 364: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=40.10, train_loss_epoch=49.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 364, global step 13140: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=59.30, train_loss_epoch=49.30]Epoch 365: Lr: 0.0001600 | Train Loss: 49.2909927 | Vali Loss: 0.1852216\n",
      "Epoch 365: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=59.30, train_loss_epoch=49.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 365, global step 13176: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=47.00, train_loss_epoch=49.20]Epoch 366: Lr: 0.0001579 | Train Loss: 49.1528931 | Vali Loss: 0.1821866\n",
      "Epoch 366: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=47.00, train_loss_epoch=49.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 366, global step 13212: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=45.80, train_loss_epoch=49.00]Epoch 367: Lr: 0.0001558 | Train Loss: 49.0299034 | Vali Loss: 0.1763539\n",
      "Epoch 367: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=45.80, train_loss_epoch=48.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 367, global step 13248: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=49.00, train_loss_epoch=48.90]Epoch 368: Lr: 0.0001538 | Train Loss: 48.9156799 | Vali Loss: 0.1858043\n",
      "Epoch 368: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=49.00, train_loss_epoch=48.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 368, global step 13284: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=47.20, train_loss_epoch=48.80]Epoch 369: Lr: 0.0001517 | Train Loss: 48.8114815 | Vali Loss: 0.1824394\n",
      "Epoch 369: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=47.20, train_loss_epoch=48.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 13320: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=46.30, train_loss_epoch=48.70]Epoch 370: Lr: 0.0001496 | Train Loss: 48.6986160 | Vali Loss: 0.1853133\n",
      "Epoch 370: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=46.30, train_loss_epoch=48.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 370, global step 13356: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=42.80, train_loss_epoch=48.60]Epoch 371: Lr: 0.0001476 | Train Loss: 48.6065483 | Vali Loss: 0.1818603\n",
      "Epoch 371: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=42.80, train_loss_epoch=48.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 371, global step 13392: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=51.20, train_loss_epoch=48.50]Epoch 372: Lr: 0.0001455 | Train Loss: 48.4757423 | Vali Loss: 0.1859045\n",
      "Epoch 372: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=51.20, train_loss_epoch=48.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 372, global step 13428: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373: 100%|██████████| 36/36 [00:07<00:00,  4.59it/s, v_num=9, train_loss_step=47.50, train_loss_epoch=48.40]Epoch 373: Lr: 0.0001435 | Train Loss: 48.4023399 | Vali Loss: 0.1873456\n",
      "Epoch 373: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=47.50, train_loss_epoch=48.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 373, global step 13464: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=52.30, train_loss_epoch=48.30]Epoch 374: Lr: 0.0001415 | Train Loss: 48.2531967 | Vali Loss: 0.1861833\n",
      "Epoch 374: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=52.30, train_loss_epoch=48.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 374, global step 13500: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=45.30, train_loss_epoch=48.20]Epoch 375: Lr: 0.0001395 | Train Loss: 48.1591301 | Vali Loss: 0.1846432\n",
      "Epoch 375: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=45.30, train_loss_epoch=48.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 375, global step 13536: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=51.00, train_loss_epoch=48.10]Epoch 376: Lr: 0.0001374 | Train Loss: 48.1127968 | Vali Loss: 0.1868553\n",
      "Epoch 376: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=51.00, train_loss_epoch=48.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 376, global step 13572: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=41.40, train_loss_epoch=48.00]Epoch 377: Lr: 0.0001354 | Train Loss: 47.9692535 | Vali Loss: 0.1858798\n",
      "Epoch 377: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=41.40, train_loss_epoch=47.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 377, global step 13608: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=52.80, train_loss_epoch=47.80]Epoch 378: Lr: 0.0001335 | Train Loss: 47.8494072 | Vali Loss: 0.1874567\n",
      "Epoch 378: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=52.80, train_loss_epoch=47.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 378, global step 13644: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=42.20, train_loss_epoch=47.80]Epoch 379: Lr: 0.0001315 | Train Loss: 47.7702141 | Vali Loss: 0.1817432\n",
      "Epoch 379: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=42.20, train_loss_epoch=47.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 13680: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=46.80, train_loss_epoch=47.70]Epoch 380: Lr: 0.0001295 | Train Loss: 47.6569023 | Vali Loss: 0.1864059\n",
      "Epoch 380: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=46.80, train_loss_epoch=47.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 380, global step 13716: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381: 100%|██████████| 36/36 [00:07<00:00,  4.52it/s, v_num=9, train_loss_step=38.00, train_loss_epoch=47.50]Epoch 381: Lr: 0.0001275 | Train Loss: 47.5362358 | Vali Loss: 0.1868299\n",
      "Epoch 381: 100%|██████████| 36/36 [00:08<00:00,  4.02it/s, v_num=9, train_loss_step=38.00, train_loss_epoch=47.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 381, global step 13752: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=48.00, train_loss_epoch=47.40]Epoch 382: Lr: 0.0001256 | Train Loss: 47.4371643 | Vali Loss: 0.1864262\n",
      "Epoch 382: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=48.00, train_loss_epoch=47.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 382, global step 13788: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=47.40]Epoch 383: Lr: 0.0001237 | Train Loss: 47.3780365 | Vali Loss: 0.1889336\n",
      "Epoch 383: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=47.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 383, global step 13824: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=40.10, train_loss_epoch=47.30]Epoch 384: Lr: 0.0001217 | Train Loss: 47.2569008 | Vali Loss: 0.1871751\n",
      "Epoch 384: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=40.10, train_loss_epoch=47.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 384, global step 13860: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385: 100%|██████████| 36/36 [00:07<00:00,  4.74it/s, v_num=9, train_loss_step=45.50, train_loss_epoch=47.20]Epoch 385: Lr: 0.0001198 | Train Loss: 47.1512375 | Vali Loss: 0.1913601\n",
      "Epoch 385: 100%|██████████| 36/36 [00:08<00:00,  4.19it/s, v_num=9, train_loss_step=45.50, train_loss_epoch=47.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 385, global step 13896: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=47.10]Epoch 386: Lr: 0.0001179 | Train Loss: 47.0749359 | Vali Loss: 0.1864697\n",
      "Epoch 386: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=46.40, train_loss_epoch=47.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 386, global step 13932: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=42.30, train_loss_epoch=47.00]Epoch 387: Lr: 0.0001160 | Train Loss: 46.9834099 | Vali Loss: 0.1949656\n",
      "Epoch 387: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=42.30, train_loss_epoch=46.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 387, global step 13968: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=47.50, train_loss_epoch=46.90]Epoch 388: Lr: 0.0001141 | Train Loss: 46.8733063 | Vali Loss: 0.1987336\n",
      "Epoch 388: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=47.50, train_loss_epoch=46.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 388, global step 14004: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=43.90, train_loss_epoch=46.80]Epoch 389: Lr: 0.0001122 | Train Loss: 46.8047676 | Vali Loss: 0.1846788\n",
      "Epoch 389: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=43.90, train_loss_epoch=46.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 14040: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=50.50, train_loss_epoch=46.70]Epoch 390: Lr: 0.0001104 | Train Loss: 46.7406158 | Vali Loss: 0.1915191\n",
      "Epoch 390: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=50.50, train_loss_epoch=46.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 390, global step 14076: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=50.30, train_loss_epoch=46.60]Epoch 391: Lr: 0.0001085 | Train Loss: 46.6403694 | Vali Loss: 0.1883076\n",
      "Epoch 391: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=50.30, train_loss_epoch=46.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 391, global step 14112: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=43.40, train_loss_epoch=46.50]Epoch 392: Lr: 0.0001067 | Train Loss: 46.5327492 | Vali Loss: 0.1883455\n",
      "Epoch 392: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=43.40, train_loss_epoch=46.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 392, global step 14148: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=51.70, train_loss_epoch=46.50]Epoch 393: Lr: 0.0001048 | Train Loss: 46.4671211 | Vali Loss: 0.1902525\n",
      "Epoch 393: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=51.70, train_loss_epoch=46.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 393, global step 14184: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394: 100%|██████████| 36/36 [00:07<00:00,  4.58it/s, v_num=9, train_loss_step=49.40, train_loss_epoch=46.40]Epoch 394: Lr: 0.0001030 | Train Loss: 46.3874245 | Vali Loss: 0.1921306\n",
      "Epoch 394: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=49.40, train_loss_epoch=46.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 394, global step 14220: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=39.70, train_loss_epoch=46.30]Epoch 395: Lr: 0.0001012 | Train Loss: 46.3219337 | Vali Loss: 0.1857041\n",
      "Epoch 395: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=39.70, train_loss_epoch=46.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 395, global step 14256: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=50.90, train_loss_epoch=46.20]Epoch 396: Lr: 0.0000994 | Train Loss: 46.2258682 | Vali Loss: 0.1922181\n",
      "Epoch 396: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=50.90, train_loss_epoch=46.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 396, global step 14292: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=46.10]Epoch 397: Lr: 0.0000976 | Train Loss: 46.1414719 | Vali Loss: 0.1863044\n",
      "Epoch 397: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=46.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 397, global step 14328: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=42.70, train_loss_epoch=46.10]Epoch 398: Lr: 0.0000958 | Train Loss: 46.0761223 | Vali Loss: 0.1880973\n",
      "Epoch 398: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=42.70, train_loss_epoch=46.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 398, global step 14364: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=49.10, train_loss_epoch=46.00]Epoch 399: Lr: 0.0000941 | Train Loss: 46.0047951 | Vali Loss: 0.1937390\n",
      "Epoch 399: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=49.10, train_loss_epoch=45.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 14400: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: 100%|██████████| 36/36 [00:07<00:00,  4.53it/s, v_num=9, train_loss_step=48.80, train_loss_epoch=45.90]Epoch 400: Lr: 0.0000923 | Train Loss: 45.9151192 | Vali Loss: 0.1987916\n",
      "Epoch 400: 100%|██████████| 36/36 [00:09<00:00,  4.00it/s, v_num=9, train_loss_step=48.80, train_loss_epoch=45.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400, global step 14436: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=47.00, train_loss_epoch=45.80]Epoch 401: Lr: 0.0000906 | Train Loss: 45.8352470 | Vali Loss: 0.1856481\n",
      "Epoch 401: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=47.00, train_loss_epoch=45.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 401, global step 14472: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=42.10, train_loss_epoch=45.80]Epoch 402: Lr: 0.0000889 | Train Loss: 45.7703629 | Vali Loss: 0.1867892\n",
      "Epoch 402: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=42.10, train_loss_epoch=45.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 402, global step 14508: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=50.40, train_loss_epoch=45.70]Epoch 403: Lr: 0.0000872 | Train Loss: 45.6923866 | Vali Loss: 0.1881564\n",
      "Epoch 403: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=50.40, train_loss_epoch=45.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 403, global step 14544: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=46.00, train_loss_epoch=45.60]Epoch 404: Lr: 0.0000855 | Train Loss: 45.6421585 | Vali Loss: 0.1836415\n",
      "Epoch 404: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=46.00, train_loss_epoch=45.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 404, global step 14580: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=49.10, train_loss_epoch=45.60]Epoch 405: Lr: 0.0000838 | Train Loss: 45.5794487 | Vali Loss: 0.1894923\n",
      "Epoch 405: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=49.10, train_loss_epoch=45.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 405, global step 14616: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=49.80, train_loss_epoch=45.50]Epoch 406: Lr: 0.0000821 | Train Loss: 45.5062256 | Vali Loss: 0.1880241\n",
      "Epoch 406: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=49.80, train_loss_epoch=45.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 406, global step 14652: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=48.70, train_loss_epoch=45.40]Epoch 407: Lr: 0.0000805 | Train Loss: 45.4269562 | Vali Loss: 0.1930129\n",
      "Epoch 407: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=48.70, train_loss_epoch=45.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 407, global step 14688: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=44.30, train_loss_epoch=45.40]Epoch 408: Lr: 0.0000788 | Train Loss: 45.3621063 | Vali Loss: 0.1919953\n",
      "Epoch 408: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=44.30, train_loss_epoch=45.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 408, global step 14724: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=38.70, train_loss_epoch=45.30]Epoch 409: Lr: 0.0000772 | Train Loss: 45.2972641 | Vali Loss: 0.1946545\n",
      "Epoch 409: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=38.70, train_loss_epoch=45.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 14760: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=44.00, train_loss_epoch=45.20]Epoch 410: Lr: 0.0000756 | Train Loss: 45.2418747 | Vali Loss: 0.1881132\n",
      "Epoch 410: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=44.00, train_loss_epoch=45.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 410, global step 14796: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=45.00, train_loss_epoch=45.20]Epoch 411: Lr: 0.0000740 | Train Loss: 45.1791039 | Vali Loss: 0.1930587\n",
      "Epoch 411: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=45.00, train_loss_epoch=45.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 411, global step 14832: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=44.60, train_loss_epoch=45.10]Epoch 412: Lr: 0.0000724 | Train Loss: 45.1279831 | Vali Loss: 0.1878234\n",
      "Epoch 412: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=44.60, train_loss_epoch=45.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 412, global step 14868: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=48.00, train_loss_epoch=45.10]Epoch 413: Lr: 0.0000708 | Train Loss: 45.0584984 | Vali Loss: 0.1885661\n",
      "Epoch 413: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=48.00, train_loss_epoch=45.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 413, global step 14904: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=39.30, train_loss_epoch=45.00]Epoch 414: Lr: 0.0000693 | Train Loss: 45.0325241 | Vali Loss: 0.1874257\n",
      "Epoch 414: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=39.30, train_loss_epoch=45.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 414, global step 14940: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=47.70, train_loss_epoch=45.00]Epoch 415: Lr: 0.0000677 | Train Loss: 44.9599495 | Vali Loss: 0.1933959\n",
      "Epoch 415: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=47.70, train_loss_epoch=44.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 415, global step 14976: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=49.00, train_loss_epoch=44.90]Epoch 416: Lr: 0.0000662 | Train Loss: 44.8918114 | Vali Loss: 0.1903305\n",
      "Epoch 416: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=49.00, train_loss_epoch=44.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 416, global step 15012: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=37.60, train_loss_epoch=44.80]Epoch 417: Lr: 0.0000647 | Train Loss: 44.8333549 | Vali Loss: 0.1858928\n",
      "Epoch 417: 100%|██████████| 36/36 [00:08<00:00,  4.19it/s, v_num=9, train_loss_step=37.60, train_loss_epoch=44.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 417, global step 15048: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=42.30, train_loss_epoch=44.80]Epoch 418: Lr: 0.0000632 | Train Loss: 44.7926712 | Vali Loss: 0.1947454\n",
      "Epoch 418: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=42.30, train_loss_epoch=44.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 418, global step 15084: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=49.30, train_loss_epoch=44.70]Epoch 419: Lr: 0.0000617 | Train Loss: 44.7271309 | Vali Loss: 0.1908761\n",
      "Epoch 419: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=49.30, train_loss_epoch=44.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 15120: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=47.90, train_loss_epoch=44.70]Epoch 420: Lr: 0.0000602 | Train Loss: 44.6729698 | Vali Loss: 0.1937773\n",
      "Epoch 420: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=47.90, train_loss_epoch=44.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 420, global step 15156: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=47.60, train_loss_epoch=44.60]Epoch 421: Lr: 0.0000588 | Train Loss: 44.6342583 | Vali Loss: 0.1890672\n",
      "Epoch 421: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=47.60, train_loss_epoch=44.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 421, global step 15192: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422: 100%|██████████| 36/36 [00:07<00:00,  4.53it/s, v_num=9, train_loss_step=45.50, train_loss_epoch=44.60]Epoch 422: Lr: 0.0000573 | Train Loss: 44.5824471 | Vali Loss: 0.1922154\n",
      "Epoch 422: 100%|██████████| 36/36 [00:08<00:00,  4.02it/s, v_num=9, train_loss_step=45.50, train_loss_epoch=44.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 422, global step 15228: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=45.40, train_loss_epoch=44.50]Epoch 423: Lr: 0.0000559 | Train Loss: 44.5329742 | Vali Loss: 0.1854098\n",
      "Epoch 423: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=45.40, train_loss_epoch=44.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 423, global step 15264: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424: 100%|██████████| 36/36 [00:07<00:00,  4.57it/s, v_num=9, train_loss_step=49.70, train_loss_epoch=44.50]Epoch 424: Lr: 0.0000545 | Train Loss: 44.4882965 | Vali Loss: 0.1933201\n",
      "Epoch 424: 100%|██████████| 36/36 [00:08<00:00,  4.04it/s, v_num=9, train_loss_step=49.70, train_loss_epoch=44.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 424, global step 15300: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=40.30, train_loss_epoch=44.40]Epoch 425: Lr: 0.0000531 | Train Loss: 44.4279633 | Vali Loss: 0.1945844\n",
      "Epoch 425: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=40.30, train_loss_epoch=44.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 425, global step 15336: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=45.00, train_loss_epoch=44.40]Epoch 426: Lr: 0.0000517 | Train Loss: 44.3861237 | Vali Loss: 0.1893706\n",
      "Epoch 426: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=45.00, train_loss_epoch=44.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 426, global step 15372: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=44.50, train_loss_epoch=44.30]Epoch 427: Lr: 0.0000504 | Train Loss: 44.3482895 | Vali Loss: 0.1935708\n",
      "Epoch 427: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=44.50, train_loss_epoch=44.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 427, global step 15408: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=47.30, train_loss_epoch=44.30]Epoch 428: Lr: 0.0000490 | Train Loss: 44.2999611 | Vali Loss: 0.1937575\n",
      "Epoch 428: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=47.30, train_loss_epoch=44.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 428, global step 15444: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=39.90, train_loss_epoch=44.30]Epoch 429: Lr: 0.0000477 | Train Loss: 44.2524681 | Vali Loss: 0.1914466\n",
      "Epoch 429: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=39.90, train_loss_epoch=44.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 15480: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=42.50, train_loss_epoch=44.20]Epoch 430: Lr: 0.0000464 | Train Loss: 44.2097588 | Vali Loss: 0.1926077\n",
      "Epoch 430: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=42.50, train_loss_epoch=44.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 430, global step 15516: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431: 100%|██████████| 36/36 [00:07<00:00,  4.62it/s, v_num=9, train_loss_step=46.00, train_loss_epoch=44.20]Epoch 431: Lr: 0.0000451 | Train Loss: 44.1763992 | Vali Loss: 0.1923855\n",
      "Epoch 431: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=46.00, train_loss_epoch=44.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 431, global step 15552: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=49.20, train_loss_epoch=44.10]Epoch 432: Lr: 0.0000438 | Train Loss: 44.1400909 | Vali Loss: 0.1895730\n",
      "Epoch 432: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=49.20, train_loss_epoch=44.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 432, global step 15588: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=38.60, train_loss_epoch=44.10]Epoch 433: Lr: 0.0000426 | Train Loss: 44.0933914 | Vali Loss: 0.1927903\n",
      "Epoch 433: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=38.60, train_loss_epoch=44.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 433, global step 15624: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=42.90, train_loss_epoch=44.10]Epoch 434: Lr: 0.0000413 | Train Loss: 44.0619850 | Vali Loss: 0.1945694\n",
      "Epoch 434: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=42.90, train_loss_epoch=44.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 434, global step 15660: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=41.40, train_loss_epoch=44.00]Epoch 435: Lr: 0.0000401 | Train Loss: 44.0309181 | Vali Loss: 0.1928169\n",
      "Epoch 435: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=41.40, train_loss_epoch=44.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 435, global step 15696: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=44.00]Epoch 436: Lr: 0.0000389 | Train Loss: 43.9878807 | Vali Loss: 0.1936981\n",
      "Epoch 436: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=44.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 436, global step 15732: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=44.30, train_loss_epoch=44.00]Epoch 437: Lr: 0.0000377 | Train Loss: 43.9529381 | Vali Loss: 0.1957956\n",
      "Epoch 437: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=44.30, train_loss_epoch=43.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 437, global step 15768: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=48.20, train_loss_epoch=43.90]Epoch 438: Lr: 0.0000365 | Train Loss: 43.9221992 | Vali Loss: 0.1960178\n",
      "Epoch 438: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=48.20, train_loss_epoch=43.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 438, global step 15804: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=49.70, train_loss_epoch=43.90]Epoch 439: Lr: 0.0000354 | Train Loss: 43.8862267 | Vali Loss: 0.1925951\n",
      "Epoch 439: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=49.70, train_loss_epoch=43.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 15840: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=43.90]Epoch 440: Lr: 0.0000342 | Train Loss: 43.8570786 | Vali Loss: 0.1921041\n",
      "Epoch 440: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=43.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 440, global step 15876: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=47.50, train_loss_epoch=43.80]Epoch 441: Lr: 0.0000331 | Train Loss: 43.8264084 | Vali Loss: 0.1916358\n",
      "Epoch 441: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=47.50, train_loss_epoch=43.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 441, global step 15912: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442: 100%|██████████| 36/36 [00:07<00:00,  4.56it/s, v_num=9, train_loss_step=42.70, train_loss_epoch=43.80]Epoch 442: Lr: 0.0000320 | Train Loss: 43.7959290 | Vali Loss: 0.1943325\n",
      "Epoch 442: 100%|██████████| 36/36 [00:08<00:00,  4.05it/s, v_num=9, train_loss_step=42.70, train_loss_epoch=43.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 442, global step 15948: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443: 100%|██████████| 36/36 [00:07<00:00,  4.64it/s, v_num=9, train_loss_step=43.50, train_loss_epoch=43.80]Epoch 443: Lr: 0.0000309 | Train Loss: 43.7643166 | Vali Loss: 0.1954418\n",
      "Epoch 443: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=43.50, train_loss_epoch=43.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 443, global step 15984: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=43.20, train_loss_epoch=43.70]Epoch 444: Lr: 0.0000298 | Train Loss: 43.7351646 | Vali Loss: 0.1926711\n",
      "Epoch 444: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=43.20, train_loss_epoch=43.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 444, global step 16020: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=37.70, train_loss_epoch=43.70]Epoch 445: Lr: 0.0000288 | Train Loss: 43.7071571 | Vali Loss: 0.1943150\n",
      "Epoch 445: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=37.70, train_loss_epoch=43.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 445, global step 16056: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=47.20, train_loss_epoch=43.70]Epoch 446: Lr: 0.0000277 | Train Loss: 43.6789169 | Vali Loss: 0.1925019\n",
      "Epoch 446: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=47.20, train_loss_epoch=43.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 446, global step 16092: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=45.30, train_loss_epoch=43.70]Epoch 447: Lr: 0.0000267 | Train Loss: 43.6536026 | Vali Loss: 0.1941907\n",
      "Epoch 447: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=45.30, train_loss_epoch=43.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 447, global step 16128: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=41.90, train_loss_epoch=43.60]Epoch 448: Lr: 0.0000257 | Train Loss: 43.6316643 | Vali Loss: 0.1939354\n",
      "Epoch 448: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=41.90, train_loss_epoch=43.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 448, global step 16164: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=46.80, train_loss_epoch=43.60]Epoch 449: Lr: 0.0000247 | Train Loss: 43.6050072 | Vali Loss: 0.1919167\n",
      "Epoch 449: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=46.80, train_loss_epoch=43.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 16200: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=41.30, train_loss_epoch=43.60]Epoch 450: Lr: 0.0000238 | Train Loss: 43.5812111 | Vali Loss: 0.1935275\n",
      "Epoch 450: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=41.30, train_loss_epoch=43.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 450, global step 16236: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=42.80, train_loss_epoch=43.60]Epoch 451: Lr: 0.0000228 | Train Loss: 43.5587692 | Vali Loss: 0.1952581\n",
      "Epoch 451: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=42.80, train_loss_epoch=43.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 451, global step 16272: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=46.80, train_loss_epoch=43.50]Epoch 452: Lr: 0.0000219 | Train Loss: 43.5340157 | Vali Loss: 0.1943786\n",
      "Epoch 452: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=46.80, train_loss_epoch=43.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 452, global step 16308: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=45.90, train_loss_epoch=43.50]Epoch 453: Lr: 0.0000210 | Train Loss: 43.5163498 | Vali Loss: 0.1939786\n",
      "Epoch 453: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=45.90, train_loss_epoch=43.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 453, global step 16344: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=53.10, train_loss_epoch=43.50]Epoch 454: Lr: 0.0000201 | Train Loss: 43.4985771 | Vali Loss: 0.1931433\n",
      "Epoch 454: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=53.10, train_loss_epoch=43.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 454, global step 16380: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=44.20, train_loss_epoch=43.50]Epoch 455: Lr: 0.0000192 | Train Loss: 43.4750366 | Vali Loss: 0.1934230\n",
      "Epoch 455: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=44.20, train_loss_epoch=43.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 455, global step 16416: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456: 100%|██████████| 36/36 [00:07<00:00,  4.51it/s, v_num=9, train_loss_step=44.60, train_loss_epoch=43.50]Epoch 456: Lr: 0.0000184 | Train Loss: 43.4570541 | Vali Loss: 0.1933355\n",
      "Epoch 456: 100%|██████████| 36/36 [00:08<00:00,  4.00it/s, v_num=9, train_loss_step=44.60, train_loss_epoch=43.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 456, global step 16452: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=47.70, train_loss_epoch=43.40]Epoch 457: Lr: 0.0000175 | Train Loss: 43.4382706 | Vali Loss: 0.1944097\n",
      "Epoch 457: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=47.70, train_loss_epoch=43.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 457, global step 16488: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=40.00, train_loss_epoch=43.40]Epoch 458: Lr: 0.0000167 | Train Loss: 43.4220200 | Vali Loss: 0.1951721\n",
      "Epoch 458: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=40.00, train_loss_epoch=43.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 458, global step 16524: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=45.20, train_loss_epoch=43.40]Epoch 459: Lr: 0.0000159 | Train Loss: 43.4057465 | Vali Loss: 0.1949509\n",
      "Epoch 459: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=45.20, train_loss_epoch=43.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 16560: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=43.40, train_loss_epoch=43.40]Epoch 460: Lr: 0.0000151 | Train Loss: 43.3886871 | Vali Loss: 0.1952519\n",
      "Epoch 460: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=43.40, train_loss_epoch=43.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 460, global step 16596: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=38.90, train_loss_epoch=43.40]Epoch 461: Lr: 0.0000144 | Train Loss: 43.3764610 | Vali Loss: 0.1929519\n",
      "Epoch 461: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=38.90, train_loss_epoch=43.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 461, global step 16632: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=36.10, train_loss_epoch=43.40]Epoch 462: Lr: 0.0000136 | Train Loss: 43.3565063 | Vali Loss: 0.1939940\n",
      "Epoch 462: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=36.10, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 462, global step 16668: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=46.70, train_loss_epoch=43.30]Epoch 463: Lr: 0.0000129 | Train Loss: 43.3408356 | Vali Loss: 0.1945570\n",
      "Epoch 463: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=46.70, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 463, global step 16704: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=50.70, train_loss_epoch=43.30]Epoch 464: Lr: 0.0000122 | Train Loss: 43.3287430 | Vali Loss: 0.1939738\n",
      "Epoch 464: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=50.70, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 464, global step 16740: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=42.40, train_loss_epoch=43.30]Epoch 465: Lr: 0.0000115 | Train Loss: 43.3160362 | Vali Loss: 0.1938826\n",
      "Epoch 465: 100%|██████████| 36/36 [00:08<00:00,  4.12it/s, v_num=9, train_loss_step=42.40, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 465, global step 16776: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466: 100%|██████████| 36/36 [00:07<00:00,  4.51it/s, v_num=9, train_loss_step=44.30, train_loss_epoch=43.30]Epoch 466: Lr: 0.0000109 | Train Loss: 43.3034821 | Vali Loss: 0.1943228\n",
      "Epoch 466: 100%|██████████| 36/36 [00:09<00:00,  4.00it/s, v_num=9, train_loss_step=44.30, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 466, global step 16812: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=44.80, train_loss_epoch=43.30]Epoch 467: Lr: 0.0000102 | Train Loss: 43.2932014 | Vali Loss: 0.1951231\n",
      "Epoch 467: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=44.80, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 467, global step 16848: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=50.90, train_loss_epoch=43.30]Epoch 468: Lr: 0.0000096 | Train Loss: 43.2823448 | Vali Loss: 0.1948706\n",
      "Epoch 468: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=50.90, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 468, global step 16884: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=40.90, train_loss_epoch=43.30]Epoch 469: Lr: 0.0000090 | Train Loss: 43.2703590 | Vali Loss: 0.1951524\n",
      "Epoch 469: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=40.90, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 16920: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=44.40, train_loss_epoch=43.30]Epoch 470: Lr: 0.0000084 | Train Loss: 43.2595940 | Vali Loss: 0.1935651\n",
      "Epoch 470: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=44.40, train_loss_epoch=43.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 470, global step 16956: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=49.50, train_loss_epoch=43.30]Epoch 471: Lr: 0.0000078 | Train Loss: 43.2505226 | Vali Loss: 0.1935415\n",
      "Epoch 471: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=49.50, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 471, global step 16992: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472: 100%|██████████| 36/36 [00:07<00:00,  4.60it/s, v_num=9, train_loss_step=47.60, train_loss_epoch=43.20]Epoch 472: Lr: 0.0000073 | Train Loss: 43.2414627 | Vali Loss: 0.1928196\n",
      "Epoch 472: 100%|██████████| 36/36 [00:08<00:00,  4.08it/s, v_num=9, train_loss_step=47.60, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 472, global step 17028: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=42.50, train_loss_epoch=43.20]Epoch 473: Lr: 0.0000068 | Train Loss: 43.2334709 | Vali Loss: 0.1956840\n",
      "Epoch 473: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=42.50, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 473, global step 17064: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=41.10, train_loss_epoch=43.20]Epoch 474: Lr: 0.0000063 | Train Loss: 43.2262840 | Vali Loss: 0.1942692\n",
      "Epoch 474: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=41.10, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 474, global step 17100: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=42.10, train_loss_epoch=43.20]Epoch 475: Lr: 0.0000058 | Train Loss: 43.2187538 | Vali Loss: 0.1954785\n",
      "Epoch 475: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=42.10, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 475, global step 17136: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476: 100%|██████████| 36/36 [00:07<00:00,  4.57it/s, v_num=9, train_loss_step=44.80, train_loss_epoch=43.20]Epoch 476: Lr: 0.0000053 | Train Loss: 43.2114944 | Vali Loss: 0.1931073\n",
      "Epoch 476: 100%|██████████| 36/36 [00:08<00:00,  4.06it/s, v_num=9, train_loss_step=44.80, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 476, global step 17172: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477: 100%|██████████| 36/36 [00:07<00:00,  4.63it/s, v_num=9, train_loss_step=41.70, train_loss_epoch=43.20]Epoch 477: Lr: 0.0000048 | Train Loss: 43.2066383 | Vali Loss: 0.1948674\n",
      "Epoch 477: 100%|██████████| 36/36 [00:08<00:00,  4.10it/s, v_num=9, train_loss_step=41.70, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 477, global step 17208: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478: 100%|██████████| 36/36 [00:07<00:00,  4.73it/s, v_num=9, train_loss_step=41.10, train_loss_epoch=43.20]Epoch 478: Lr: 0.0000044 | Train Loss: 43.1995049 | Vali Loss: 0.1937206\n",
      "Epoch 478: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=41.10, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 478, global step 17244: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479: 100%|██████████| 36/36 [00:07<00:00,  4.53it/s, v_num=9, train_loss_step=47.60, train_loss_epoch=43.20]Epoch 479: Lr: 0.0000040 | Train Loss: 43.1949692 | Vali Loss: 0.1935105\n",
      "Epoch 479: 100%|██████████| 36/36 [00:08<00:00,  4.02it/s, v_num=9, train_loss_step=47.60, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 17280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=36.50, train_loss_epoch=43.20]Epoch 480: Lr: 0.0000036 | Train Loss: 43.1902771 | Vali Loss: 0.1951068\n",
      "Epoch 480: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=36.50, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 480, global step 17316: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=40.20, train_loss_epoch=43.20]Epoch 481: Lr: 0.0000032 | Train Loss: 43.1858902 | Vali Loss: 0.1937278\n",
      "Epoch 481: 100%|██████████| 36/36 [00:08<00:00,  4.14it/s, v_num=9, train_loss_step=40.20, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 481, global step 17352: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482: 100%|██████████| 36/36 [00:07<00:00,  4.71it/s, v_num=9, train_loss_step=45.80, train_loss_epoch=43.20]Epoch 482: Lr: 0.0000029 | Train Loss: 43.1807747 | Vali Loss: 0.1937516\n",
      "Epoch 482: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=45.80, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 482, global step 17388: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483: 100%|██████████| 36/36 [00:07<00:00,  4.52it/s, v_num=9, train_loss_step=47.80, train_loss_epoch=43.20]Epoch 483: Lr: 0.0000026 | Train Loss: 43.1766090 | Vali Loss: 0.1937496\n",
      "Epoch 483: 100%|██████████| 36/36 [00:08<00:00,  4.01it/s, v_num=9, train_loss_step=47.80, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 483, global step 17424: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=38.20, train_loss_epoch=43.20]Epoch 484: Lr: 0.0000023 | Train Loss: 43.1725845 | Vali Loss: 0.1936028\n",
      "Epoch 484: 100%|██████████| 36/36 [00:08<00:00,  4.18it/s, v_num=9, train_loss_step=38.20, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 484, global step 17460: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=39.30, train_loss_epoch=43.20]Epoch 485: Lr: 0.0000020 | Train Loss: 43.1695976 | Vali Loss: 0.1939795\n",
      "Epoch 485: 100%|██████████| 36/36 [00:08<00:00,  4.16it/s, v_num=9, train_loss_step=39.30, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 485, global step 17496: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486: 100%|██████████| 36/36 [00:07<00:00,  4.57it/s, v_num=9, train_loss_step=40.80, train_loss_epoch=43.20]Epoch 486: Lr: 0.0000017 | Train Loss: 43.1668167 | Vali Loss: 0.1943848\n",
      "Epoch 486: 100%|██████████| 36/36 [00:08<00:00,  4.05it/s, v_num=9, train_loss_step=40.80, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 486, global step 17532: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=49.90, train_loss_epoch=43.20]Epoch 487: Lr: 0.0000014 | Train Loss: 43.1645927 | Vali Loss: 0.1941445\n",
      "Epoch 487: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=49.90, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 487, global step 17568: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=46.20, train_loss_epoch=43.20]Epoch 488: Lr: 0.0000012 | Train Loss: 43.1623306 | Vali Loss: 0.1941942\n",
      "Epoch 488: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=46.20, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 488, global step 17604: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=41.70, train_loss_epoch=43.20]Epoch 489: Lr: 0.0000010 | Train Loss: 43.1608200 | Vali Loss: 0.1943053\n",
      "Epoch 489: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=41.70, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 17640: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=45.60, train_loss_epoch=43.20]Epoch 490: Lr: 0.0000008 | Train Loss: 43.1589584 | Vali Loss: 0.1939177\n",
      "Epoch 490: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=45.60, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 490, global step 17676: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491: 100%|██████████| 36/36 [00:07<00:00,  4.65it/s, v_num=9, train_loss_step=44.40, train_loss_epoch=43.20]Epoch 491: Lr: 0.0000006 | Train Loss: 43.1577492 | Vali Loss: 0.1943026\n",
      "Epoch 491: 100%|██████████| 36/36 [00:08<00:00,  4.11it/s, v_num=9, train_loss_step=44.40, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 491, global step 17712: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=40.60, train_loss_epoch=43.20]Epoch 492: Lr: 0.0000005 | Train Loss: 43.1562653 | Vali Loss: 0.1941340\n",
      "Epoch 492: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=40.60, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 492, global step 17748: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493: 100%|██████████| 36/36 [00:07<00:00,  4.67it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=43.20]Epoch 493: Lr: 0.0000004 | Train Loss: 43.1554871 | Vali Loss: 0.1941851\n",
      "Epoch 493: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=49.60, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 493, global step 17784: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494: 100%|██████████| 36/36 [00:07<00:00,  4.61it/s, v_num=9, train_loss_step=49.50, train_loss_epoch=43.20]Epoch 494: Lr: 0.0000003 | Train Loss: 43.1547546 | Vali Loss: 0.1942017\n",
      "Epoch 494: 100%|██████████| 36/36 [00:08<00:00,  4.09it/s, v_num=9, train_loss_step=49.50, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 494, global step 17820: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495: 100%|██████████| 36/36 [00:07<00:00,  4.69it/s, v_num=9, train_loss_step=40.50, train_loss_epoch=43.20]Epoch 495: Lr: 0.0000002 | Train Loss: 43.1539612 | Vali Loss: 0.1942051\n",
      "Epoch 495: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=40.50, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 495, global step 17856: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496: 100%|██████████| 36/36 [00:07<00:00,  4.68it/s, v_num=9, train_loss_step=46.50, train_loss_epoch=43.20]Epoch 496: Lr: 0.0000001 | Train Loss: 43.1535454 | Vali Loss: 0.1941925\n",
      "Epoch 496: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=46.50, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 496, global step 17892: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497: 100%|██████████| 36/36 [00:07<00:00,  4.66it/s, v_num=9, train_loss_step=42.30, train_loss_epoch=43.20]Epoch 497: Lr: 0.0000000 | Train Loss: 43.1532211 | Vali Loss: 0.1942137\n",
      "Epoch 497: 100%|██████████| 36/36 [00:08<00:00,  4.13it/s, v_num=9, train_loss_step=42.30, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 497, global step 17928: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498: 100%|██████████| 36/36 [00:07<00:00,  4.72it/s, v_num=9, train_loss_step=42.00, train_loss_epoch=43.20]Epoch 498: Lr: 0.0000000 | Train Loss: 43.1531029 | Vali Loss: 0.1942054\n",
      "Epoch 498: 100%|██████████| 36/36 [00:08<00:00,  4.17it/s, v_num=9, train_loss_step=42.00, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 498, global step 17964: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 36/36 [00:07<00:00,  4.70it/s, v_num=9, train_loss_step=38.30, train_loss_epoch=43.20]Epoch 499: Lr: 0.0000000 | Train Loss: 43.1529884 | Vali Loss: 0.1942104\n",
      "Epoch 499: 100%|██████████| 36/36 [00:08<00:00,  4.15it/s, v_num=9, train_loss_step=38.30, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 18000: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 36/36 [00:08<00:00,  4.03it/s, v_num=9, train_loss_step=38.30, train_loss_epoch=43.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> testing  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 13.92it/s]mse:641.60595703125, mae:996.1414794921875\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:01<00:00,  9.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# train and test\n",
    "print('>'*35 + ' training ' + '<'*35)\n",
    "exp.train()\n",
    "\n",
    "print('>'*35 + ' testing  ' + '<'*35)\n",
    "exp.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0690dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ssp for pred and ture with shape [num,nx,ny,nt]\n",
    "def get_ssp(pred,true,ax=(1,2)):\n",
    "    fpred = np.fft.fft2(pred,axes=ax)\n",
    "    ftrue = np.fft.fft2(true,axes=ax)\n",
    "    norm_error = np.linalg.norm(fpred-ftrue,axis=ax)\n",
    "    norm_pred = np.linalg.norm(fpred,axis=ax)\n",
    "    norm_true = np.linalg.norm(ftrue,axis=ax)\n",
    "    ssps = norm_error/(norm_pred+norm_true)\n",
    "    ssp = np.mean(ssps)\n",
    "    return ssp,ssps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized by Hs->rmse_u:0.202652, mae_u:0.142464, ssp_u:0.264106\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# show the given frames from an example\n",
    "inputs = np.load('./work_dirs/convlstm/saved/inputs.npy')\n",
    "preds = np.load('./work_dirs/convlstm/saved/preds.npy')\n",
    "trues = np.load('./work_dirs/convlstm/saved/trues.npy')\n",
    "# [n,16,1,64,64]->[n,64,64,16]\n",
    "true_u = trues.squeeze(2).transpose(0,2,3,1)\n",
    "pred_u = preds.squeeze(2).transpose(0,2,3,1)\n",
    "# mean over axis 1,2,3 while keep axis 0, then normalized with hs\n",
    "#rmse_e_hs = np.mean(np.sqrt(np.mean((pred_e-true_e)**2,axis=(1,2,3)))/hs)\n",
    "rmse_u_hs = np.mean(np.sqrt(np.mean((pred_u-true_u)**2,axis=(1,2,3)))/hs)\n",
    "#mae_e_hs = np.mean(np.mean(np.abs(pred_e-true_e),axis=(1,2,3))/hs)\n",
    "mae_u_hs = np.mean(np.mean(np.abs(pred_u-true_u),axis=(1,2,3))/hs)\n",
    "#ssp_e,ssps_e = get_ssp(pred_e,true_e)\n",
    "ssp_u,ssps_u = get_ssp(pred_u,true_u)\n",
    "#print('normalized by Hs->rmse_e:%f, rmse_u:%f, mae_e:%f, mae_u:%f, ssp_e:%f, ssp_u:%f' % (rmse_e_hs,rmse_u_hs,mae_e_hs,mae_u_hs,ssp_e,ssp_u)) \n",
    "print('normalized by Hs->rmse_u:%f, mae_u:%f, ssp_u:%f' % (rmse_u_hs,mae_u_hs,ssp_u)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16645c8",
   "metadata": {},
   "source": [
    "The results of ConvLSTM and SimVP-gSTA: \n",
    "\n",
    "| Model   | MAE/Hs | RMSE/Hs | SSP |\n",
    "|---------|-----|------|-----|\n",
    "| ConvLSTM|  0.142464   | 0.202652     | 0.264106    |\n",
    "| SimVP   |  0.073016   | 0.116635     | 0.139385    |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSTL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
