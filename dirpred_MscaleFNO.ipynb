{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct prediction based on MscaleFNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "from neuralop.models import TFNO,FNO\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "from utilities3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_paths, inlen=16, outlen=16):\n",
    "    eta = []\n",
    "    scatter = []\n",
    "    len = inlen + outlen\n",
    "    for f in file_paths:\n",
    "        reader = MatReader(f, to_torch=False)\n",
    "        eta_tmp = reader.read_field('eta')\n",
    "        scatter_tmp = reader.read_field('scatter')\n",
    "        eta_tmp = eta_tmp[:,:,:,117:437]\n",
    "        scatter_tmp = scatter_tmp[:,:,:,117:437]\n",
    "        #print(eta_tmp.shape,scatter_tmp.shape)\n",
    "        slice_eta = []\n",
    "        slice_scatter = []\n",
    "        for i in range(10):\n",
    "            slice_eta.append(eta_tmp[:,:,:,32*i:32*(i+1)])\n",
    "            slice_scatter.append(scatter_tmp[:,:,:,32*i:32*(i+1)])\n",
    "        eta_tmp = np.concatenate(slice_eta,axis=0)\n",
    "        scatter_tmp = np.concatenate(slice_scatter,axis=0)\n",
    "        #print(eta_tmp.shape,scatter_tmp.shape)\n",
    "        x = reader.read_field('x').flatten()\n",
    "        y = reader.read_field('y').flatten()\n",
    "        t = reader.read_field('t').flatten()\n",
    "        t = t[0:32] \n",
    "        if eta == []:\n",
    "            eta = eta_tmp\n",
    "            scatter = scatter_tmp\n",
    "        else:\n",
    "            eta = np.concatenate([eta,eta_tmp])\n",
    "            scatter = np.concatenate([scatter,scatter_tmp])\n",
    "    return eta, scatter, x, y, t\n",
    "\n",
    "def split_data(eta, scatter, train_test_split=[0.6,0.2,0.2], inlen=16, outlen=16, sub=2, to_torch=False):\n",
    "    train_size = int(eta.shape[0]*train_test_split[0])\n",
    "    test_size = int(eta.shape[0]*train_test_split[2])\n",
    "    train_a = scatter[:train_size,::sub,::sub,:inlen]\n",
    "    train_e = eta[:train_size,::sub,::sub,:inlen]\n",
    "    train_u = eta[:train_size,::sub,::sub,inlen:inlen+outlen]\n",
    "    val_a = scatter[train_size:train_size+test_size,::sub,::sub,:inlen]\n",
    "    val_e = eta[train_size:train_size+test_size,::sub,::sub,:inlen]\n",
    "    val_u = eta[train_size:train_size+test_size,::sub,::sub,inlen:inlen+outlen]\n",
    "    test_a = scatter[train_size+test_size:,::sub,::sub,:inlen]\n",
    "    test_e = eta[train_size+test_size:,::sub,::sub,:inlen]\n",
    "    test_u = eta[train_size+test_size:,::sub,::sub,inlen:inlen+outlen]\n",
    "    if to_torch:\n",
    "        train_a = torch.from_numpy(train_a)\n",
    "        train_e = torch.from_numpy(train_e)\n",
    "        train_u = torch.from_numpy(train_u)\n",
    "        val_a = torch.from_numpy(val_a)\n",
    "        val_e = torch.from_numpy(val_e)\n",
    "        val_u = torch.from_numpy(val_u)\n",
    "        test_a = torch.from_numpy(test_a)\n",
    "        test_e = torch.from_numpy(test_e)\n",
    "        test_u = torch.from_numpy(test_u)\n",
    "    return train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u\n",
    "\n",
    "# read and split data, for each datafile, spilit it in to train,val and test then concatenate them, add hs and spread tag in the filename, length the same as the test array\n",
    "def read_and_split(file_paths, train_test_split=[0.6,0.2,0.2], inlen=16, outlen=16, sub=2, to_torch=False):\n",
    "    eta, scatter, x, y, t = read_data([file_paths[0]], inlen=inlen, outlen=outlen)\n",
    "    train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u = split_data(eta, scatter, train_test_split=train_test_split, inlen=inlen, outlen=outlen, sub=sub, to_torch=to_torch)\n",
    "    hs = float(file_paths[0].split('angle')[1].split('h')[1].split('.mat')[0]) * np.ones(test_a.shape[0])   \n",
    "    spread = float(file_paths[0].split('angle')[1].split('h')[0]) * np.ones(test_a.shape[0]) \n",
    "\n",
    "    for i,f in enumerate(file_paths):\n",
    "        if i>0:\n",
    "            eta, scatter, x, y, t = read_data([f], inlen=inlen, outlen=outlen)\n",
    "            train_a_tmp, train_e_tmp, train_u_tmp, val_a_tmp, val_e_tmp, val_u_tmp, test_a_tmp, test_e_tmp, test_u_tmp = split_data(eta, scatter, train_test_split=train_test_split, inlen=inlen, outlen=outlen, sub=sub, to_torch=to_torch)\n",
    "            train_a = np.concatenate([train_a,train_a_tmp])\n",
    "            train_e = np.concatenate([train_e,train_e_tmp])\n",
    "            train_u = np.concatenate([train_u,train_u_tmp])\n",
    "            val_a = np.concatenate([val_a,val_a_tmp])\n",
    "            val_e = np.concatenate([val_e,val_e_tmp])\n",
    "            val_u = np.concatenate([val_u,val_u_tmp])\n",
    "            test_a = np.concatenate([test_a,test_a_tmp])\n",
    "            test_e = np.concatenate([test_e,test_e_tmp])\n",
    "            test_u = np.concatenate([test_u,test_u_tmp])\n",
    "            hs = np.concatenate([hs,float(f.split('angle')[1].split('h')[1].split('.mat')[0]) * np.ones(test_a_tmp.shape[0])])\n",
    "            spread = np.concatenate([spread,float(f.split('angle')[1].split('h')[0]) * np.ones(test_a_tmp.shape[0])])\n",
    "    if to_torch:\n",
    "        train_a = torch.from_numpy(train_a)\n",
    "        train_e = torch.from_numpy(train_e)\n",
    "        train_u = torch.from_numpy(train_u)\n",
    "        val_a = torch.from_numpy(val_a)\n",
    "        val_e = torch.from_numpy(val_e)\n",
    "        val_u = torch.from_numpy(val_u)\n",
    "        test_a = torch.from_numpy(test_a)\n",
    "        test_e = torch.from_numpy(test_e)\n",
    "        test_u = torch.from_numpy(test_u)\n",
    "        hs = torch.from_numpy(hs)\n",
    "        spread = torch.from_numpy(spread)\n",
    "\n",
    "    return train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u, x, y, t, hs, spread\n",
    "\n",
    "dirs = os.listdir(\"./mixed_data\")\n",
    "dirs = [os.path.join(\"./mixed_data\",d) for d in dirs]\n",
    "# add another dir\n",
    "dirs2 = os.listdir(\"./mixed_data2\")\n",
    "dirs2 = [os.path.join(\"./mixed_data2\",d) for d in dirs2]\n",
    "dirs = dirs + dirs2\n",
    "train_a, train_e, train_u, val_a, val_e, val_u, test_a, test_e, test_u,x_domain,y_domain,t_domain,hs, spread = read_and_split(dirs,inlen=16,outlen=16,sub=2,to_torch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter and logging setup\n",
    "modesxy = 32\n",
    "modest = 8\n",
    "width = 64\n",
    "n_net = 1\n",
    "cnnfusion = False\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "batch_size = 20\n",
    "iterations = epochs*(train_u.shape[0]//batch_size)\n",
    "prefix = \"dirpred\"\n",
    "path = 'exp/'+prefix+ '_m' + str(modesxy) + str(modest) + '_w' + str(width)+ '_n' + str(n_net)+ '_cnnfusion'+ str(cnnfusion) \n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "path_model = path+'/model'\n",
    "path_train_err = path+'/train.txt'\n",
    "path_test_err = path+'/test.txt'\n",
    "path_image = path+'/image'\n",
    "if not os.path.exists(path_image):\n",
    "    os.mkdir(path_image)\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "sh = logging.StreamHandler()\n",
    "log_file = path+'/train'+ datetime.datetime.now().strftime('%Y%m%d_%H%M%S')+'.log'\n",
    "fh = logging.FileHandler(log_file,encoding=\"UTF-8\")\n",
    "formator = logging.Formatter(fmt = '%(asctime)s : %(message)s')\n",
    "sh.setFormatter(formator)\n",
    "fh.setFormatter(formator)\n",
    "logger.addHandler(sh)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 2  \n",
    "S = 128 // sub\n",
    "T_in = 16\n",
    "T = 16 \n",
    "\n",
    "ntrain = train_a.shape[0]\n",
    "nval = val_a.shape[0]\n",
    "ntest = test_a.shape[0]\n",
    "train_a = train_a.reshape(ntrain,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "val_a = val_a.reshape(nval,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "test_a = test_a.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-scale FNO which is a combination of N FNO\n",
    "class multiscaleFNO(nn.Module):\n",
    "    def __init__(self,modes1,modes2,modes3,width,n_net):\n",
    "        super(multiscaleFNO, self).__init__()\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.n_net = n_net\n",
    "        self.fno_subnets = nn.ModuleList([FNO(n_modes=(self.modes1,self.modes2,self.modes3),\n",
    "                          n_layers=4,hidden_channels=self.width, \n",
    "                          lifting_channels = 2*self.width, \n",
    "                          projection_channels=2*self.width,in_channels=T_in+3, out_channels=1) for _ in range(n_net)])\n",
    "        #self.cs = nn.Parameter(torch.randn(n_net), requires_grad=True)\n",
    "        # give initial value to cs\n",
    "        self.cs = torch.nn.Parameter(torch.pow(2,torch.arange(-1,n_net-1,dtype=torch.float32)),requires_grad=True) \n",
    "        #self.cs = torch.nn.Parameter(torch.arange(1,n_net+1,dtype=torch.float32),requires_grad=True) \n",
    "        #self.cs = torch.nn.Parameter(torch.tensor([1.0,80.0,160.0,200.0,240.0,280.0,360.0,400.0]),requires_grad=True) \n",
    "        self.gammas = torch.nn.Parameter(torch.tensor([1.0/n_net]*n_net),requires_grad=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        results = []\n",
    "        for i in range(self.n_net):\n",
    "            scaled_x = self.cs[i] * x\n",
    "            subnet_output = self.fno_subnets[i](scaled_x)\n",
    "            weighted_output = self.gammas[i] * subnet_output\n",
    "            results.append(weighted_output)\n",
    "        u = sum(results)\n",
    "        return u\n",
    "\n",
    "# testcase, input shape [batch, chanel, S, S, T_in]\n",
    "#input = torch.randn(10, 19, 32, 32, 16)\n",
    "#model = multiscaleFNO(8, 8, 8, 32, n_net=4)\n",
    "#output = model(input)\n",
    "#print(\"input shape: \", input.shape)\n",
    "#print(\"output shape: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiscaleFNOcnnFusion(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width, n_net):\n",
    "        super(multiscaleFNOcnnFusion, self).__init__()\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.n_net = n_net\n",
    "        \n",
    "        self.fno_subnets = nn.ModuleList([\n",
    "            FNO(n_modes=(self.modes1, self.modes2, self.modes3),\n",
    "                n_layers=4,\n",
    "                hidden_channels=self.width, \n",
    "                lifting_channels=2*self.width,\n",
    "                projection_channels=2*self.width,\n",
    "                in_channels=T_in+3,\n",
    "                out_channels=1) \n",
    "            for _ in range(n_net)\n",
    "        ])\n",
    "        \n",
    "        self.cs = torch.nn.Parameter(\n",
    "            torch.pow(2, torch.arange(-1, n_net-1, dtype=torch.float32)),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.fusion_net = nn.Sequential(\n",
    "            nn.Conv3d(n_net, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取每个子网络的输出\n",
    "        subnet_outputs = []\n",
    "        for i in range(self.n_net):\n",
    "            scaled_x = self.cs[i] * x\n",
    "            subnet_output = self.fno_subnets[i](scaled_x)\n",
    "            subnet_outputs.append(subnet_output)\n",
    "        \n",
    "        # 将所有输出堆叠在一起 [batch, n_net, x, y, t]\n",
    "        stacked_outputs = torch.stack(subnet_outputs, dim=1).squeeze(2)\n",
    "        # stacked_outputs.shape = [batch, n_net, x, y, t]\n",
    "        #print(\"stacked_outputs shape: \", stacked_outputs.shape)\n",
    "        # 通过融合网络 \n",
    "        fused_output = self.fusion_net(stacked_outputs)\n",
    "        \n",
    "        # 移除多余的维度 [batch, 1, x, y, t] -> [batch, x, y, t]\n",
    "        #output = fused_output.squeeze(1)\n",
    "        \n",
    "        return fused_output\n",
    "\n",
    "# testcase, input shape [batch, chanel, S, S, T_in]\n",
    "#input = torch.randn(10, 19, 64, 64, 16)\n",
    "#model = multiscaleFNOcnnFusion(8, 8, 8, 32, n_net=8)\n",
    "#output = model(input)\n",
    "#print(\"input shape: \", input.shape)\n",
    "#print(\"output shape: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO_dir(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width,net,cnnfusion=False):\n",
    "        super(FNO_dir, self).__init__()\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        '''\n",
    "        self.fno_r = TFNO(n_modes=(self.modes1, self.modes2, self.modes3), hidden_channels=self.width,\n",
    "                        in_channels=19,\n",
    "                        out_channels=1,\n",
    "                        factorization='tucker',\n",
    "                        implementation='factorized',\n",
    "                        n_layers=4,\n",
    "                        rank=0.05)\n",
    "        self.fno_p = TFNO(n_modes=(self.modes1, self.modes2, self.modes3), hidden_channels=self.width,\n",
    "                        in_channels=19,\n",
    "                        out_channels=1,\n",
    "                        factorization='tucker',\n",
    "                        implementation='factorized',\n",
    "                        n_layers=4,\n",
    "                        rank=0.05)\n",
    "        '''\n",
    "        #self.fno_r = FNO(n_modes=(self.modes1,self.modes2,self.modes3), n_layers=4,hidden_channels=self.width, lifting_channels = self.width, projection_channels=self.width,in_channels=19, out_channels=1)\n",
    "        #self.fno_p = FNO(n_modes=(self.modes1,self.modes2,self.modes3), n_layers=4,hidden_channels=self.width, lifting_channels = self.width, projection_channels=self.width,in_channels=19, out_channels=1)\n",
    "        if cnnfusion:\n",
    "            self.fno_r = multiscaleFNOcnnFusion(self.modes1, self.modes2, self.modes3, self.width, n_net=net)\n",
    "            #self.fno_p = multiscaleFNOcnnFusion(self.modes1, self.modes2, self.modes3, self.width, n_net=net)\n",
    "        else:\n",
    "            if net == 1:\n",
    "                self.fno_r = FNO(n_modes=(self.modes1,self.modes2,self.modes3), n_layers=4,hidden_channels=self.width, lifting_channels = 2*self.width, projection_channels=2*self.width,in_channels=T_in+3, out_channels=1)\n",
    "            else:\n",
    "                self.fno_r = multiscaleFNO(self.modes1, self.modes2, self.modes3, self.width, n_net=net)\n",
    "            #self.fno_p = multiscaleFNO(self.modes1, self.modes2, self.modes3, self.width, n_net=net)\n",
    "    def forward(self,x):\n",
    "        #x = x.permute(0,4,2,3,1).repeat([1,1,1,1,10])\n",
    "        x = self.get_grid(x)\n",
    "        x = self.fno_r(x)\n",
    "        return x   \n",
    "    def get_grid(self,x):\n",
    "        # x[batch,x,y,t,c]\n",
    "        # output[batch,c+3,x,y,t]\n",
    "        shape,device = x.shape,x.device\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, x_domain[-1]-x_domain[0], size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, y_domain[-1]-y_domain[0], size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, t_domain[-1]-t_domain[0], size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        grid = torch.cat((gridx, gridy, gridz), dim=-1).to(device)\n",
    "        x = torch.cat((x,grid),dim=-1)\n",
    "        x = x.permute(0,4,1,2,3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 02:14:16,418 : models params: 134244097\n"
     ]
    }
   ],
   "source": [
    "def ssp_loss(pred, true, ax=(1, 2)):\n",
    "    fpred = torch.fft.fftn(pred, dim=ax)\n",
    "    ftrue = torch.fft.fftn(true, dim=ax)\n",
    "    norm_error = torch.norm(fpred-ftrue, dim=ax)\n",
    "    norm_pred = torch.norm(fpred, dim=ax)\n",
    "    norm_true = torch.norm(ftrue, dim=ax)\n",
    "    ssps = norm_error / (norm_pred + norm_true)\n",
    "    ssp = torch.sum(torch.mean(ssps, dim=-1))\n",
    "    return ssp\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = FNO_dir(modesxy,modesxy,modest,width,n_net,cnnfusion).cuda() #change\n",
    "#print(count_params(model))\n",
    "logger.info(\"models params: %d\" % count_params(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations)\n",
    "myloss = LpLoss(size_average=False)\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(val_a, val_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 02:14:27,093 : epoch:0, time:10.659605, train_mse:0.653252, train_l2:1.167531,  test_l2:0.631481\n",
      "2025-05-08 02:14:27,644 : best model saved\n",
      "2025-05-08 02:14:37,069 : epoch:1, time:9.423625, train_mse:0.188966, train_l2:0.523786,  test_l2:0.458060\n",
      "2025-05-08 02:14:37,706 : best model saved\n",
      "2025-05-08 02:14:47,049 : epoch:2, time:9.342071, train_mse:0.116644, train_l2:0.425006,  test_l2:0.411647\n",
      "2025-05-08 02:14:47,860 : best model saved\n",
      "2025-05-08 02:14:57,055 : epoch:3, time:9.193546, train_mse:0.096686, train_l2:0.387420,  test_l2:0.400775\n",
      "2025-05-08 02:14:57,786 : best model saved\n",
      "2025-05-08 02:15:06,947 : epoch:4, time:9.157879, train_mse:0.085154, train_l2:0.366656,  test_l2:0.400742\n",
      "2025-05-08 02:15:07,601 : best model saved\n",
      "2025-05-08 02:15:16,767 : epoch:5, time:9.164533, train_mse:0.077212, train_l2:0.349248,  test_l2:0.391694\n",
      "2025-05-08 02:15:17,519 : best model saved\n",
      "2025-05-08 02:15:26,779 : epoch:6, time:9.257969, train_mse:0.067210, train_l2:0.324102,  test_l2:0.394865\n",
      "2025-05-08 02:15:35,875 : epoch:7, time:9.092903, train_mse:0.061554, train_l2:0.312516,  test_l2:0.387805\n",
      "2025-05-08 02:15:36,705 : best model saved\n",
      "2025-05-08 02:15:46,083 : epoch:8, time:9.375589, train_mse:0.054320, train_l2:0.293763,  test_l2:0.384640\n",
      "2025-05-08 02:15:46,794 : best model saved\n",
      "2025-05-08 02:15:56,058 : epoch:9, time:9.262081, train_mse:0.051880, train_l2:0.292781,  test_l2:0.392260\n",
      "2025-05-08 02:16:05,118 : epoch:10, time:9.054063, train_mse:0.047744, train_l2:0.277112,  test_l2:0.380219\n",
      "2025-05-08 02:16:05,850 : best model saved\n",
      "2025-05-08 02:16:15,303 : epoch:11, time:9.451646, train_mse:0.044808, train_l2:0.270829,  test_l2:0.379799\n",
      "2025-05-08 02:16:16,033 : best model saved\n",
      "2025-05-08 02:16:25,529 : epoch:12, time:9.494721, train_mse:0.044118, train_l2:0.266080,  test_l2:0.381349\n",
      "2025-05-08 02:16:34,888 : epoch:13, time:9.355589, train_mse:0.041036, train_l2:0.258145,  test_l2:0.376584\n",
      "2025-05-08 02:16:35,634 : best model saved\n",
      "2025-05-08 02:16:44,977 : epoch:14, time:9.340804, train_mse:0.038608, train_l2:0.250344,  test_l2:0.374687\n",
      "2025-05-08 02:16:45,715 : best model saved\n",
      "2025-05-08 02:16:54,877 : epoch:15, time:9.161163, train_mse:0.037278, train_l2:0.245734,  test_l2:0.377262\n",
      "2025-05-08 02:17:04,153 : epoch:16, time:9.272622, train_mse:0.036420, train_l2:0.244242,  test_l2:0.383833\n",
      "2025-05-08 02:17:13,274 : epoch:17, time:9.117602, train_mse:0.036982, train_l2:0.249555,  test_l2:0.376748\n",
      "2025-05-08 02:17:22,671 : epoch:18, time:9.393314, train_mse:0.035785, train_l2:0.246474,  test_l2:0.380657\n",
      "2025-05-08 02:17:32,008 : epoch:19, time:9.334011, train_mse:0.034788, train_l2:0.239987,  test_l2:0.372910\n",
      "2025-05-08 02:17:32,744 : best model saved\n",
      "2025-05-08 02:17:41,831 : epoch:20, time:9.084496, train_mse:0.034122, train_l2:0.235759,  test_l2:0.370415\n",
      "2025-05-08 02:17:42,539 : best model saved\n",
      "2025-05-08 02:17:51,827 : epoch:21, time:9.285121, train_mse:0.032823, train_l2:0.230896,  test_l2:0.368083\n",
      "2025-05-08 02:17:52,559 : best model saved\n",
      "2025-05-08 02:18:01,723 : epoch:22, time:9.159945, train_mse:0.031713, train_l2:0.227062,  test_l2:0.367142\n",
      "2025-05-08 02:18:02,471 : best model saved\n",
      "2025-05-08 02:18:11,739 : epoch:23, time:9.265396, train_mse:0.031491, train_l2:0.226882,  test_l2:0.369395\n",
      "2025-05-08 02:18:20,945 : epoch:24, time:9.202422, train_mse:0.031455, train_l2:0.227687,  test_l2:0.366513\n",
      "2025-05-08 02:18:21,655 : best model saved\n",
      "2025-05-08 02:18:31,020 : epoch:25, time:9.362291, train_mse:0.031353, train_l2:0.228050,  test_l2:0.373199\n",
      "2025-05-08 02:18:40,265 : epoch:26, time:9.242610, train_mse:0.030852, train_l2:0.224287,  test_l2:0.367656\n",
      "2025-05-08 02:18:49,374 : epoch:27, time:9.105509, train_mse:0.029577, train_l2:0.219228,  test_l2:0.364078\n",
      "2025-05-08 02:18:50,112 : best model saved\n",
      "2025-05-08 02:18:59,288 : epoch:28, time:9.174762, train_mse:0.029110, train_l2:0.218123,  test_l2:0.369955\n",
      "2025-05-08 02:19:08,324 : epoch:29, time:9.032389, train_mse:0.031018, train_l2:0.224299,  test_l2:0.366150\n",
      "2025-05-08 02:19:17,479 : epoch:30, time:9.148511, train_mse:0.029084, train_l2:0.217698,  test_l2:0.363299\n",
      "2025-05-08 02:19:18,190 : best model saved\n",
      "2025-05-08 02:19:27,506 : epoch:31, time:9.314441, train_mse:0.028070, train_l2:0.213437,  test_l2:0.363435\n",
      "2025-05-08 02:19:36,933 : epoch:32, time:9.424915, train_mse:0.027558, train_l2:0.211934,  test_l2:0.363581\n",
      "2025-05-08 02:19:45,981 : epoch:33, time:9.045074, train_mse:0.027382, train_l2:0.210863,  test_l2:0.366096\n",
      "2025-05-08 02:19:55,228 : epoch:34, time:9.242983, train_mse:0.028830, train_l2:0.216448,  test_l2:0.366041\n",
      "2025-05-08 02:20:04,546 : epoch:35, time:9.314681, train_mse:0.029568, train_l2:0.221134,  test_l2:0.364068\n",
      "2025-05-08 02:20:13,460 : epoch:36, time:8.909683, train_mse:0.028977, train_l2:0.218882,  test_l2:0.361959\n",
      "2025-05-08 02:20:14,173 : best model saved\n",
      "2025-05-08 02:20:23,195 : epoch:37, time:9.019397, train_mse:0.027047, train_l2:0.209516,  test_l2:0.362588\n",
      "2025-05-08 02:20:32,076 : epoch:38, time:8.875772, train_mse:0.026881, train_l2:0.209423,  test_l2:0.367184\n",
      "2025-05-08 02:20:41,519 : epoch:39, time:9.435604, train_mse:0.027515, train_l2:0.212276,  test_l2:0.366416\n",
      "2025-05-08 02:20:51,297 : epoch:40, time:9.775345, train_mse:0.028318, train_l2:0.215282,  test_l2:0.363105\n",
      "2025-05-08 02:21:01,732 : epoch:41, time:10.429775, train_mse:0.026563, train_l2:0.207769,  test_l2:0.360394\n",
      "2025-05-08 02:21:02,498 : best model saved\n",
      "2025-05-08 02:21:12,847 : epoch:42, time:10.347189, train_mse:0.025445, train_l2:0.203205,  test_l2:0.363694\n",
      "2025-05-08 02:21:23,437 : epoch:43, time:10.587711, train_mse:0.025260, train_l2:0.202760,  test_l2:0.361214\n",
      "2025-05-08 02:21:33,642 : epoch:44, time:10.201809, train_mse:0.025423, train_l2:0.204196,  test_l2:0.363100\n",
      "2025-05-08 02:21:43,675 : epoch:45, time:10.030838, train_mse:0.025098, train_l2:0.202725,  test_l2:0.364343\n",
      "2025-05-08 02:21:53,570 : epoch:46, time:9.892007, train_mse:0.025513, train_l2:0.203936,  test_l2:0.360319\n",
      "2025-05-08 02:21:54,286 : best model saved\n",
      "2025-05-08 02:22:04,556 : epoch:47, time:10.266477, train_mse:0.025506, train_l2:0.203484,  test_l2:0.362310\n",
      "2025-05-08 02:22:15,014 : epoch:48, time:10.455467, train_mse:0.026825, train_l2:0.208900,  test_l2:0.369537\n",
      "2025-05-08 02:22:25,213 : epoch:49, time:10.196965, train_mse:0.026303, train_l2:0.205966,  test_l2:0.361518\n",
      "2025-05-08 02:22:35,069 : epoch:50, time:9.854166, train_mse:0.025160, train_l2:0.205012,  test_l2:0.378243\n",
      "2025-05-08 02:22:44,736 : epoch:51, time:9.664753, train_mse:0.025399, train_l2:0.204816,  test_l2:0.358630\n",
      "2025-05-08 02:22:45,430 : best model saved\n",
      "2025-05-08 02:22:54,796 : epoch:52, time:9.363934, train_mse:0.024497, train_l2:0.200874,  test_l2:0.363557\n",
      "2025-05-08 02:23:04,332 : epoch:53, time:9.534790, train_mse:0.024760, train_l2:0.201496,  test_l2:0.362390\n",
      "2025-05-08 02:23:13,839 : epoch:54, time:9.503872, train_mse:0.024155, train_l2:0.198893,  test_l2:0.359714\n",
      "2025-05-08 02:23:23,916 : epoch:55, time:10.074593, train_mse:0.023753, train_l2:0.196570,  test_l2:0.358573\n",
      "2025-05-08 02:23:24,619 : best model saved\n",
      "2025-05-08 02:23:34,552 : epoch:56, time:9.930693, train_mse:0.023206, train_l2:0.193807,  test_l2:0.358061\n",
      "2025-05-08 02:23:35,268 : best model saved\n",
      "2025-05-08 02:23:45,563 : epoch:57, time:10.293188, train_mse:0.023204, train_l2:0.193881,  test_l2:0.359752\n",
      "2025-05-08 02:23:55,760 : epoch:58, time:10.194723, train_mse:0.023703, train_l2:0.196433,  test_l2:0.358900\n",
      "2025-05-08 02:24:06,114 : epoch:59, time:10.351919, train_mse:0.023516, train_l2:0.195420,  test_l2:0.358706\n",
      "2025-05-08 02:24:16,745 : epoch:60, time:10.627950, train_mse:0.022950, train_l2:0.192465,  test_l2:0.355070\n",
      "2025-05-08 02:24:17,459 : best model saved\n",
      "2025-05-08 02:24:27,745 : epoch:61, time:10.283657, train_mse:0.022732, train_l2:0.191542,  test_l2:0.355690\n",
      "2025-05-08 02:24:37,842 : epoch:62, time:10.094480, train_mse:0.022667, train_l2:0.190781,  test_l2:0.358172\n",
      "2025-05-08 02:24:48,333 : epoch:63, time:10.490027, train_mse:0.022133, train_l2:0.189027,  test_l2:0.355428\n",
      "2025-05-08 02:24:58,825 : epoch:64, time:10.489373, train_mse:0.022304, train_l2:0.190149,  test_l2:0.357435\n",
      "2025-05-08 02:25:09,271 : epoch:65, time:10.442341, train_mse:0.023236, train_l2:0.196681,  test_l2:0.358544\n",
      "2025-05-08 02:25:19,377 : epoch:66, time:10.103722, train_mse:0.022352, train_l2:0.190523,  test_l2:0.356878\n",
      "2025-05-08 02:25:29,921 : epoch:67, time:10.541450, train_mse:0.021982, train_l2:0.188624,  test_l2:0.357113\n",
      "2025-05-08 02:25:40,281 : epoch:68, time:10.358547, train_mse:0.022289, train_l2:0.189943,  test_l2:0.358506\n",
      "2025-05-08 02:25:50,319 : epoch:69, time:10.034785, train_mse:0.022189, train_l2:0.189870,  test_l2:0.357224\n",
      "2025-05-08 02:26:00,932 : epoch:70, time:10.612006, train_mse:0.023639, train_l2:0.197913,  test_l2:0.360097\n",
      "2025-05-08 02:26:11,118 : epoch:71, time:10.183025, train_mse:0.022385, train_l2:0.190151,  test_l2:0.364384\n",
      "2025-05-08 02:26:21,680 : epoch:72, time:10.559794, train_mse:0.021571, train_l2:0.186610,  test_l2:0.353550\n",
      "2025-05-08 02:26:22,374 : best model saved\n",
      "2025-05-08 02:26:32,559 : epoch:73, time:10.182082, train_mse:0.020933, train_l2:0.183439,  test_l2:0.355254\n",
      "2025-05-08 02:26:42,911 : epoch:74, time:10.349804, train_mse:0.020614, train_l2:0.182037,  test_l2:0.354380\n",
      "2025-05-08 02:26:53,398 : epoch:75, time:10.485121, train_mse:0.020566, train_l2:0.181915,  test_l2:0.353009\n",
      "2025-05-08 02:26:54,110 : best model saved\n",
      "2025-05-08 02:27:04,505 : epoch:76, time:10.393706, train_mse:0.020975, train_l2:0.183519,  test_l2:0.356006\n",
      "2025-05-08 02:27:14,470 : epoch:77, time:9.961744, train_mse:0.021854, train_l2:0.188655,  test_l2:0.356463\n",
      "2025-05-08 02:27:24,307 : epoch:78, time:9.834609, train_mse:0.021181, train_l2:0.185301,  test_l2:0.357092\n",
      "2025-05-08 02:27:34,400 : epoch:79, time:10.089912, train_mse:0.021223, train_l2:0.185203,  test_l2:0.354427\n",
      "2025-05-08 02:27:44,430 : epoch:80, time:10.028006, train_mse:0.020693, train_l2:0.182208,  test_l2:0.353600\n",
      "2025-05-08 02:27:53,820 : epoch:81, time:9.387361, train_mse:0.020189, train_l2:0.180484,  test_l2:0.353423\n",
      "2025-05-08 02:28:04,131 : epoch:82, time:10.308799, train_mse:0.019817, train_l2:0.178795,  test_l2:0.353295\n",
      "2025-05-08 02:28:14,382 : epoch:83, time:10.249898, train_mse:0.019524, train_l2:0.178130,  test_l2:0.359032\n",
      "2025-05-08 02:28:24,779 : epoch:84, time:10.395078, train_mse:0.021473, train_l2:0.189974,  test_l2:0.354598\n",
      "2025-05-08 02:28:35,091 : epoch:85, time:10.310290, train_mse:0.020304, train_l2:0.181152,  test_l2:0.354568\n",
      "2025-05-08 02:28:45,612 : epoch:86, time:10.516414, train_mse:0.019517, train_l2:0.177530,  test_l2:0.353272\n",
      "2025-05-08 02:28:55,930 : epoch:87, time:10.316573, train_mse:0.020525, train_l2:0.182071,  test_l2:0.360190\n",
      "2025-05-08 02:29:06,515 : epoch:88, time:10.582764, train_mse:0.022025, train_l2:0.189464,  test_l2:0.356538\n",
      "2025-05-08 02:29:17,528 : epoch:89, time:11.011759, train_mse:0.020764, train_l2:0.183200,  test_l2:0.352919\n",
      "2025-05-08 02:29:18,344 : best model saved\n",
      "2025-05-08 02:29:28,737 : epoch:90, time:10.391307, train_mse:0.019483, train_l2:0.176902,  test_l2:0.354149\n",
      "2025-05-08 02:29:39,329 : epoch:91, time:10.589216, train_mse:0.018753, train_l2:0.173872,  test_l2:0.353385\n",
      "2025-05-08 02:29:49,874 : epoch:92, time:10.542533, train_mse:0.018962, train_l2:0.174796,  test_l2:0.352354\n",
      "2025-05-08 02:29:50,587 : best model saved\n",
      "2025-05-08 02:30:00,923 : epoch:93, time:10.334415, train_mse:0.019258, train_l2:0.176028,  test_l2:0.352281\n",
      "2025-05-08 02:30:01,626 : best model saved\n",
      "2025-05-08 02:30:12,148 : epoch:94, time:10.520792, train_mse:0.019324, train_l2:0.176783,  test_l2:0.353499\n",
      "2025-05-08 02:30:22,684 : epoch:95, time:10.534013, train_mse:0.018992, train_l2:0.175025,  test_l2:0.354209\n",
      "2025-05-08 02:30:33,123 : epoch:96, time:10.436194, train_mse:0.019190, train_l2:0.175732,  test_l2:0.352185\n",
      "2025-05-08 02:30:33,938 : best model saved\n",
      "2025-05-08 02:30:44,411 : epoch:97, time:10.471087, train_mse:0.019150, train_l2:0.176342,  test_l2:0.356073\n",
      "2025-05-08 02:30:54,778 : epoch:98, time:10.364097, train_mse:0.019428, train_l2:0.176757,  test_l2:0.354177\n",
      "2025-05-08 02:31:05,125 : epoch:99, time:10.344034, train_mse:0.019157, train_l2:0.176261,  test_l2:0.352383\n",
      "2025-05-08 02:31:15,500 : epoch:100, time:10.373409, train_mse:0.019229, train_l2:0.176061,  test_l2:0.352186\n",
      "2025-05-08 02:31:26,312 : epoch:101, time:10.809588, train_mse:0.018761, train_l2:0.173738,  test_l2:0.352817\n",
      "2025-05-08 02:31:37,025 : epoch:102, time:10.710082, train_mse:0.019090, train_l2:0.175127,  test_l2:0.352105\n",
      "2025-05-08 02:31:37,860 : best model saved\n",
      "2025-05-08 02:31:48,669 : epoch:103, time:10.807058, train_mse:0.018331, train_l2:0.171419,  test_l2:0.352996\n",
      "2025-05-08 02:31:58,945 : epoch:104, time:10.274546, train_mse:0.018032, train_l2:0.170328,  test_l2:0.353300\n",
      "2025-05-08 02:32:09,436 : epoch:105, time:10.488472, train_mse:0.018052, train_l2:0.170317,  test_l2:0.355425\n",
      "2025-05-08 02:32:20,309 : epoch:106, time:10.871768, train_mse:0.018953, train_l2:0.175610,  test_l2:0.353332\n",
      "2025-05-08 02:32:30,684 : epoch:107, time:10.372421, train_mse:0.019448, train_l2:0.177949,  test_l2:0.357408\n",
      "2025-05-08 02:32:41,005 : epoch:108, time:10.319751, train_mse:0.019379, train_l2:0.181396,  test_l2:0.354250\n",
      "2025-05-08 02:32:51,540 : epoch:109, time:10.533067, train_mse:0.018860, train_l2:0.175166,  test_l2:0.355481\n",
      "2025-05-08 02:33:01,636 : epoch:110, time:10.093848, train_mse:0.018666, train_l2:0.173694,  test_l2:0.354810\n",
      "2025-05-08 02:33:11,972 : epoch:111, time:10.333693, train_mse:0.017966, train_l2:0.170192,  test_l2:0.351962\n",
      "2025-05-08 02:33:12,670 : best model saved\n",
      "2025-05-08 02:33:23,004 : epoch:112, time:10.332714, train_mse:0.017557, train_l2:0.168230,  test_l2:0.352114\n",
      "2025-05-08 02:33:33,351 : epoch:113, time:10.344277, train_mse:0.017387, train_l2:0.168586,  test_l2:0.351440\n",
      "2025-05-08 02:33:34,063 : best model saved\n",
      "2025-05-08 02:33:44,336 : epoch:114, time:10.271877, train_mse:0.017122, train_l2:0.166055,  test_l2:0.351688\n",
      "2025-05-08 02:33:54,823 : epoch:115, time:10.484733, train_mse:0.016973, train_l2:0.165337,  test_l2:0.353241\n",
      "2025-05-08 02:34:05,397 : epoch:116, time:10.571587, train_mse:0.016897, train_l2:0.165002,  test_l2:0.354108\n",
      "2025-05-08 02:34:15,822 : epoch:117, time:10.424125, train_mse:0.017189, train_l2:0.167149,  test_l2:0.353934\n",
      "2025-05-08 02:34:26,156 : epoch:118, time:10.330382, train_mse:0.017986, train_l2:0.173234,  test_l2:0.357176\n",
      "2025-05-08 02:34:36,198 : epoch:119, time:10.040064, train_mse:0.017454, train_l2:0.169295,  test_l2:0.352317\n",
      "2025-05-08 02:34:46,553 : epoch:120, time:10.353909, train_mse:0.016985, train_l2:0.165488,  test_l2:0.350583\n",
      "2025-05-08 02:34:47,324 : best model saved\n",
      "2025-05-08 02:34:57,530 : epoch:121, time:10.205032, train_mse:0.017034, train_l2:0.165970,  test_l2:0.351369\n",
      "2025-05-08 02:35:07,850 : epoch:122, time:10.317436, train_mse:0.016947, train_l2:0.165264,  test_l2:0.353826\n",
      "2025-05-08 02:35:18,527 : epoch:123, time:10.673860, train_mse:0.016942, train_l2:0.165272,  test_l2:0.352274\n",
      "2025-05-08 02:35:29,037 : epoch:124, time:10.505409, train_mse:0.018347, train_l2:0.171796,  test_l2:0.356398\n",
      "2025-05-08 02:35:39,323 : epoch:125, time:10.284345, train_mse:0.017884, train_l2:0.170405,  test_l2:0.351694\n",
      "2025-05-08 02:35:49,451 : epoch:126, time:10.125231, train_mse:0.016761, train_l2:0.164603,  test_l2:0.351046\n",
      "2025-05-08 02:35:59,817 : epoch:127, time:10.364780, train_mse:0.015997, train_l2:0.160219,  test_l2:0.349945\n",
      "2025-05-08 02:36:00,518 : best model saved\n",
      "2025-05-08 02:36:10,726 : epoch:128, time:10.206563, train_mse:0.015764, train_l2:0.159002,  test_l2:0.351862\n",
      "2025-05-08 02:36:20,586 : epoch:129, time:9.858534, train_mse:0.016800, train_l2:0.165056,  test_l2:0.352808\n",
      "2025-05-08 02:36:30,190 : epoch:130, time:9.601751, train_mse:0.017074, train_l2:0.165847,  test_l2:0.351495\n",
      "2025-05-08 02:36:40,121 : epoch:131, time:9.930405, train_mse:0.016551, train_l2:0.163268,  test_l2:0.350371\n",
      "2025-05-08 02:36:50,500 : epoch:132, time:10.377443, train_mse:0.016060, train_l2:0.160609,  test_l2:0.350722\n",
      "2025-05-08 02:37:01,050 : epoch:133, time:10.548187, train_mse:0.015991, train_l2:0.160653,  test_l2:0.352514\n",
      "2025-05-08 02:37:11,350 : epoch:134, time:10.297586, train_mse:0.016063, train_l2:0.161514,  test_l2:0.351705\n",
      "2025-05-08 02:37:21,465 : epoch:135, time:10.112692, train_mse:0.015940, train_l2:0.160479,  test_l2:0.351453\n",
      "2025-05-08 02:37:31,914 : epoch:136, time:10.446674, train_mse:0.016251, train_l2:0.161561,  test_l2:0.351660\n",
      "2025-05-08 02:37:42,344 : epoch:137, time:10.427076, train_mse:0.015979, train_l2:0.160544,  test_l2:0.352219\n",
      "2025-05-08 02:37:52,593 : epoch:138, time:10.246698, train_mse:0.016215, train_l2:0.162689,  test_l2:0.351711\n",
      "2025-05-08 02:38:03,209 : epoch:139, time:10.615400, train_mse:0.016141, train_l2:0.161819,  test_l2:0.352739\n",
      "2025-05-08 02:38:13,331 : epoch:140, time:10.119028, train_mse:0.015939, train_l2:0.160911,  test_l2:0.354192\n",
      "2025-05-08 02:38:23,602 : epoch:141, time:10.269005, train_mse:0.015839, train_l2:0.160202,  test_l2:0.354992\n",
      "2025-05-08 02:38:33,693 : epoch:142, time:10.088333, train_mse:0.015897, train_l2:0.159997,  test_l2:0.352855\n",
      "2025-05-08 02:38:44,303 : epoch:143, time:10.607590, train_mse:0.015645, train_l2:0.158489,  test_l2:0.350746\n",
      "2025-05-08 02:38:54,687 : epoch:144, time:10.381474, train_mse:0.015524, train_l2:0.158543,  test_l2:0.351427\n",
      "2025-05-08 02:39:04,817 : epoch:145, time:10.128660, train_mse:0.015173, train_l2:0.156696,  test_l2:0.351039\n",
      "2025-05-08 02:39:15,304 : epoch:146, time:10.485196, train_mse:0.015200, train_l2:0.157269,  test_l2:0.350903\n",
      "2025-05-08 02:39:25,622 : epoch:147, time:10.315146, train_mse:0.015224, train_l2:0.157189,  test_l2:0.351760\n",
      "2025-05-08 02:39:36,300 : epoch:148, time:10.675566, train_mse:0.015086, train_l2:0.156137,  test_l2:0.349873\n",
      "2025-05-08 02:39:37,001 : best model saved\n",
      "2025-05-08 02:39:47,415 : epoch:149, time:10.412223, train_mse:0.015155, train_l2:0.156240,  test_l2:0.350176\n",
      "2025-05-08 02:39:57,829 : epoch:150, time:10.409169, train_mse:0.015022, train_l2:0.155624,  test_l2:0.350915\n",
      "2025-05-08 02:40:08,080 : epoch:151, time:10.249114, train_mse:0.014980, train_l2:0.155440,  test_l2:0.351268\n",
      "2025-05-08 02:40:18,344 : epoch:152, time:10.262483, train_mse:0.014866, train_l2:0.154983,  test_l2:0.350270\n",
      "2025-05-08 02:40:28,724 : epoch:153, time:10.376650, train_mse:0.015312, train_l2:0.157129,  test_l2:0.351209\n",
      "2025-05-08 02:40:38,782 : epoch:154, time:10.055570, train_mse:0.015852, train_l2:0.160970,  test_l2:0.358634\n",
      "2025-05-08 02:40:49,109 : epoch:155, time:10.324370, train_mse:0.016124, train_l2:0.161751,  test_l2:0.353892\n",
      "2025-05-08 02:40:59,557 : epoch:156, time:10.445549, train_mse:0.015100, train_l2:0.156004,  test_l2:0.351259\n",
      "2025-05-08 02:41:09,613 : epoch:157, time:10.054722, train_mse:0.014739, train_l2:0.154403,  test_l2:0.351194\n",
      "2025-05-08 02:41:19,879 : epoch:158, time:10.263399, train_mse:0.014719, train_l2:0.153955,  test_l2:0.351464\n",
      "2025-05-08 02:41:30,117 : epoch:159, time:10.235963, train_mse:0.014565, train_l2:0.153234,  test_l2:0.352198\n",
      "2025-05-08 02:41:40,383 : epoch:160, time:10.261844, train_mse:0.014604, train_l2:0.153612,  test_l2:0.351639\n",
      "2025-05-08 02:41:50,953 : epoch:161, time:10.568532, train_mse:0.014479, train_l2:0.152641,  test_l2:0.352380\n",
      "2025-05-08 02:42:01,232 : epoch:162, time:10.276026, train_mse:0.014749, train_l2:0.155828,  test_l2:0.353583\n",
      "2025-05-08 02:42:11,812 : epoch:163, time:10.576146, train_mse:0.015067, train_l2:0.157221,  test_l2:0.352470\n",
      "2025-05-08 02:42:22,060 : epoch:164, time:10.246577, train_mse:0.014618, train_l2:0.153895,  test_l2:0.352056\n",
      "2025-05-08 02:42:32,600 : epoch:165, time:10.537596, train_mse:0.014379, train_l2:0.152094,  test_l2:0.351018\n",
      "2025-05-08 02:42:42,965 : epoch:166, time:10.363406, train_mse:0.014417, train_l2:0.152578,  test_l2:0.350613\n",
      "2025-05-08 02:42:53,576 : epoch:167, time:10.609572, train_mse:0.014213, train_l2:0.151509,  test_l2:0.351712\n",
      "2025-05-08 02:43:03,915 : epoch:168, time:10.337169, train_mse:0.014155, train_l2:0.151363,  test_l2:0.350255\n",
      "2025-05-08 02:43:14,281 : epoch:169, time:10.364087, train_mse:0.014021, train_l2:0.150342,  test_l2:0.349832\n",
      "2025-05-08 02:43:14,976 : best model saved\n",
      "2025-05-08 02:43:25,602 : epoch:170, time:10.624042, train_mse:0.014543, train_l2:0.153164,  test_l2:0.354078\n",
      "2025-05-08 02:43:36,050 : epoch:171, time:10.445090, train_mse:0.015395, train_l2:0.157786,  test_l2:0.352335\n",
      "2025-05-08 02:43:46,524 : epoch:172, time:10.471187, train_mse:0.014575, train_l2:0.153303,  test_l2:0.352212\n",
      "2025-05-08 02:43:56,760 : epoch:173, time:10.234765, train_mse:0.013989, train_l2:0.149952,  test_l2:0.351337\n",
      "2025-05-08 02:44:07,194 : epoch:174, time:10.431156, train_mse:0.013946, train_l2:0.149934,  test_l2:0.350754\n",
      "2025-05-08 02:44:17,897 : epoch:175, time:10.700064, train_mse:0.013745, train_l2:0.148951,  test_l2:0.353578\n",
      "2025-05-08 02:44:28,114 : epoch:176, time:10.212770, train_mse:0.013625, train_l2:0.148285,  test_l2:0.349602\n",
      "2025-05-08 02:44:28,950 : best model saved\n",
      "2025-05-08 02:44:39,521 : epoch:177, time:10.569326, train_mse:0.013377, train_l2:0.146629,  test_l2:0.350953\n",
      "2025-05-08 02:44:50,070 : epoch:178, time:10.547480, train_mse:0.013333, train_l2:0.146495,  test_l2:0.350195\n",
      "2025-05-08 02:45:00,604 : epoch:179, time:10.530645, train_mse:0.013048, train_l2:0.145085,  test_l2:0.349923\n",
      "2025-05-08 02:45:11,117 : epoch:180, time:10.510665, train_mse:0.013080, train_l2:0.145885,  test_l2:0.351444\n",
      "2025-05-08 02:45:21,628 : epoch:181, time:10.507802, train_mse:0.013143, train_l2:0.145923,  test_l2:0.349653\n",
      "2025-05-08 02:45:32,081 : epoch:182, time:10.451855, train_mse:0.012981, train_l2:0.144728,  test_l2:0.352445\n",
      "2025-05-08 02:45:42,259 : epoch:183, time:10.174491, train_mse:0.012884, train_l2:0.144134,  test_l2:0.349257\n",
      "2025-05-08 02:45:42,950 : best model saved\n",
      "2025-05-08 02:45:53,558 : epoch:184, time:10.606994, train_mse:0.012756, train_l2:0.142935,  test_l2:0.350633\n",
      "2025-05-08 02:46:04,060 : epoch:185, time:10.499761, train_mse:0.012687, train_l2:0.142720,  test_l2:0.350126\n",
      "2025-05-08 02:46:14,129 : epoch:186, time:10.066568, train_mse:0.012939, train_l2:0.143839,  test_l2:0.351688\n",
      "2025-05-08 02:46:24,450 : epoch:187, time:10.319268, train_mse:0.012838, train_l2:0.143476,  test_l2:0.351078\n",
      "2025-05-08 02:46:34,605 : epoch:188, time:10.152807, train_mse:0.013106, train_l2:0.146489,  test_l2:0.351309\n",
      "2025-05-08 02:46:44,739 : epoch:189, time:10.131897, train_mse:0.013440, train_l2:0.147382,  test_l2:0.351156\n",
      "2025-05-08 02:46:54,715 : epoch:190, time:9.975569, train_mse:0.013610, train_l2:0.148350,  test_l2:0.351191\n",
      "2025-05-08 02:47:04,998 : epoch:191, time:10.279977, train_mse:0.013761, train_l2:0.149335,  test_l2:0.351716\n",
      "2025-05-08 02:47:15,194 : epoch:192, time:10.195106, train_mse:0.013606, train_l2:0.148246,  test_l2:0.351717\n",
      "2025-05-08 02:47:25,466 : epoch:193, time:10.268838, train_mse:0.012979, train_l2:0.144943,  test_l2:0.353438\n",
      "2025-05-08 02:47:35,731 : epoch:194, time:10.263912, train_mse:0.013020, train_l2:0.144715,  test_l2:0.350358\n",
      "2025-05-08 02:47:46,182 : epoch:195, time:10.449097, train_mse:0.012750, train_l2:0.142979,  test_l2:0.351290\n",
      "2025-05-08 02:47:56,552 : epoch:196, time:10.368509, train_mse:0.012518, train_l2:0.142148,  test_l2:0.351717\n",
      "2025-05-08 02:48:06,748 : epoch:197, time:10.194006, train_mse:0.012438, train_l2:0.141399,  test_l2:0.351557\n",
      "2025-05-08 02:48:17,230 : epoch:198, time:10.481208, train_mse:0.012391, train_l2:0.141119,  test_l2:0.350599\n",
      "2025-05-08 02:48:27,720 : epoch:199, time:10.486185, train_mse:0.012346, train_l2:0.140996,  test_l2:0.351678\n",
      "2025-05-08 02:48:38,257 : epoch:200, time:10.533597, train_mse:0.012270, train_l2:0.140548,  test_l2:0.350591\n",
      "2025-05-08 02:48:48,540 : epoch:201, time:10.280538, train_mse:0.012423, train_l2:0.141717,  test_l2:0.351336\n",
      "2025-05-08 02:48:59,005 : epoch:202, time:10.462880, train_mse:0.012334, train_l2:0.141004,  test_l2:0.350987\n",
      "2025-05-08 02:49:09,498 : epoch:203, time:10.490642, train_mse:0.012380, train_l2:0.141452,  test_l2:0.354357\n",
      "2025-05-08 02:49:19,875 : epoch:204, time:10.375180, train_mse:0.012576, train_l2:0.142496,  test_l2:0.352371\n",
      "2025-05-08 02:49:30,503 : epoch:205, time:10.625879, train_mse:0.012269, train_l2:0.140921,  test_l2:0.352292\n",
      "2025-05-08 02:49:40,900 : epoch:206, time:10.395116, train_mse:0.012532, train_l2:0.143228,  test_l2:0.357883\n",
      "2025-05-08 02:49:51,046 : epoch:207, time:10.143731, train_mse:0.012497, train_l2:0.142233,  test_l2:0.351882\n",
      "2025-05-08 02:50:01,381 : epoch:208, time:10.330250, train_mse:0.012217, train_l2:0.141229,  test_l2:0.351617\n",
      "2025-05-08 02:50:11,695 : epoch:209, time:10.312579, train_mse:0.011967, train_l2:0.138937,  test_l2:0.352341\n",
      "2025-05-08 02:50:21,858 : epoch:210, time:10.161034, train_mse:0.011815, train_l2:0.138227,  test_l2:0.350863\n",
      "2025-05-08 02:50:32,156 : epoch:211, time:10.296724, train_mse:0.011673, train_l2:0.137225,  test_l2:0.350350\n",
      "2025-05-08 02:50:42,419 : epoch:212, time:10.261786, train_mse:0.011528, train_l2:0.136356,  test_l2:0.350174\n",
      "2025-05-08 02:50:52,850 : epoch:213, time:10.428407, train_mse:0.011892, train_l2:0.138811,  test_l2:0.353965\n",
      "2025-05-08 02:51:03,002 : epoch:214, time:10.150373, train_mse:0.012392, train_l2:0.143021,  test_l2:0.355002\n",
      "2025-05-08 02:51:13,134 : epoch:215, time:10.128015, train_mse:0.012095, train_l2:0.139741,  test_l2:0.351697\n",
      "2025-05-08 02:51:23,145 : epoch:216, time:10.009389, train_mse:0.011899, train_l2:0.138388,  test_l2:0.351132\n",
      "2025-05-08 02:51:33,481 : epoch:217, time:10.333086, train_mse:0.011865, train_l2:0.138199,  test_l2:0.351197\n",
      "2025-05-08 02:51:44,069 : epoch:218, time:10.587107, train_mse:0.011635, train_l2:0.136957,  test_l2:0.352888\n",
      "2025-05-08 02:51:54,406 : epoch:219, time:10.333901, train_mse:0.011554, train_l2:0.136284,  test_l2:0.351003\n",
      "2025-05-08 02:52:04,912 : epoch:220, time:10.504267, train_mse:0.011318, train_l2:0.134908,  test_l2:0.350351\n",
      "2025-05-08 02:52:15,376 : epoch:221, time:10.459356, train_mse:0.011196, train_l2:0.134109,  test_l2:0.351949\n",
      "2025-05-08 02:52:25,207 : epoch:222, time:9.828480, train_mse:0.011280, train_l2:0.134585,  test_l2:0.351081\n",
      "2025-05-08 02:52:35,419 : epoch:223, time:10.209714, train_mse:0.011244, train_l2:0.134732,  test_l2:0.351062\n",
      "2025-05-08 02:52:45,588 : epoch:224, time:10.164715, train_mse:0.011112, train_l2:0.133687,  test_l2:0.351891\n",
      "2025-05-08 02:52:56,148 : epoch:225, time:10.558709, train_mse:0.010908, train_l2:0.132610,  test_l2:0.353084\n",
      "2025-05-08 02:53:06,387 : epoch:226, time:10.237186, train_mse:0.011122, train_l2:0.134118,  test_l2:0.351464\n",
      "2025-05-08 02:53:16,436 : epoch:227, time:10.045847, train_mse:0.011020, train_l2:0.133396,  test_l2:0.351743\n",
      "2025-05-08 02:53:27,011 : epoch:228, time:10.573564, train_mse:0.010924, train_l2:0.132642,  test_l2:0.352386\n",
      "2025-05-08 02:53:37,443 : epoch:229, time:10.429893, train_mse:0.011098, train_l2:0.134011,  test_l2:0.352725\n",
      "2025-05-08 02:53:47,843 : epoch:230, time:10.398145, train_mse:0.011610, train_l2:0.136550,  test_l2:0.351757\n",
      "2025-05-08 02:53:58,141 : epoch:231, time:10.296153, train_mse:0.011632, train_l2:0.136664,  test_l2:0.352207\n",
      "2025-05-08 02:54:08,480 : epoch:232, time:10.336783, train_mse:0.011394, train_l2:0.135415,  test_l2:0.351701\n",
      "2025-05-08 02:54:18,991 : epoch:233, time:10.509020, train_mse:0.011214, train_l2:0.134196,  test_l2:0.351348\n",
      "2025-05-08 02:54:29,530 : epoch:234, time:10.534508, train_mse:0.010904, train_l2:0.132700,  test_l2:0.351637\n",
      "2025-05-08 02:54:39,640 : epoch:235, time:10.107773, train_mse:0.011079, train_l2:0.136269,  test_l2:0.353596\n",
      "2025-05-08 02:54:50,120 : epoch:236, time:10.476159, train_mse:0.011147, train_l2:0.136088,  test_l2:0.352538\n",
      "2025-05-08 02:55:00,728 : epoch:237, time:10.605594, train_mse:0.010784, train_l2:0.132578,  test_l2:0.352942\n",
      "2025-05-08 02:55:10,995 : epoch:238, time:10.265155, train_mse:0.010512, train_l2:0.130430,  test_l2:0.351138\n",
      "2025-05-08 02:55:21,127 : epoch:239, time:10.128810, train_mse:0.010372, train_l2:0.129422,  test_l2:0.352029\n",
      "2025-05-08 02:55:31,467 : epoch:240, time:10.337278, train_mse:0.010333, train_l2:0.129041,  test_l2:0.351120\n",
      "2025-05-08 02:55:41,826 : epoch:241, time:10.356202, train_mse:0.010416, train_l2:0.129552,  test_l2:0.352464\n",
      "2025-05-08 02:55:52,803 : epoch:242, time:10.974797, train_mse:0.010592, train_l2:0.130988,  test_l2:0.352404\n",
      "2025-05-08 02:56:02,922 : epoch:243, time:10.117646, train_mse:0.010754, train_l2:0.131649,  test_l2:0.352256\n",
      "2025-05-08 02:56:12,934 : epoch:244, time:10.009766, train_mse:0.010637, train_l2:0.131188,  test_l2:0.351963\n",
      "2025-05-08 02:56:23,049 : epoch:245, time:10.112230, train_mse:0.010991, train_l2:0.132945,  test_l2:0.352705\n",
      "2025-05-08 02:56:33,577 : epoch:246, time:10.526375, train_mse:0.010790, train_l2:0.131579,  test_l2:0.353207\n",
      "2025-05-08 02:56:44,297 : epoch:247, time:10.715464, train_mse:0.010460, train_l2:0.130043,  test_l2:0.352782\n",
      "2025-05-08 02:56:55,228 : epoch:248, time:10.928627, train_mse:0.010284, train_l2:0.128815,  test_l2:0.352920\n",
      "2025-05-08 02:57:06,024 : epoch:249, time:10.791983, train_mse:0.010143, train_l2:0.127923,  test_l2:0.354006\n",
      "2025-05-08 02:57:16,318 : epoch:250, time:10.291537, train_mse:0.010049, train_l2:0.127351,  test_l2:0.353201\n",
      "2025-05-08 02:57:26,923 : epoch:251, time:10.600752, train_mse:0.009940, train_l2:0.126419,  test_l2:0.352723\n",
      "2025-05-08 02:57:37,505 : epoch:252, time:10.577750, train_mse:0.009810, train_l2:0.125665,  test_l2:0.351832\n",
      "2025-05-08 02:57:47,783 : epoch:253, time:10.275216, train_mse:0.009703, train_l2:0.125239,  test_l2:0.353448\n",
      "2025-05-08 02:57:58,170 : epoch:254, time:10.384196, train_mse:0.009689, train_l2:0.125577,  test_l2:0.353922\n",
      "2025-05-08 02:58:08,721 : epoch:255, time:10.547067, train_mse:0.009839, train_l2:0.126903,  test_l2:0.354029\n",
      "2025-05-08 02:58:19,184 : epoch:256, time:10.459212, train_mse:0.009832, train_l2:0.126159,  test_l2:0.352181\n",
      "2025-05-08 02:58:29,621 : epoch:257, time:10.433990, train_mse:0.009753, train_l2:0.125344,  test_l2:0.353724\n",
      "2025-05-08 02:58:40,131 : epoch:258, time:10.507827, train_mse:0.009904, train_l2:0.126298,  test_l2:0.353032\n",
      "2025-05-08 02:58:50,729 : epoch:259, time:10.596293, train_mse:0.009990, train_l2:0.126946,  test_l2:0.353283\n",
      "2025-05-08 02:59:00,875 : epoch:260, time:10.144202, train_mse:0.009987, train_l2:0.126921,  test_l2:0.353085\n",
      "2025-05-08 02:59:11,133 : epoch:261, time:10.255394, train_mse:0.010019, train_l2:0.127431,  test_l2:0.356268\n",
      "2025-05-08 02:59:21,611 : epoch:262, time:10.475978, train_mse:0.009804, train_l2:0.125814,  test_l2:0.352562\n",
      "2025-05-08 02:59:32,173 : epoch:263, time:10.561491, train_mse:0.009541, train_l2:0.123943,  test_l2:0.354444\n",
      "2025-05-08 02:59:42,963 : epoch:264, time:10.786300, train_mse:0.009453, train_l2:0.123830,  test_l2:0.353380\n",
      "2025-05-08 02:59:53,359 : epoch:265, time:10.394544, train_mse:0.009345, train_l2:0.122858,  test_l2:0.354427\n",
      "2025-05-08 03:00:03,893 : epoch:266, time:10.532616, train_mse:0.009370, train_l2:0.122945,  test_l2:0.353153\n",
      "2025-05-08 03:00:14,467 : epoch:267, time:10.570986, train_mse:0.009309, train_l2:0.122574,  test_l2:0.354255\n",
      "2025-05-08 03:00:25,288 : epoch:268, time:10.819675, train_mse:0.009249, train_l2:0.122233,  test_l2:0.354604\n",
      "2025-05-08 03:00:35,651 : epoch:269, time:10.360381, train_mse:0.009229, train_l2:0.122256,  test_l2:0.354320\n",
      "2025-05-08 03:00:46,120 : epoch:270, time:10.466544, train_mse:0.009490, train_l2:0.124706,  test_l2:0.353685\n",
      "2025-05-08 03:00:56,610 : epoch:271, time:10.487454, train_mse:0.009618, train_l2:0.124913,  test_l2:0.355217\n",
      "2025-05-08 03:01:06,825 : epoch:272, time:10.211110, train_mse:0.009711, train_l2:0.125998,  test_l2:0.356644\n",
      "2025-05-08 03:01:17,156 : epoch:273, time:10.328575, train_mse:0.009357, train_l2:0.123087,  test_l2:0.354434\n",
      "2025-05-08 03:01:27,650 : epoch:274, time:10.491817, train_mse:0.009181, train_l2:0.121951,  test_l2:0.354020\n",
      "2025-05-08 03:01:38,097 : epoch:275, time:10.444334, train_mse:0.009118, train_l2:0.121655,  test_l2:0.354488\n",
      "2025-05-08 03:01:48,128 : epoch:276, time:10.028070, train_mse:0.009194, train_l2:0.122108,  test_l2:0.353884\n",
      "2025-05-08 03:01:58,318 : epoch:277, time:10.188536, train_mse:0.009010, train_l2:0.120540,  test_l2:0.355140\n",
      "2025-05-08 03:02:08,959 : epoch:278, time:10.638168, train_mse:0.008902, train_l2:0.119783,  test_l2:0.355610\n",
      "2025-05-08 03:02:19,386 : epoch:279, time:10.423670, train_mse:0.008784, train_l2:0.119174,  test_l2:0.355262\n",
      "2025-05-08 03:02:30,037 : epoch:280, time:10.649879, train_mse:0.008742, train_l2:0.118826,  test_l2:0.357300\n",
      "2025-05-08 03:02:40,321 : epoch:281, time:10.282086, train_mse:0.008883, train_l2:0.119617,  test_l2:0.355859\n",
      "2025-05-08 03:02:50,795 : epoch:282, time:10.471892, train_mse:0.008836, train_l2:0.119257,  test_l2:0.355156\n",
      "2025-05-08 03:03:00,924 : epoch:283, time:10.128263, train_mse:0.009177, train_l2:0.121574,  test_l2:0.354962\n",
      "2025-05-08 03:03:10,601 : epoch:284, time:9.674912, train_mse:0.009040, train_l2:0.120735,  test_l2:0.354939\n",
      "2025-05-08 03:03:20,577 : epoch:285, time:9.973918, train_mse:0.008906, train_l2:0.119869,  test_l2:0.355019\n",
      "2025-05-08 03:03:30,601 : epoch:286, time:10.020395, train_mse:0.008756, train_l2:0.118748,  test_l2:0.355194\n",
      "2025-05-08 03:03:41,403 : epoch:287, time:10.799590, train_mse:0.008691, train_l2:0.118422,  test_l2:0.354988\n",
      "2025-05-08 03:03:51,723 : epoch:288, time:10.316554, train_mse:0.008571, train_l2:0.117537,  test_l2:0.355326\n",
      "2025-05-08 03:04:01,511 : epoch:289, time:9.784778, train_mse:0.008392, train_l2:0.116276,  test_l2:0.355865\n",
      "2025-05-08 03:04:11,431 : epoch:290, time:9.916903, train_mse:0.008310, train_l2:0.115642,  test_l2:0.356466\n",
      "2025-05-08 03:04:21,938 : epoch:291, time:10.505242, train_mse:0.008214, train_l2:0.114987,  test_l2:0.356178\n",
      "2025-05-08 03:04:32,490 : epoch:292, time:10.549838, train_mse:0.008155, train_l2:0.114651,  test_l2:0.355585\n",
      "2025-05-08 03:04:42,696 : epoch:293, time:10.204746, train_mse:0.008097, train_l2:0.114209,  test_l2:0.356534\n",
      "2025-05-08 03:04:53,322 : epoch:294, time:10.624113, train_mse:0.008043, train_l2:0.113963,  test_l2:0.356363\n",
      "2025-05-08 03:05:03,729 : epoch:295, time:10.406126, train_mse:0.008039, train_l2:0.113986,  test_l2:0.356238\n",
      "2025-05-08 03:05:14,328 : epoch:296, time:10.596952, train_mse:0.008092, train_l2:0.114344,  test_l2:0.357255\n",
      "2025-05-08 03:05:24,666 : epoch:297, time:10.335769, train_mse:0.008102, train_l2:0.114300,  test_l2:0.356994\n",
      "2025-05-08 03:05:35,273 : epoch:298, time:10.605221, train_mse:0.008124, train_l2:0.114562,  test_l2:0.357641\n",
      "2025-05-08 03:05:45,737 : epoch:299, time:10.460416, train_mse:0.008090, train_l2:0.114238,  test_l2:0.356240\n",
      "2025-05-08 03:05:55,832 : epoch:300, time:10.092540, train_mse:0.008038, train_l2:0.113859,  test_l2:0.357379\n",
      "2025-05-08 03:06:05,643 : epoch:301, time:9.808780, train_mse:0.008217, train_l2:0.116133,  test_l2:0.357452\n",
      "2025-05-08 03:06:15,351 : epoch:302, time:9.705636, train_mse:0.007985, train_l2:0.113840,  test_l2:0.357843\n",
      "2025-05-08 03:06:25,301 : epoch:303, time:9.948401, train_mse:0.007978, train_l2:0.113898,  test_l2:0.356915\n",
      "2025-05-08 03:06:35,548 : epoch:304, time:10.244067, train_mse:0.008138, train_l2:0.116154,  test_l2:0.359023\n",
      "2025-05-08 03:06:45,641 : epoch:305, time:10.088460, train_mse:0.008440, train_l2:0.119280,  test_l2:0.357903\n",
      "2025-05-08 03:06:56,123 : epoch:306, time:10.479831, train_mse:0.007917, train_l2:0.113311,  test_l2:0.357220\n",
      "2025-05-08 03:07:06,259 : epoch:307, time:10.129697, train_mse:0.007619, train_l2:0.110897,  test_l2:0.357530\n",
      "2025-05-08 03:07:16,685 : epoch:308, time:10.423571, train_mse:0.007498, train_l2:0.109943,  test_l2:0.358102\n",
      "2025-05-08 03:07:27,707 : epoch:309, time:11.019077, train_mse:0.007408, train_l2:0.109427,  test_l2:0.358337\n",
      "2025-05-08 03:07:38,059 : epoch:310, time:10.349215, train_mse:0.007481, train_l2:0.109865,  test_l2:0.358164\n",
      "2025-05-08 03:07:48,291 : epoch:311, time:10.229064, train_mse:0.007499, train_l2:0.109957,  test_l2:0.358838\n",
      "2025-05-08 03:07:58,374 : epoch:312, time:10.080929, train_mse:0.007423, train_l2:0.109318,  test_l2:0.357808\n",
      "2025-05-08 03:08:08,809 : epoch:313, time:10.431792, train_mse:0.007416, train_l2:0.109270,  test_l2:0.359577\n",
      "2025-05-08 03:08:18,800 : epoch:314, time:9.990292, train_mse:0.007394, train_l2:0.109057,  test_l2:0.359335\n",
      "2025-05-08 03:08:29,077 : epoch:315, time:10.275626, train_mse:0.007413, train_l2:0.109207,  test_l2:0.358675\n",
      "2025-05-08 03:08:39,357 : epoch:316, time:10.276845, train_mse:0.007298, train_l2:0.108460,  test_l2:0.359353\n",
      "2025-05-08 03:08:49,513 : epoch:317, time:10.154858, train_mse:0.007304, train_l2:0.108481,  test_l2:0.360109\n",
      "2025-05-08 03:08:59,527 : epoch:318, time:10.011787, train_mse:0.007308, train_l2:0.108615,  test_l2:0.359125\n",
      "2025-05-08 03:09:09,898 : epoch:319, time:10.370641, train_mse:0.007310, train_l2:0.108480,  test_l2:0.359474\n",
      "2025-05-08 03:09:20,386 : epoch:320, time:10.485652, train_mse:0.007324, train_l2:0.108493,  test_l2:0.360025\n",
      "2025-05-08 03:09:30,551 : epoch:321, time:10.162896, train_mse:0.007275, train_l2:0.108207,  test_l2:0.360506\n",
      "2025-05-08 03:09:41,312 : epoch:322, time:10.759634, train_mse:0.007130, train_l2:0.107145,  test_l2:0.359828\n",
      "2025-05-08 03:09:51,919 : epoch:323, time:10.604642, train_mse:0.007029, train_l2:0.106269,  test_l2:0.360629\n",
      "2025-05-08 03:10:02,145 : epoch:324, time:10.223633, train_mse:0.006969, train_l2:0.105844,  test_l2:0.360467\n",
      "2025-05-08 03:10:12,661 : epoch:325, time:10.515089, train_mse:0.006890, train_l2:0.105259,  test_l2:0.360582\n",
      "2025-05-08 03:10:22,817 : epoch:326, time:10.153387, train_mse:0.006815, train_l2:0.104659,  test_l2:0.360848\n",
      "2025-05-08 03:10:33,371 : epoch:327, time:10.553258, train_mse:0.006787, train_l2:0.104444,  test_l2:0.360823\n",
      "2025-05-08 03:10:43,680 : epoch:328, time:10.306573, train_mse:0.006736, train_l2:0.104031,  test_l2:0.361669\n",
      "2025-05-08 03:10:54,076 : epoch:329, time:10.394662, train_mse:0.006717, train_l2:0.103806,  test_l2:0.361612\n",
      "2025-05-08 03:11:04,393 : epoch:330, time:10.315382, train_mse:0.006720, train_l2:0.103779,  test_l2:0.360626\n",
      "2025-05-08 03:11:14,784 : epoch:331, time:10.389027, train_mse:0.006828, train_l2:0.104552,  test_l2:0.361225\n",
      "2025-05-08 03:11:25,348 : epoch:332, time:10.562166, train_mse:0.006802, train_l2:0.104401,  test_l2:0.362606\n",
      "2025-05-08 03:11:35,593 : epoch:333, time:10.241480, train_mse:0.006761, train_l2:0.104128,  test_l2:0.363023\n",
      "2025-05-08 03:11:46,190 : epoch:334, time:10.592504, train_mse:0.006682, train_l2:0.103538,  test_l2:0.362095\n",
      "2025-05-08 03:11:56,374 : epoch:335, time:10.181228, train_mse:0.006574, train_l2:0.102795,  test_l2:0.361741\n",
      "2025-05-08 03:12:06,586 : epoch:336, time:10.209640, train_mse:0.006495, train_l2:0.102074,  test_l2:0.362569\n",
      "2025-05-08 03:12:17,055 : epoch:337, time:10.466278, train_mse:0.006414, train_l2:0.101498,  test_l2:0.363079\n",
      "2025-05-08 03:12:27,428 : epoch:338, time:10.370982, train_mse:0.006334, train_l2:0.100924,  test_l2:0.362921\n",
      "2025-05-08 03:12:37,890 : epoch:339, time:10.457985, train_mse:0.006309, train_l2:0.100675,  test_l2:0.363560\n",
      "2025-05-08 03:12:48,359 : epoch:340, time:10.466094, train_mse:0.006276, train_l2:0.100363,  test_l2:0.363513\n",
      "2025-05-08 03:12:59,117 : epoch:341, time:10.756362, train_mse:0.006254, train_l2:0.100131,  test_l2:0.363597\n",
      "2025-05-08 03:13:09,495 : epoch:342, time:10.376018, train_mse:0.006220, train_l2:0.099895,  test_l2:0.363592\n",
      "2025-05-08 03:13:20,012 : epoch:343, time:10.513833, train_mse:0.006197, train_l2:0.099766,  test_l2:0.364227\n",
      "2025-05-08 03:13:30,657 : epoch:344, time:10.643226, train_mse:0.006126, train_l2:0.099096,  test_l2:0.364028\n",
      "2025-05-08 03:13:40,935 : epoch:345, time:10.276696, train_mse:0.006113, train_l2:0.099154,  test_l2:0.364660\n",
      "2025-05-08 03:13:51,166 : epoch:346, time:10.227575, train_mse:0.006358, train_l2:0.101885,  test_l2:0.364086\n",
      "2025-05-08 03:14:01,586 : epoch:347, time:10.418574, train_mse:0.006166, train_l2:0.099451,  test_l2:0.364732\n",
      "2025-05-08 03:14:11,883 : epoch:348, time:10.294749, train_mse:0.006025, train_l2:0.098365,  test_l2:0.364791\n",
      "2025-05-08 03:14:22,308 : epoch:349, time:10.423222, train_mse:0.005933, train_l2:0.097419,  test_l2:0.365216\n",
      "2025-05-08 03:14:33,207 : epoch:350, time:10.896306, train_mse:0.005842, train_l2:0.096665,  test_l2:0.364888\n",
      "2025-05-08 03:14:43,593 : epoch:351, time:10.383087, train_mse:0.005819, train_l2:0.096446,  test_l2:0.365040\n",
      "2025-05-08 03:14:54,003 : epoch:352, time:10.407132, train_mse:0.005806, train_l2:0.096404,  test_l2:0.366480\n",
      "2025-05-08 03:15:04,380 : epoch:353, time:10.374647, train_mse:0.005815, train_l2:0.096335,  test_l2:0.365716\n",
      "2025-05-08 03:15:14,669 : epoch:354, time:10.287219, train_mse:0.005815, train_l2:0.096348,  test_l2:0.365996\n",
      "2025-05-08 03:15:24,940 : epoch:355, time:10.268546, train_mse:0.005776, train_l2:0.095884,  test_l2:0.367405\n",
      "2025-05-08 03:15:35,208 : epoch:356, time:10.266215, train_mse:0.005741, train_l2:0.095684,  test_l2:0.366674\n",
      "2025-05-08 03:15:45,327 : epoch:357, time:10.117278, train_mse:0.005689, train_l2:0.095197,  test_l2:0.366581\n",
      "2025-05-08 03:15:55,531 : epoch:358, time:10.202307, train_mse:0.005622, train_l2:0.094568,  test_l2:0.366812\n",
      "2025-05-08 03:16:05,248 : epoch:359, time:9.714831, train_mse:0.005552, train_l2:0.094083,  test_l2:0.366460\n",
      "2025-05-08 03:16:15,293 : epoch:360, time:10.043773, train_mse:0.005537, train_l2:0.093863,  test_l2:0.366983\n",
      "2025-05-08 03:16:25,661 : epoch:361, time:10.365686, train_mse:0.005552, train_l2:0.094063,  test_l2:0.368138\n",
      "2025-05-08 03:16:36,129 : epoch:362, time:10.464460, train_mse:0.005599, train_l2:0.094439,  test_l2:0.367184\n",
      "2025-05-08 03:16:46,599 : epoch:363, time:10.469155, train_mse:0.005540, train_l2:0.093915,  test_l2:0.367344\n",
      "2025-05-08 03:16:56,856 : epoch:364, time:10.254894, train_mse:0.005465, train_l2:0.093091,  test_l2:0.367983\n",
      "2025-05-08 03:17:07,149 : epoch:365, time:10.292064, train_mse:0.005390, train_l2:0.092588,  test_l2:0.367335\n",
      "2025-05-08 03:17:17,035 : epoch:366, time:9.883060, train_mse:0.005340, train_l2:0.092091,  test_l2:0.368447\n",
      "2025-05-08 03:17:27,506 : epoch:367, time:10.467965, train_mse:0.005294, train_l2:0.091662,  test_l2:0.368380\n",
      "2025-05-08 03:17:37,910 : epoch:368, time:10.402581, train_mse:0.005261, train_l2:0.091379,  test_l2:0.369204\n",
      "2025-05-08 03:17:48,661 : epoch:369, time:10.748818, train_mse:0.005233, train_l2:0.091119,  test_l2:0.369490\n",
      "2025-05-08 03:17:59,098 : epoch:370, time:10.435085, train_mse:0.005169, train_l2:0.090554,  test_l2:0.368538\n",
      "2025-05-08 03:18:09,522 : epoch:371, time:10.421740, train_mse:0.005135, train_l2:0.090207,  test_l2:0.369355\n",
      "2025-05-08 03:18:20,035 : epoch:372, time:10.511878, train_mse:0.005089, train_l2:0.089793,  test_l2:0.369589\n",
      "2025-05-08 03:18:30,423 : epoch:373, time:10.385456, train_mse:0.005060, train_l2:0.089473,  test_l2:0.369665\n",
      "2025-05-08 03:18:40,978 : epoch:374, time:10.552113, train_mse:0.005016, train_l2:0.089146,  test_l2:0.369844\n",
      "2025-05-08 03:18:51,025 : epoch:375, time:10.046047, train_mse:0.004994, train_l2:0.088940,  test_l2:0.370225\n",
      "2025-05-08 03:19:01,520 : epoch:376, time:10.494150, train_mse:0.004974, train_l2:0.088661,  test_l2:0.370505\n",
      "2025-05-08 03:19:12,207 : epoch:377, time:10.682918, train_mse:0.004943, train_l2:0.088378,  test_l2:0.370497\n",
      "2025-05-08 03:19:22,947 : epoch:378, time:10.737508, train_mse:0.004921, train_l2:0.088219,  test_l2:0.370825\n",
      "2025-05-08 03:19:33,200 : epoch:379, time:10.249670, train_mse:0.004901, train_l2:0.087988,  test_l2:0.370980\n",
      "2025-05-08 03:19:43,502 : epoch:380, time:10.300685, train_mse:0.004868, train_l2:0.087687,  test_l2:0.371376\n",
      "2025-05-08 03:19:53,732 : epoch:381, time:10.227281, train_mse:0.004834, train_l2:0.087363,  test_l2:0.371157\n",
      "2025-05-08 03:20:04,371 : epoch:382, time:10.636474, train_mse:0.004819, train_l2:0.087225,  test_l2:0.371868\n",
      "2025-05-08 03:20:14,726 : epoch:383, time:10.353673, train_mse:0.004786, train_l2:0.086933,  test_l2:0.372187\n",
      "2025-05-08 03:20:24,977 : epoch:384, time:10.249563, train_mse:0.004774, train_l2:0.086781,  test_l2:0.372349\n",
      "2025-05-08 03:20:35,182 : epoch:385, time:10.203626, train_mse:0.004738, train_l2:0.086489,  test_l2:0.372139\n",
      "2025-05-08 03:20:45,713 : epoch:386, time:10.528693, train_mse:0.004700, train_l2:0.086123,  test_l2:0.372480\n",
      "2025-05-08 03:20:55,736 : epoch:387, time:10.021802, train_mse:0.004670, train_l2:0.085791,  test_l2:0.372982\n",
      "2025-05-08 03:21:05,799 : epoch:388, time:10.061068, train_mse:0.004652, train_l2:0.085537,  test_l2:0.373104\n",
      "2025-05-08 03:21:15,704 : epoch:389, time:9.902618, train_mse:0.004624, train_l2:0.085305,  test_l2:0.373294\n",
      "2025-05-08 03:21:25,939 : epoch:390, time:10.233111, train_mse:0.004593, train_l2:0.085037,  test_l2:0.373186\n",
      "2025-05-08 03:21:36,329 : epoch:391, time:10.388492, train_mse:0.004654, train_l2:0.085932,  test_l2:0.373627\n",
      "2025-05-08 03:21:46,781 : epoch:392, time:10.450952, train_mse:0.004645, train_l2:0.085793,  test_l2:0.373723\n",
      "2025-05-08 03:21:57,161 : epoch:393, time:10.378291, train_mse:0.004570, train_l2:0.084875,  test_l2:0.373905\n",
      "2025-05-08 03:22:07,578 : epoch:394, time:10.416051, train_mse:0.004489, train_l2:0.084041,  test_l2:0.374255\n",
      "2025-05-08 03:22:18,017 : epoch:395, time:10.435386, train_mse:0.004440, train_l2:0.083495,  test_l2:0.374210\n",
      "2025-05-08 03:22:28,701 : epoch:396, time:10.682718, train_mse:0.004398, train_l2:0.083111,  test_l2:0.374188\n",
      "2025-05-08 03:22:39,514 : epoch:397, time:10.810175, train_mse:0.004389, train_l2:0.082925,  test_l2:0.374787\n",
      "2025-05-08 03:22:50,089 : epoch:398, time:10.574225, train_mse:0.004362, train_l2:0.082689,  test_l2:0.375302\n",
      "2025-05-08 03:23:00,410 : epoch:399, time:10.318772, train_mse:0.004339, train_l2:0.082496,  test_l2:0.375606\n",
      "2025-05-08 03:23:11,001 : epoch:400, time:10.587542, train_mse:0.004319, train_l2:0.082247,  test_l2:0.375630\n",
      "2025-05-08 03:23:21,739 : epoch:401, time:10.736565, train_mse:0.004293, train_l2:0.082016,  test_l2:0.375805\n",
      "2025-05-08 03:23:32,188 : epoch:402, time:10.448211, train_mse:0.004272, train_l2:0.081767,  test_l2:0.376009\n",
      "2025-05-08 03:23:42,755 : epoch:403, time:10.564166, train_mse:0.004246, train_l2:0.081521,  test_l2:0.375908\n",
      "2025-05-08 03:23:53,247 : epoch:404, time:10.490546, train_mse:0.004230, train_l2:0.081304,  test_l2:0.376547\n",
      "2025-05-08 03:24:04,155 : epoch:405, time:10.906183, train_mse:0.004206, train_l2:0.081081,  test_l2:0.376704\n",
      "2025-05-08 03:24:14,666 : epoch:406, time:10.508292, train_mse:0.004177, train_l2:0.080828,  test_l2:0.376704\n",
      "2025-05-08 03:24:25,001 : epoch:407, time:10.332633, train_mse:0.004163, train_l2:0.080644,  test_l2:0.377141\n",
      "2025-05-08 03:24:35,685 : epoch:408, time:10.681332, train_mse:0.004146, train_l2:0.080460,  test_l2:0.377360\n",
      "2025-05-08 03:24:45,919 : epoch:409, time:10.232058, train_mse:0.004124, train_l2:0.080296,  test_l2:0.377510\n",
      "2025-05-08 03:24:56,458 : epoch:410, time:10.537355, train_mse:0.004111, train_l2:0.080093,  test_l2:0.377516\n",
      "2025-05-08 03:25:06,955 : epoch:411, time:10.493637, train_mse:0.004095, train_l2:0.079915,  test_l2:0.378130\n",
      "2025-05-08 03:25:17,659 : epoch:412, time:10.699859, train_mse:0.004076, train_l2:0.079748,  test_l2:0.377874\n",
      "2025-05-08 03:25:28,469 : epoch:413, time:10.807267, train_mse:0.004059, train_l2:0.079570,  test_l2:0.378150\n",
      "2025-05-08 03:25:38,905 : epoch:414, time:10.433702, train_mse:0.004040, train_l2:0.079379,  test_l2:0.378362\n",
      "2025-05-08 03:25:49,503 : epoch:415, time:10.594976, train_mse:0.004024, train_l2:0.079184,  test_l2:0.378646\n",
      "2025-05-08 03:25:59,693 : epoch:416, time:10.187668, train_mse:0.004010, train_l2:0.079017,  test_l2:0.378757\n",
      "2025-05-08 03:26:09,489 : epoch:417, time:9.794168, train_mse:0.003992, train_l2:0.078840,  test_l2:0.378804\n",
      "2025-05-08 03:26:19,553 : epoch:418, time:10.061873, train_mse:0.003978, train_l2:0.078674,  test_l2:0.379217\n",
      "2025-05-08 03:26:29,555 : epoch:419, time:9.999753, train_mse:0.003962, train_l2:0.078506,  test_l2:0.379412\n",
      "2025-05-08 03:26:40,019 : epoch:420, time:10.461180, train_mse:0.003945, train_l2:0.078332,  test_l2:0.379487\n",
      "2025-05-08 03:26:50,637 : epoch:421, time:10.617307, train_mse:0.003926, train_l2:0.078148,  test_l2:0.379738\n",
      "2025-05-08 03:27:01,158 : epoch:422, time:10.518966, train_mse:0.003908, train_l2:0.077960,  test_l2:0.379880\n",
      "2025-05-08 03:27:11,457 : epoch:423, time:10.297627, train_mse:0.003894, train_l2:0.077821,  test_l2:0.380131\n",
      "2025-05-08 03:27:21,669 : epoch:424, time:10.209617, train_mse:0.003878, train_l2:0.077641,  test_l2:0.380073\n",
      "2025-05-08 03:27:31,718 : epoch:425, time:10.047082, train_mse:0.003864, train_l2:0.077487,  test_l2:0.380312\n",
      "2025-05-08 03:27:41,771 : epoch:426, time:10.052193, train_mse:0.003852, train_l2:0.077351,  test_l2:0.380349\n",
      "2025-05-08 03:27:52,422 : epoch:427, time:10.649042, train_mse:0.003841, train_l2:0.077203,  test_l2:0.380752\n",
      "2025-05-08 03:28:02,530 : epoch:428, time:10.105399, train_mse:0.003825, train_l2:0.077043,  test_l2:0.380770\n",
      "2025-05-08 03:28:12,681 : epoch:429, time:10.149509, train_mse:0.003811, train_l2:0.076897,  test_l2:0.380940\n",
      "2025-05-08 03:28:22,766 : epoch:430, time:10.083213, train_mse:0.003799, train_l2:0.076750,  test_l2:0.381230\n",
      "2025-05-08 03:28:33,147 : epoch:431, time:10.379016, train_mse:0.003783, train_l2:0.076598,  test_l2:0.381435\n",
      "2025-05-08 03:28:43,685 : epoch:432, time:10.536295, train_mse:0.003774, train_l2:0.076480,  test_l2:0.381501\n",
      "2025-05-08 03:28:53,877 : epoch:433, time:10.191343, train_mse:0.003760, train_l2:0.076350,  test_l2:0.381569\n",
      "2025-05-08 03:29:03,991 : epoch:434, time:10.111382, train_mse:0.003748, train_l2:0.076215,  test_l2:0.381726\n",
      "2025-05-08 03:29:14,358 : epoch:435, time:10.365896, train_mse:0.003738, train_l2:0.076100,  test_l2:0.381978\n",
      "2025-05-08 03:29:24,949 : epoch:436, time:10.587858, train_mse:0.003726, train_l2:0.075976,  test_l2:0.382115\n",
      "2025-05-08 03:29:35,536 : epoch:437, time:10.580992, train_mse:0.003719, train_l2:0.075887,  test_l2:0.382147\n",
      "2025-05-08 03:29:46,277 : epoch:438, time:10.735760, train_mse:0.003704, train_l2:0.075745,  test_l2:0.382184\n",
      "2025-05-08 03:29:56,683 : epoch:439, time:10.403634, train_mse:0.003694, train_l2:0.075636,  test_l2:0.382423\n",
      "2025-05-08 03:30:07,008 : epoch:440, time:10.321850, train_mse:0.003686, train_l2:0.075526,  test_l2:0.382584\n",
      "2025-05-08 03:30:17,357 : epoch:441, time:10.347001, train_mse:0.003674, train_l2:0.075413,  test_l2:0.382712\n",
      "2025-05-08 03:30:27,541 : epoch:442, time:10.181278, train_mse:0.003666, train_l2:0.075318,  test_l2:0.382817\n",
      "2025-05-08 03:30:37,809 : epoch:443, time:10.266454, train_mse:0.003659, train_l2:0.075216,  test_l2:0.382949\n",
      "2025-05-08 03:30:48,363 : epoch:444, time:10.552393, train_mse:0.003646, train_l2:0.075110,  test_l2:0.383044\n",
      "2025-05-08 03:30:58,622 : epoch:445, time:10.257645, train_mse:0.003637, train_l2:0.075001,  test_l2:0.383108\n",
      "2025-05-08 03:31:08,751 : epoch:446, time:10.126680, train_mse:0.003630, train_l2:0.074912,  test_l2:0.383222\n",
      "2025-05-08 03:31:18,739 : epoch:447, time:9.985419, train_mse:0.003622, train_l2:0.074824,  test_l2:0.383293\n",
      "2025-05-08 03:31:28,764 : epoch:448, time:10.023510, train_mse:0.003610, train_l2:0.074713,  test_l2:0.383500\n",
      "2025-05-08 03:31:38,921 : epoch:449, time:10.154304, train_mse:0.003604, train_l2:0.074631,  test_l2:0.383562\n",
      "2025-05-08 03:31:49,423 : epoch:450, time:10.499416, train_mse:0.003594, train_l2:0.074544,  test_l2:0.383646\n",
      "2025-05-08 03:31:59,968 : epoch:451, time:10.543013, train_mse:0.003588, train_l2:0.074462,  test_l2:0.383828\n",
      "2025-05-08 03:32:10,917 : epoch:452, time:10.946748, train_mse:0.003581, train_l2:0.074382,  test_l2:0.383814\n",
      "2025-05-08 03:32:21,411 : epoch:453, time:10.491332, train_mse:0.003575, train_l2:0.074303,  test_l2:0.383876\n",
      "2025-05-08 03:32:31,519 : epoch:454, time:10.105837, train_mse:0.003566, train_l2:0.074212,  test_l2:0.384031\n",
      "2025-05-08 03:32:42,060 : epoch:455, time:10.537503, train_mse:0.003558, train_l2:0.074139,  test_l2:0.384105\n",
      "2025-05-08 03:32:52,637 : epoch:456, time:10.572909, train_mse:0.003552, train_l2:0.074060,  test_l2:0.384170\n",
      "2025-05-08 03:33:03,070 : epoch:457, time:10.431601, train_mse:0.003545, train_l2:0.073986,  test_l2:0.384313\n",
      "2025-05-08 03:33:13,526 : epoch:458, time:10.453161, train_mse:0.003539, train_l2:0.073924,  test_l2:0.384397\n",
      "2025-05-08 03:33:23,710 : epoch:459, time:10.183153, train_mse:0.003533, train_l2:0.073859,  test_l2:0.384441\n",
      "2025-05-08 03:33:34,098 : epoch:460, time:10.385038, train_mse:0.003526, train_l2:0.073788,  test_l2:0.384485\n",
      "2025-05-08 03:33:44,427 : epoch:461, time:10.328513, train_mse:0.003521, train_l2:0.073726,  test_l2:0.384592\n",
      "2025-05-08 03:33:54,681 : epoch:462, time:10.250189, train_mse:0.003515, train_l2:0.073668,  test_l2:0.384603\n",
      "2025-05-08 03:34:05,248 : epoch:463, time:10.566606, train_mse:0.003510, train_l2:0.073612,  test_l2:0.384682\n",
      "2025-05-08 03:34:15,598 : epoch:464, time:10.347041, train_mse:0.003506, train_l2:0.073559,  test_l2:0.384789\n",
      "2025-05-08 03:34:25,908 : epoch:465, time:10.305574, train_mse:0.003501, train_l2:0.073504,  test_l2:0.384820\n",
      "2025-05-08 03:34:35,954 : epoch:466, time:10.045474, train_mse:0.003496, train_l2:0.073448,  test_l2:0.384872\n",
      "2025-05-08 03:34:46,512 : epoch:467, time:10.556104, train_mse:0.003492, train_l2:0.073405,  test_l2:0.384957\n",
      "2025-05-08 03:34:56,583 : epoch:468, time:10.069093, train_mse:0.003487, train_l2:0.073355,  test_l2:0.385000\n",
      "2025-05-08 03:35:06,830 : epoch:469, time:10.245613, train_mse:0.003484, train_l2:0.073309,  test_l2:0.385007\n",
      "2025-05-08 03:35:17,092 : epoch:470, time:10.260338, train_mse:0.003479, train_l2:0.073266,  test_l2:0.385097\n",
      "2025-05-08 03:35:27,297 : epoch:471, time:10.203783, train_mse:0.003476, train_l2:0.073228,  test_l2:0.385130\n",
      "2025-05-08 03:35:37,941 : epoch:472, time:10.641846, train_mse:0.003472, train_l2:0.073191,  test_l2:0.385144\n",
      "2025-05-08 03:35:48,342 : epoch:473, time:10.397623, train_mse:0.003469, train_l2:0.073155,  test_l2:0.385162\n",
      "2025-05-08 03:35:58,890 : epoch:474, time:10.544846, train_mse:0.003466, train_l2:0.073120,  test_l2:0.385222\n",
      "2025-05-08 03:36:08,892 : epoch:475, time:9.998291, train_mse:0.003463, train_l2:0.073083,  test_l2:0.385273\n",
      "2025-05-08 03:36:19,345 : epoch:476, time:10.451393, train_mse:0.003460, train_l2:0.073055,  test_l2:0.385282\n",
      "2025-05-08 03:36:29,847 : epoch:477, time:10.501374, train_mse:0.003458, train_l2:0.073026,  test_l2:0.385314\n",
      "2025-05-08 03:36:40,321 : epoch:478, time:10.472100, train_mse:0.003455, train_l2:0.073000,  test_l2:0.385349\n",
      "2025-05-08 03:36:50,680 : epoch:479, time:10.357162, train_mse:0.003453, train_l2:0.072976,  test_l2:0.385413\n",
      "2025-05-08 03:37:00,900 : epoch:480, time:10.218917, train_mse:0.003451, train_l2:0.072951,  test_l2:0.385408\n",
      "2025-05-08 03:37:11,352 : epoch:481, time:10.448384, train_mse:0.003449, train_l2:0.072930,  test_l2:0.385439\n",
      "2025-05-08 03:37:21,904 : epoch:482, time:10.549583, train_mse:0.003447, train_l2:0.072909,  test_l2:0.385441\n",
      "2025-05-08 03:37:32,174 : epoch:483, time:10.267577, train_mse:0.003445, train_l2:0.072890,  test_l2:0.385448\n",
      "2025-05-08 03:37:42,510 : epoch:484, time:10.334090, train_mse:0.003444, train_l2:0.072874,  test_l2:0.385462\n",
      "2025-05-08 03:37:52,644 : epoch:485, time:10.132010, train_mse:0.003442, train_l2:0.072858,  test_l2:0.385478\n",
      "2025-05-08 03:38:03,389 : epoch:486, time:10.743213, train_mse:0.003441, train_l2:0.072843,  test_l2:0.385516\n",
      "2025-05-08 03:38:13,729 : epoch:487, time:10.338302, train_mse:0.003440, train_l2:0.072831,  test_l2:0.385528\n",
      "2025-05-08 03:38:24,240 : epoch:488, time:10.508557, train_mse:0.003439, train_l2:0.072820,  test_l2:0.385517\n",
      "2025-05-08 03:38:35,085 : epoch:489, time:10.842465, train_mse:0.003438, train_l2:0.072809,  test_l2:0.385540\n",
      "2025-05-08 03:38:45,291 : epoch:490, time:10.204442, train_mse:0.003437, train_l2:0.072800,  test_l2:0.385516\n",
      "2025-05-08 03:38:55,828 : epoch:491, time:10.533113, train_mse:0.003436, train_l2:0.072792,  test_l2:0.385534\n",
      "2025-05-08 03:39:05,809 : epoch:492, time:9.980037, train_mse:0.003436, train_l2:0.072786,  test_l2:0.385554\n",
      "2025-05-08 03:39:16,191 : epoch:493, time:10.380011, train_mse:0.003435, train_l2:0.072780,  test_l2:0.385554\n",
      "2025-05-08 03:39:26,921 : epoch:494, time:10.728745, train_mse:0.003435, train_l2:0.072775,  test_l2:0.385553\n",
      "2025-05-08 03:39:37,194 : epoch:495, time:10.269617, train_mse:0.003435, train_l2:0.072772,  test_l2:0.385559\n",
      "2025-05-08 03:39:47,651 : epoch:496, time:10.455566, train_mse:0.003434, train_l2:0.072769,  test_l2:0.385559\n",
      "2025-05-08 03:39:58,126 : epoch:497, time:10.470645, train_mse:0.003434, train_l2:0.072767,  test_l2:0.385558\n",
      "2025-05-08 03:40:08,574 : epoch:498, time:10.445893, train_mse:0.003434, train_l2:0.072765,  test_l2:0.385557\n",
      "2025-05-08 03:40:19,029 : epoch:499, time:10.451628, train_mse:0.003434, train_l2:0.072765,  test_l2:0.385557\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer\n",
    "gamma = 1.0\n",
    "best_err = 1e10\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        out = out.view(batch_size, S, S, T)\n",
    "\n",
    "        mse = F.mse_loss(out, y, reduction='mean')\n",
    "        # mse.backward()\n",
    "\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x)\n",
    "            out = out.view(batch_size, S, S, T)\n",
    "#            out = y_normalizer.decode(out)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    logger.info('epoch:%d, time:%f, train_mse:%f, train_l2:%f,  test_l2:%f'%\n",
    "               (ep, t2-t1, train_mse, train_l2,test_l2))\n",
    "    if test_l2<best_err:\n",
    "        best_err = test_l2\n",
    "        torch.save(model, path_model)\n",
    "        logger.info('best model saved')\n",
    "\n",
    "#torch.save(model, path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 03:40:19,554 : 0    0.359190\n",
      "2025-05-08 03:40:19,571 : 1    0.265943\n",
      "2025-05-08 03:40:19,581 : 2    0.371688\n",
      "2025-05-08 03:40:19,590 : 3    0.541948\n",
      "2025-05-08 03:40:19,599 : 4    0.321139\n",
      "2025-05-08 03:40:19,608 : 5    0.306439\n",
      "2025-05-08 03:40:19,673 : 6    0.539004\n",
      "2025-05-08 03:40:19,687 : 7    0.382147\n",
      "2025-05-08 03:40:19,697 : 8    0.332345\n",
      "2025-05-08 03:40:19,713 : 9    0.364134\n",
      "2025-05-08 03:40:19,722 : 10    0.438590\n",
      "2025-05-08 03:40:19,739 : 11    0.295619\n",
      "2025-05-08 03:40:19,749 : 12    0.417132\n",
      "2025-05-08 03:40:19,758 : 13    0.403903\n",
      "2025-05-08 03:40:19,767 : 14    0.430318\n",
      "2025-05-08 03:40:19,776 : 15    0.403275\n",
      "2025-05-08 03:40:19,805 : 16    0.413278\n",
      "2025-05-08 03:40:19,848 : 17    0.404600\n",
      "2025-05-08 03:40:19,857 : 18    0.461607\n",
      "2025-05-08 03:40:19,874 : 19    0.338014\n",
      "2025-05-08 03:40:19,883 : 20    0.331858\n",
      "2025-05-08 03:40:19,899 : 21    0.340784\n",
      "2025-05-08 03:40:19,908 : 22    0.480059\n",
      "2025-05-08 03:40:19,917 : 23    0.297184\n",
      "2025-05-08 03:40:19,926 : 24    0.299857\n",
      "2025-05-08 03:40:19,936 : 25    0.292787\n",
      "2025-05-08 03:40:19,949 : 26    0.334987\n",
      "2025-05-08 03:40:20,009 : 27    0.316583\n",
      "2025-05-08 03:40:20,019 : 28    0.319167\n",
      "2025-05-08 03:40:20,033 : 29    0.319395\n",
      "2025-05-08 03:40:20,042 : 30    0.307391\n",
      "2025-05-08 03:40:20,051 : 31    0.338657\n",
      "2025-05-08 03:40:20,065 : 32    0.323934\n",
      "2025-05-08 03:40:20,074 : 33    0.284020\n",
      "2025-05-08 03:40:20,083 : 34    0.376351\n",
      "2025-05-08 03:40:20,093 : 35    0.388003\n",
      "2025-05-08 03:40:20,102 : 36    0.380033\n",
      "2025-05-08 03:40:20,129 : 37    0.387474\n",
      "2025-05-08 03:40:20,140 : 38    0.484698\n",
      "2025-05-08 03:40:20,155 : 39    0.380697\n",
      "2025-05-08 03:40:20,168 : 40    0.326763\n",
      "2025-05-08 03:40:20,183 : 41    0.265054\n",
      "2025-05-08 03:40:20,192 : 42    0.282683\n",
      "2025-05-08 03:40:20,209 : 43    0.326788\n",
      "2025-05-08 03:40:20,218 : 44    0.366648\n",
      "2025-05-08 03:40:20,228 : 45    0.277138\n",
      "2025-05-08 03:40:20,237 : 46    0.388924\n",
      "2025-05-08 03:40:20,247 : 47    0.478796\n",
      "2025-05-08 03:40:20,257 : 48    0.450210\n",
      "2025-05-08 03:40:20,267 : 49    0.346188\n",
      "2025-05-08 03:40:20,277 : 50    0.304708\n",
      "2025-05-08 03:40:20,291 : 51    0.318093\n",
      "2025-05-08 03:40:20,307 : 52    0.384152\n",
      "2025-05-08 03:40:20,345 : 53    0.391970\n",
      "2025-05-08 03:40:20,371 : 54    0.306252\n",
      "2025-05-08 03:40:20,381 : 55    0.430430\n",
      "2025-05-08 03:40:20,398 : 56    0.465164\n",
      "2025-05-08 03:40:20,407 : 57    0.398772\n",
      "2025-05-08 03:40:20,423 : 58    0.444162\n",
      "2025-05-08 03:40:20,432 : 59    0.505615\n",
      "2025-05-08 03:40:20,441 : 60    0.293273\n",
      "2025-05-08 03:40:20,450 : 61    0.290724\n",
      "2025-05-08 03:40:20,459 : 62    0.312534\n",
      "2025-05-08 03:40:20,468 : 63    0.258351\n",
      "2025-05-08 03:40:20,546 : 64    0.310663\n",
      "2025-05-08 03:40:20,556 : 65    0.394886\n",
      "2025-05-08 03:40:20,573 : 66    0.401336\n",
      "2025-05-08 03:40:20,582 : 67    0.322111\n",
      "2025-05-08 03:40:20,598 : 68    0.363502\n",
      "2025-05-08 03:40:20,608 : 69    0.343328\n",
      "2025-05-08 03:40:20,617 : 70    0.376911\n",
      "2025-05-08 03:40:20,626 : 71    0.337126\n",
      "2025-05-08 03:40:20,636 : 72    0.332412\n",
      "2025-05-08 03:40:20,654 : 73    0.307992\n",
      "2025-05-08 03:40:20,719 : 74    0.357191\n",
      "2025-05-08 03:40:20,728 : 75    0.386216\n",
      "2025-05-08 03:40:20,745 : 76    0.428844\n",
      "2025-05-08 03:40:20,754 : 77    0.314442\n",
      "2025-05-08 03:40:20,770 : 78    0.352176\n",
      "2025-05-08 03:40:20,779 : 79    0.361922\n",
      "2025-05-08 03:40:20,788 : 80    0.303833\n",
      "2025-05-08 03:40:20,797 : 81    0.341872\n",
      "2025-05-08 03:40:20,807 : 82    0.331573\n",
      "2025-05-08 03:40:20,817 : 83    0.342626\n",
      "2025-05-08 03:40:20,830 : 84    0.318570\n",
      "2025-05-08 03:40:20,899 : 85    0.319709\n",
      "2025-05-08 03:40:20,909 : 86    0.401246\n",
      "2025-05-08 03:40:20,925 : 87    0.360867\n",
      "2025-05-08 03:40:20,934 : 88    0.358807\n",
      "2025-05-08 03:40:20,951 : 89    0.364965\n",
      "2025-05-08 03:40:20,960 : 90    0.364124\n",
      "2025-05-08 03:40:20,969 : 91    0.384942\n",
      "2025-05-08 03:40:20,979 : 92    0.380216\n",
      "2025-05-08 03:40:20,988 : 93    0.351942\n",
      "2025-05-08 03:40:20,997 : 94    0.381749\n",
      "2025-05-08 03:40:21,010 : 95    0.339467\n",
      "2025-05-08 03:40:21,079 : 96    0.440726\n",
      "2025-05-08 03:40:21,088 : 97    0.407472\n",
      "2025-05-08 03:40:21,106 : 98    0.333527\n",
      "2025-05-08 03:40:21,115 : 99    0.344545\n",
      "2025-05-08 03:40:21,125 : 100    0.318292\n",
      "2025-05-08 03:40:21,136 : 101    0.301335\n",
      "2025-05-08 03:40:21,145 : 102    0.377359\n",
      "2025-05-08 03:40:21,154 : 103    0.389221\n",
      "2025-05-08 03:40:21,163 : 104    0.352392\n",
      "2025-05-08 03:40:21,172 : 105    0.336681\n",
      "2025-05-08 03:40:21,182 : 106    0.354214\n",
      "2025-05-08 03:40:21,191 : 107    0.368096\n",
      "2025-05-08 03:40:21,200 : 108    0.377315\n",
      "2025-05-08 03:40:21,209 : 109    0.400974\n",
      "2025-05-08 03:40:21,218 : 110    0.351382\n",
      "2025-05-08 03:40:21,227 : 111    0.327767\n",
      "2025-05-08 03:40:21,236 : 112    0.389026\n",
      "2025-05-08 03:40:21,246 : 113    0.359623\n",
      "2025-05-08 03:40:21,255 : 114    0.348053\n",
      "2025-05-08 03:40:21,264 : 115    0.403275\n",
      "2025-05-08 03:40:21,275 : 116    0.371556\n",
      "2025-05-08 03:40:21,285 : 117    0.332076\n",
      "2025-05-08 03:40:21,295 : 118    0.391922\n",
      "2025-05-08 03:40:21,306 : 119    0.422148\n",
      "2025-05-08 03:40:21,316 : 120    0.342275\n",
      "2025-05-08 03:40:21,325 : 121    0.238298\n",
      "2025-05-08 03:40:21,334 : 122    0.258555\n",
      "2025-05-08 03:40:21,344 : 123    0.292664\n",
      "2025-05-08 03:40:21,353 : 124    0.557088\n",
      "2025-05-08 03:40:21,362 : 125    0.337625\n",
      "2025-05-08 03:40:21,372 : 126    0.338159\n",
      "2025-05-08 03:40:21,381 : 127    0.359794\n",
      "2025-05-08 03:40:21,390 : 128    0.486932\n",
      "2025-05-08 03:40:21,399 : 129    0.400479\n",
      "2025-05-08 03:40:21,408 : 130    0.291326\n",
      "2025-05-08 03:40:21,417 : 131    0.329160\n",
      "2025-05-08 03:40:21,445 : 132    0.321717\n",
      "2025-05-08 03:40:21,515 : 133    0.434002\n",
      "2025-05-08 03:40:21,528 : 134    0.343921\n",
      "2025-05-08 03:40:21,541 : 135    0.301917\n",
      "2025-05-08 03:40:21,552 : 136    0.335116\n",
      "2025-05-08 03:40:21,611 : 137    0.398172\n",
      "2025-05-08 03:40:21,620 : 138    0.414550\n",
      "2025-05-08 03:40:21,630 : 139    0.347022\n",
      "2025-05-08 03:40:21,639 : 140    0.330258\n",
      "2025-05-08 03:40:21,647 : 141    0.403927\n",
      "2025-05-08 03:40:21,656 : 142    0.286793\n",
      "2025-05-08 03:40:21,665 : 143    0.338065\n",
      "2025-05-08 03:40:21,673 : 144    0.332243\n",
      "2025-05-08 03:40:21,682 : 145    0.318898\n",
      "2025-05-08 03:40:21,691 : 146    0.282899\n",
      "2025-05-08 03:40:21,699 : 147    0.253931\n",
      "2025-05-08 03:40:21,708 : 148    0.313259\n",
      "2025-05-08 03:40:21,717 : 149    0.314984\n",
      "2025-05-08 03:40:21,726 : 150    0.372159\n",
      "2025-05-08 03:40:21,735 : 151    0.345035\n",
      "2025-05-08 03:40:21,744 : 152    0.316704\n",
      "2025-05-08 03:40:21,754 : 153    0.320456\n",
      "2025-05-08 03:40:21,763 : 154    0.314043\n",
      "2025-05-08 03:40:21,772 : 155    0.331213\n",
      "2025-05-08 03:40:21,781 : 156    0.384677\n",
      "2025-05-08 03:40:21,790 : 157    0.352956\n",
      "2025-05-08 03:40:21,800 : 158    0.387553\n",
      "2025-05-08 03:40:21,809 : 159    0.337630\n",
      "2025-05-08 03:40:21,819 : 160    0.317770\n",
      "2025-05-08 03:40:21,828 : 161    0.324809\n",
      "2025-05-08 03:40:21,838 : 162    0.240906\n",
      "2025-05-08 03:40:21,847 : 163    0.249837\n",
      "2025-05-08 03:40:21,856 : 164    0.315679\n",
      "2025-05-08 03:40:21,864 : 165    0.288816\n",
      "2025-05-08 03:40:21,945 : 166    0.385143\n",
      "2025-05-08 03:40:21,954 : 167    0.329280\n",
      "2025-05-08 03:40:21,963 : 168    0.458071\n",
      "2025-05-08 03:40:21,974 : 169    0.347460\n",
      "2025-05-08 03:40:21,983 : 170    0.351000\n",
      "2025-05-08 03:40:21,993 : 171    0.314118\n",
      "2025-05-08 03:40:22,006 : 172    0.313952\n",
      "2025-05-08 03:40:22,015 : 173    0.336307\n",
      "2025-05-08 03:40:22,024 : 174    0.342127\n",
      "2025-05-08 03:40:22,037 : 175    0.403120\n",
      "2025-05-08 03:40:22,051 : 176    0.366041\n",
      "2025-05-08 03:40:22,060 : 177    0.314317\n",
      "2025-05-08 03:40:22,069 : 178    0.366800\n",
      "2025-05-08 03:40:22,078 : 179    0.353246\n",
      "2025-05-08 03:40:22,089 : 180    0.351739\n",
      "2025-05-08 03:40:22,103 : 181    0.336847\n",
      "2025-05-08 03:40:22,112 : 182    0.305206\n",
      "2025-05-08 03:40:22,121 : 183    0.270934\n",
      "2025-05-08 03:40:22,136 : 184    0.335670\n",
      "2025-05-08 03:40:22,150 : 185    0.300175\n",
      "2025-05-08 03:40:22,160 : 186    0.383151\n",
      "2025-05-08 03:40:22,169 : 187    0.381478\n",
      "2025-05-08 03:40:22,183 : 188    0.330983\n",
      "2025-05-08 03:40:22,192 : 189    0.358626\n",
      "2025-05-08 03:40:22,201 : 190    0.360822\n",
      "2025-05-08 03:40:22,213 : 191    0.318500\n",
      "2025-05-08 03:40:22,223 : 192    0.402372\n",
      "2025-05-08 03:40:22,233 : 193    0.313634\n",
      "2025-05-08 03:40:22,242 : 194    0.365494\n",
      "2025-05-08 03:40:22,251 : 195    0.386961\n",
      "2025-05-08 03:40:22,260 : 196    0.336691\n",
      "2025-05-08 03:40:22,269 : 197    0.409353\n",
      "2025-05-08 03:40:22,279 : 198    0.383443\n",
      "2025-05-08 03:40:22,290 : 199    0.403889\n",
      "2025-05-08 03:40:22,313 : 200    0.351284\n",
      "2025-05-08 03:40:22,334 : 201    0.350602\n",
      "2025-05-08 03:40:22,345 : 202    0.347361\n",
      "2025-05-08 03:40:22,356 : 203    0.336896\n",
      "2025-05-08 03:40:22,375 : 204    0.293747\n",
      "2025-05-08 03:40:22,385 : 205    0.337756\n",
      "2025-05-08 03:40:22,395 : 206    0.291070\n",
      "2025-05-08 03:40:22,406 : 207    0.301237\n",
      "2025-05-08 03:40:22,415 : 208    0.304121\n",
      "2025-05-08 03:40:22,424 : 209    0.325960\n",
      "2025-05-08 03:40:22,433 : 210    0.364417\n",
      "2025-05-08 03:40:22,443 : 211    0.330495\n",
      "2025-05-08 03:40:22,452 : 212    0.367498\n",
      "2025-05-08 03:40:22,461 : 213    0.392453\n",
      "2025-05-08 03:40:22,471 : 214    0.352625\n",
      "2025-05-08 03:40:22,481 : 215    0.364521\n",
      "2025-05-08 03:40:22,490 : 216    0.472203\n",
      "2025-05-08 03:40:22,499 : 217    0.383618\n",
      "2025-05-08 03:40:22,508 : 218    0.451397\n",
      "2025-05-08 03:40:22,517 : 219    0.434745\n",
      "2025-05-08 03:40:22,527 : 220    0.351596\n",
      "2025-05-08 03:40:22,536 : 221    0.269017\n",
      "2025-05-08 03:40:22,545 : 222    0.303805\n",
      "2025-05-08 03:40:22,554 : 223    0.317062\n",
      "2025-05-08 03:40:22,563 : 224    0.350964\n",
      "2025-05-08 03:40:22,573 : 225    0.356155\n",
      "2025-05-08 03:40:22,582 : 226    0.295396\n",
      "2025-05-08 03:40:22,591 : 227    0.302770\n",
      "2025-05-08 03:40:22,600 : 228    0.312804\n",
      "2025-05-08 03:40:22,610 : 229    0.345499\n",
      "2025-05-08 03:40:22,620 : 230    0.351106\n",
      "2025-05-08 03:40:22,631 : 231    0.388185\n",
      "2025-05-08 03:40:22,643 : 232    0.401119\n",
      "2025-05-08 03:40:22,654 : 233    0.369009\n",
      "2025-05-08 03:40:22,665 : 234    0.376437\n",
      "2025-05-08 03:40:22,675 : 235    0.383781\n",
      "2025-05-08 03:40:22,686 : 236    0.418421\n",
      "2025-05-08 03:40:22,696 : 237    0.462760\n",
      "2025-05-08 03:40:22,707 : 238    0.388564\n",
      "2025-05-08 03:40:22,718 : 239    0.404724\n"
     ]
    }
   ],
   "source": [
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "model = torch.load(path_model).cuda()\n",
    "#model = torch.load(model,path_model).cuda()\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        x, y  = x.cuda(), y.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        out = out.view(1, S, S, T)\n",
    "#        out = y_normalizer.decode(out)\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        #print(index, test_l2)\n",
    "        logger.info('%d    %f' % (index,test_l2))\n",
    "        index = index + 1\n",
    "\n",
    "scipy.io.savemat(path+'/pred.mat', mdict={'pred': pred.cpu().numpy(), 'test_u': test_u.cpu().numpy()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fno",
   "language": "python",
   "name": "fno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
